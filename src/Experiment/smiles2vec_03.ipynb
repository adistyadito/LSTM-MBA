{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "16952110",
   "metadata": {},
   "source": [
    "# B\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3662f43d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CELL 1 - Import\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Embedding, Conv1D, LSTM, Dense, Dropout, BatchNormalization\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau, ModelCheckpoint\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "from sklearn.metrics import classification_report, confusion_matrix, roc_auc_score\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "bec8d068",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Distribusi label:\n",
      "target\n",
      "0    0.504717\n",
      "1    0.495283\n",
      "Name: proportion, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# CELL 2 - Load & Preprocess\n",
    "df = pd.read_csv('/home/dito-adistya/Dito/TA/Coding/LSTM-MBA/data/GSARPC3.csv')\n",
    "df['smiles'] = df['smiles'].str.upper()\n",
    "\n",
    "# Encode label\n",
    "df['target'] = df['categories'].apply(lambda x: 1 if x == \"inhibitor\" else 0)\n",
    "print(\"Distribusi label:\")\n",
    "print(df['target'].value_counts(normalize=True))\n",
    "\n",
    "# Stratified split\n",
    "df_train, df_test = train_test_split(\n",
    "    df, test_size=0.2, random_state=42, stratify=df['target']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "4e2293d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train: (508, 168) | vocab: 28 | max_len: 168\n"
     ]
    }
   ],
   "source": [
    "# CELL 3 - SMILES → Integer Sequence (WITH PADDING & mask_zero)\n",
    "all_chars = set(''.join(df['smiles']))\n",
    "charset = sorted(all_chars)\n",
    "char_to_int = {c: i+1 for i, c in enumerate(charset)}  # 1,2,3,...\n",
    "char_to_int['<PAD>'] = 0  # padding token\n",
    "vocab_size = len(char_to_int)\n",
    "\n",
    "MAX_LEN = min(250, max(len(s) for s in df['smiles']) + 5)\n",
    "\n",
    "def smiles_to_seq(smiles_list, max_len):\n",
    "    seqs = []\n",
    "    for s in smiles_list:\n",
    "        seq = [char_to_int.get(c, 0) for c in s]\n",
    "        if len(seq) > max_len:\n",
    "            seq = seq[:max_len]\n",
    "        else:\n",
    "            seq += [0] * (max_len - len(seq))  # PAD\n",
    "        seqs.append(seq)\n",
    "    return np.array(seqs, dtype=np.int32)\n",
    "\n",
    "X_train = smiles_to_seq(df_train['smiles'].tolist(), MAX_LEN)\n",
    "X_test = smiles_to_seq(df_test['smiles'].tolist(), MAX_LEN)\n",
    "y_train = df_train['target'].values.astype(np.float32)\n",
    "y_test = df_test['target'].values.astype(np.float32)\n",
    "\n",
    "print(f\"X_train: {X_train.shape} | vocab: {vocab_size} | max_len: {MAX_LEN}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "5d4cff8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CELL 4 - Build SMILES2VEC + LSTM (NO Bidirectional, Conv1D opsional)\n",
    "def build_model(\n",
    "    embedding_dim=64,\n",
    "    use_conv=False,           # bisa False untuk pure SMILES2Vec\n",
    "    conv_filters=64,\n",
    "    conv_kernel_size=5,\n",
    "    lstm_units=128,\n",
    "    dropout_rate=0.5,\n",
    "    learning_rate=0.001\n",
    "):\n",
    "    model = Sequential()\n",
    "    \n",
    "    # === SMILES2VEC: Embedding Layer (trainable) ===\n",
    "    model.add(Embedding(\n",
    "        input_dim=vocab_size,\n",
    "        output_dim=embedding_dim,\n",
    "        input_length=MAX_LEN,\n",
    "        mask_zero=True,       # ignore <PAD>\n",
    "        name='smiles2vec'\n",
    "    ))\n",
    "    \n",
    "    # Optional Conv1D\n",
    "    if use_conv:\n",
    "        model.add(Conv1D(conv_filters, conv_kernel_size, activation='relu', padding='same'))\n",
    "        model.add(BatchNormalization())\n",
    "    \n",
    "    # LSTM (unidirectional only)\n",
    "    model.add(LSTM(lstm_units, return_sequences=False))\n",
    "    model.add(Dropout(dropout_rate))\n",
    "    model.add(Dense(32, activation='relu'))\n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "    model.compile(\n",
    "        optimizer=Adam(learning_rate=learning_rate),\n",
    "        loss='binary_crossentropy',\n",
    "        metrics=['accuracy', 'Precision', 'Recall', 'AUC']\n",
    "    )\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "8b6febf8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class weights: {0: 0.9921875, 1: 1.007936507936508}\n",
      "Epoch 1/200\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/dito-adistya/miniconda3/envs/py311/lib/python3.11/site-packages/keras/src/layers/core/embedding.py:97: UserWarning: Argument `input_length` is deprecated. Just remove it.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 189ms/step - AUC: 0.4886 - Precision: 0.4920 - Recall: 0.7341 - accuracy: 0.4921 - loss: 0.6934 - val_AUC: 0.6698 - val_Precision: 0.4880 - val_Recall: 0.9683 - val_accuracy: 0.4844 - val_loss: 0.6891 - learning_rate: 0.0010\n",
      "Epoch 2/200\n",
      "\u001b[1m 1/16\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 131ms/step - AUC: 0.6548 - Precision: 0.4516 - Recall: 1.0000 - accuracy: 0.4688 - loss: 0.6934"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/dito-adistya/miniconda3/envs/py311/lib/python3.11/site-packages/keras/src/callbacks/early_stopping.py:99: UserWarning: Early stopping conditioned on metric `val_auc` which is not available. Available metrics are: AUC,Precision,Recall,accuracy,loss,val_AUC,val_Precision,val_Recall,val_accuracy,val_loss\n",
      "  current = self.get_monitor_value(logs)\n",
      "/home/dito-adistya/miniconda3/envs/py311/lib/python3.11/site-packages/keras/src/callbacks/model_checkpoint.py:276: UserWarning: Can save best model only with val_auc available.\n",
      "  if self._should_save_model(epoch, batch, logs, filepath):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 144ms/step - AUC: 0.6228 - Precision: 0.6100 - Recall: 0.5833 - accuracy: 0.6083 - loss: 0.6863 - val_AUC: 0.6510 - val_Precision: 0.6167 - val_Recall: 0.5873 - val_accuracy: 0.6172 - val_loss: 0.6784 - learning_rate: 0.0010\n",
      "Epoch 3/200\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 136ms/step - AUC: 0.6364 - Precision: 0.6073 - Recall: 0.6627 - accuracy: 0.6201 - loss: 0.6729 - val_AUC: 0.6531 - val_Precision: 0.6207 - val_Recall: 0.5714 - val_accuracy: 0.6172 - val_loss: 0.6582 - learning_rate: 0.0010\n",
      "Epoch 4/200\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 151ms/step - AUC: 0.6648 - Precision: 0.6154 - Recall: 0.6667 - accuracy: 0.6280 - loss: 0.6548 - val_AUC: 0.6635 - val_Precision: 0.6552 - val_Recall: 0.6032 - val_accuracy: 0.6484 - val_loss: 0.6486 - learning_rate: 0.0010\n",
      "Epoch 5/200\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 140ms/step - AUC: 0.6861 - Precision: 0.6575 - Recall: 0.6627 - accuracy: 0.6614 - loss: 0.6411 - val_AUC: 0.6729 - val_Precision: 0.6056 - val_Recall: 0.6825 - val_accuracy: 0.6250 - val_loss: 0.6502 - learning_rate: 0.0010\n",
      "Epoch 6/200\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 138ms/step - AUC: 0.7079 - Precision: 0.5915 - Recall: 0.7183 - accuracy: 0.6142 - loss: 0.6312 - val_AUC: 0.6764 - val_Precision: 0.7000 - val_Recall: 0.5556 - val_accuracy: 0.6641 - val_loss: 0.6335 - learning_rate: 0.0010\n",
      "Epoch 7/200\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 146ms/step - AUC: 0.7024 - Precision: 0.6844 - Recall: 0.6111 - accuracy: 0.6673 - loss: 0.6269 - val_AUC: 0.6598 - val_Precision: 0.6786 - val_Recall: 0.6032 - val_accuracy: 0.6641 - val_loss: 0.6433 - learning_rate: 0.0010\n",
      "Epoch 8/200\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 180ms/step - AUC: 0.7126 - Precision: 0.6781 - Recall: 0.6270 - accuracy: 0.6673 - loss: 0.6225 - val_AUC: 0.6785 - val_Precision: 0.7200 - val_Recall: 0.5714 - val_accuracy: 0.6797 - val_loss: 0.6302 - learning_rate: 0.0010\n",
      "Epoch 9/200\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 161ms/step - AUC: 0.7328 - Precision: 0.6496 - Recall: 0.7063 - accuracy: 0.6654 - loss: 0.6099 - val_AUC: 0.6855 - val_Precision: 0.7000 - val_Recall: 0.5556 - val_accuracy: 0.6641 - val_loss: 0.6328 - learning_rate: 0.0010\n",
      "Epoch 10/200\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 149ms/step - AUC: 0.7220 - Precision: 0.6872 - Recall: 0.6627 - accuracy: 0.6831 - loss: 0.6173 - val_AUC: 0.6852 - val_Precision: 0.6923 - val_Recall: 0.5714 - val_accuracy: 0.6641 - val_loss: 0.6344 - learning_rate: 0.0010\n",
      "Epoch 11/200\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 147ms/step - AUC: 0.7375 - Precision: 0.6864 - Recall: 0.6429 - accuracy: 0.6772 - loss: 0.6037 - val_AUC: 0.6852 - val_Precision: 0.7292 - val_Recall: 0.5556 - val_accuracy: 0.6797 - val_loss: 0.6300 - learning_rate: 0.0010\n",
      "Epoch 12/200\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 148ms/step - AUC: 0.7313 - Precision: 0.6862 - Recall: 0.6508 - accuracy: 0.6791 - loss: 0.6047 - val_AUC: 0.6984 - val_Precision: 0.6029 - val_Recall: 0.6508 - val_accuracy: 0.6172 - val_loss: 0.6310 - learning_rate: 0.0010\n",
      "Epoch 13/200\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 144ms/step - AUC: 0.7456 - Precision: 0.6545 - Recall: 0.7143 - accuracy: 0.6713 - loss: 0.5956 - val_AUC: 0.6916 - val_Precision: 0.7273 - val_Recall: 0.5079 - val_accuracy: 0.6641 - val_loss: 0.6257 - learning_rate: 0.0010\n",
      "Epoch 14/200\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 143ms/step - AUC: 0.7521 - Precision: 0.7156 - Recall: 0.6389 - accuracy: 0.6949 - loss: 0.5888 - val_AUC: 0.6729 - val_Precision: 0.6333 - val_Recall: 0.6032 - val_accuracy: 0.6328 - val_loss: 0.6520 - learning_rate: 0.0010\n",
      "Epoch 15/200\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 168ms/step - AUC: 0.7704 - Precision: 0.7104 - Recall: 0.7302 - accuracy: 0.7185 - loss: 0.5733 - val_AUC: 0.6939 - val_Precision: 0.7021 - val_Recall: 0.5238 - val_accuracy: 0.6562 - val_loss: 0.6381 - learning_rate: 0.0010\n",
      "Epoch 16/200\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 148ms/step - AUC: 0.7800 - Precision: 0.7028 - Recall: 0.6944 - accuracy: 0.7028 - loss: 0.5660 - val_AUC: 0.6947 - val_Precision: 0.6923 - val_Recall: 0.5714 - val_accuracy: 0.6641 - val_loss: 0.6276 - learning_rate: 0.0010\n",
      "Epoch 17/200\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 160ms/step - AUC: 0.7791 - Precision: 0.7178 - Recall: 0.6865 - accuracy: 0.7106 - loss: 0.5618 - val_AUC: 0.6755 - val_Precision: 0.6349 - val_Recall: 0.6349 - val_accuracy: 0.6406 - val_loss: 0.6530 - learning_rate: 0.0010\n",
      "Epoch 18/200\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 155ms/step - AUC: 0.7984 - Precision: 0.6934 - Recall: 0.7293 - accuracy: 0.7124 - loss: 0.5470\n",
      "Epoch 18: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 171ms/step - AUC: 0.7884 - Precision: 0.6908 - Recall: 0.7183 - accuracy: 0.7008 - loss: 0.5527 - val_AUC: 0.6791 - val_Precision: 0.6735 - val_Recall: 0.5238 - val_accuracy: 0.6406 - val_loss: 0.6717 - learning_rate: 0.0010\n",
      "Epoch 19/200\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 129ms/step - AUC: 0.8094 - Precision: 0.7375 - Recall: 0.7024 - accuracy: 0.7283 - loss: 0.5278 - val_AUC: 0.6935 - val_Precision: 0.6545 - val_Recall: 0.5714 - val_accuracy: 0.6406 - val_loss: 0.6627 - learning_rate: 5.0000e-04\n",
      "Epoch 20/200\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 131ms/step - AUC: 0.8157 - Precision: 0.7236 - Recall: 0.7897 - accuracy: 0.7461 - loss: 0.5239 - val_AUC: 0.6888 - val_Precision: 0.6800 - val_Recall: 0.5397 - val_accuracy: 0.6484 - val_loss: 0.6917 - learning_rate: 5.0000e-04\n",
      "Epoch 21/200\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 136ms/step - AUC: 0.8225 - Precision: 0.7305 - Recall: 0.7421 - accuracy: 0.7362 - loss: 0.5077 - val_AUC: 0.7004 - val_Precision: 0.6981 - val_Recall: 0.5873 - val_accuracy: 0.6719 - val_loss: 0.6795 - learning_rate: 5.0000e-04\n",
      "Epoch 22/200\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 143ms/step - AUC: 0.8293 - Precision: 0.7371 - Recall: 0.7341 - accuracy: 0.7382 - loss: 0.5017 - val_AUC: 0.6849 - val_Precision: 0.6852 - val_Recall: 0.5873 - val_accuracy: 0.6641 - val_loss: 0.6941 - learning_rate: 5.0000e-04\n",
      "Epoch 23/200\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 132ms/step - AUC: 0.8362 - Precision: 0.7489 - Recall: 0.7851 - accuracy: 0.7690 - loss: 0.5021\n",
      "Epoch 23: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 150ms/step - AUC: 0.8455 - Precision: 0.7568 - Recall: 0.7778 - accuracy: 0.7657 - loss: 0.4891 - val_AUC: 0.6944 - val_Precision: 0.7018 - val_Recall: 0.6349 - val_accuracy: 0.6875 - val_loss: 0.7194 - learning_rate: 5.0000e-04\n",
      "Epoch 24/200\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 153ms/step - AUC: 0.8491 - Precision: 0.7509 - Recall: 0.7897 - accuracy: 0.7657 - loss: 0.4780 - val_AUC: 0.6902 - val_Precision: 0.7037 - val_Recall: 0.6032 - val_accuracy: 0.6797 - val_loss: 0.7509 - learning_rate: 2.5000e-04\n",
      "Epoch 25/200\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 163ms/step - AUC: 0.8590 - Precision: 0.7547 - Recall: 0.7937 - accuracy: 0.7697 - loss: 0.4655 - val_AUC: 0.6866 - val_Precision: 0.6607 - val_Recall: 0.5873 - val_accuracy: 0.6484 - val_loss: 0.7682 - learning_rate: 2.5000e-04\n",
      "Epoch 26/200\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 149ms/step - AUC: 0.8646 - Precision: 0.7571 - Recall: 0.8413 - accuracy: 0.7874 - loss: 0.4564 - val_AUC: 0.6908 - val_Precision: 0.6923 - val_Recall: 0.5714 - val_accuracy: 0.6641 - val_loss: 0.7935 - learning_rate: 2.5000e-04\n",
      "Epoch 27/200\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 145ms/step - AUC: 0.8669 - Precision: 0.7778 - Recall: 0.7778 - accuracy: 0.7795 - loss: 0.4550 - val_AUC: 0.6911 - val_Precision: 0.6545 - val_Recall: 0.5714 - val_accuracy: 0.6406 - val_loss: 0.8035 - learning_rate: 2.5000e-04\n",
      "Epoch 28/200\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 135ms/step - AUC: 0.8836 - Precision: 0.7895 - Recall: 0.8385 - accuracy: 0.8045 - loss: 0.4279\n",
      "Epoch 28: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 155ms/step - AUC: 0.8646 - Precision: 0.7736 - Recall: 0.8135 - accuracy: 0.7894 - loss: 0.4544 - val_AUC: 0.6922 - val_Precision: 0.7000 - val_Recall: 0.5556 - val_accuracy: 0.6641 - val_loss: 0.7775 - learning_rate: 2.5000e-04\n",
      "Epoch 29/200\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 153ms/step - AUC: 0.8781 - Precision: 0.7863 - Recall: 0.8175 - accuracy: 0.7992 - loss: 0.4364 - val_AUC: 0.6912 - val_Precision: 0.6607 - val_Recall: 0.5873 - val_accuracy: 0.6484 - val_loss: 0.8272 - learning_rate: 1.2500e-04\n",
      "Epoch 30/200\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 152ms/step - AUC: 0.8833 - Precision: 0.7794 - Recall: 0.8413 - accuracy: 0.8031 - loss: 0.4280 - val_AUC: 0.6846 - val_Precision: 0.7000 - val_Recall: 0.5556 - val_accuracy: 0.6641 - val_loss: 0.8247 - learning_rate: 1.2500e-04\n",
      "Epoch 31/200\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 162ms/step - AUC: 0.8738 - Precision: 0.7903 - Recall: 0.7778 - accuracy: 0.7874 - loss: 0.4432 - val_AUC: 0.6896 - val_Precision: 0.7234 - val_Recall: 0.5397 - val_accuracy: 0.6719 - val_loss: 0.8135 - learning_rate: 1.2500e-04\n",
      "Epoch 32/200\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 147ms/step - AUC: 0.8818 - Precision: 0.8000 - Recall: 0.8254 - accuracy: 0.8110 - loss: 0.4300 - val_AUC: 0.6838 - val_Precision: 0.6610 - val_Recall: 0.6190 - val_accuracy: 0.6562 - val_loss: 0.8895 - learning_rate: 1.2500e-04\n",
      "Epoch 33/200\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 134ms/step - AUC: 0.8768 - Precision: 0.7631 - Recall: 0.7963 - accuracy: 0.7743 - loss: 0.4315\n",
      "Epoch 33: ReduceLROnPlateau reducing learning rate to 6.25000029685907e-05.\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 151ms/step - AUC: 0.8871 - Precision: 0.7662 - Recall: 0.8452 - accuracy: 0.7953 - loss: 0.4194 - val_AUC: 0.6912 - val_Precision: 0.6727 - val_Recall: 0.5873 - val_accuracy: 0.6562 - val_loss: 0.8605 - learning_rate: 1.2500e-04\n",
      "Epoch 34/200\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 149ms/step - AUC: 0.8939 - Precision: 0.7926 - Recall: 0.8492 - accuracy: 0.8150 - loss: 0.4109 - val_AUC: 0.6894 - val_Precision: 0.6852 - val_Recall: 0.5873 - val_accuracy: 0.6641 - val_loss: 0.8863 - learning_rate: 6.2500e-05\n",
      "Epoch 35/200\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 136ms/step - AUC: 0.8945 - Precision: 0.7749 - Recall: 0.8333 - accuracy: 0.7972 - loss: 0.4074 - val_AUC: 0.6885 - val_Precision: 0.6852 - val_Recall: 0.5873 - val_accuracy: 0.6641 - val_loss: 0.9026 - learning_rate: 6.2500e-05\n",
      "Epoch 36/200\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 144ms/step - AUC: 0.8869 - Precision: 0.7709 - Recall: 0.8413 - accuracy: 0.7972 - loss: 0.4178 - val_AUC: 0.6916 - val_Precision: 0.6852 - val_Recall: 0.5873 - val_accuracy: 0.6641 - val_loss: 0.9000 - learning_rate: 6.2500e-05\n",
      "Epoch 37/200\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 166ms/step - AUC: 0.8891 - Precision: 0.7719 - Recall: 0.8056 - accuracy: 0.7854 - loss: 0.4127 - val_AUC: 0.6904 - val_Precision: 0.6852 - val_Recall: 0.5873 - val_accuracy: 0.6641 - val_loss: 0.8975 - learning_rate: 6.2500e-05\n",
      "Epoch 38/200\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 121ms/step - AUC: 0.8951 - Precision: 0.7960 - Recall: 0.8451 - accuracy: 0.8186 - loss: 0.4052\n",
      "Epoch 38: ReduceLROnPlateau reducing learning rate to 3.125000148429535e-05.\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 139ms/step - AUC: 0.8906 - Precision: 0.7909 - Recall: 0.8254 - accuracy: 0.8051 - loss: 0.4105 - val_AUC: 0.6934 - val_Precision: 0.6852 - val_Recall: 0.5873 - val_accuracy: 0.6641 - val_loss: 0.9009 - learning_rate: 6.2500e-05\n",
      "Epoch 39/200\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 169ms/step - AUC: 0.8885 - Precision: 0.7795 - Recall: 0.8135 - accuracy: 0.7933 - loss: 0.4160 - val_AUC: 0.6918 - val_Precision: 0.6727 - val_Recall: 0.5873 - val_accuracy: 0.6562 - val_loss: 0.9054 - learning_rate: 3.1250e-05\n",
      "Epoch 40/200\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 179ms/step - AUC: 0.8911 - Precision: 0.7839 - Recall: 0.8492 - accuracy: 0.8091 - loss: 0.4123 - val_AUC: 0.6890 - val_Precision: 0.6842 - val_Recall: 0.6190 - val_accuracy: 0.6719 - val_loss: 0.9130 - learning_rate: 3.1250e-05\n",
      "Epoch 41/200\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 149ms/step - AUC: 0.8897 - Precision: 0.7873 - Recall: 0.8373 - accuracy: 0.8071 - loss: 0.4129 - val_AUC: 0.6908 - val_Precision: 0.6842 - val_Recall: 0.6190 - val_accuracy: 0.6719 - val_loss: 0.9082 - learning_rate: 3.1250e-05\n",
      "Epoch 42/200\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 159ms/step - AUC: 0.8971 - Precision: 0.7701 - Recall: 0.8373 - accuracy: 0.7953 - loss: 0.4016 - val_AUC: 0.6921 - val_Precision: 0.6842 - val_Recall: 0.6190 - val_accuracy: 0.6719 - val_loss: 0.9105 - learning_rate: 3.1250e-05\n",
      "Epoch 43/200\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 131ms/step - AUC: 0.8875 - Precision: 0.7951 - Recall: 0.8240 - accuracy: 0.7998 - loss: 0.4152\n",
      "Epoch 43: ReduceLROnPlateau reducing learning rate to 1.5625000742147677e-05.\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 156ms/step - AUC: 0.9004 - Precision: 0.7889 - Recall: 0.8452 - accuracy: 0.8110 - loss: 0.3990 - val_AUC: 0.6906 - val_Precision: 0.6964 - val_Recall: 0.6190 - val_accuracy: 0.6797 - val_loss: 0.9196 - learning_rate: 3.1250e-05\n",
      "Epoch 44/200\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 156ms/step - AUC: 0.8942 - Precision: 0.7857 - Recall: 0.8294 - accuracy: 0.8031 - loss: 0.4075 - val_AUC: 0.6908 - val_Precision: 0.6842 - val_Recall: 0.6190 - val_accuracy: 0.6719 - val_loss: 0.9216 - learning_rate: 1.5625e-05\n",
      "Epoch 45/200\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 149ms/step - AUC: 0.8948 - Precision: 0.7939 - Recall: 0.8254 - accuracy: 0.8071 - loss: 0.4037 - val_AUC: 0.6917 - val_Precision: 0.6842 - val_Recall: 0.6190 - val_accuracy: 0.6719 - val_loss: 0.9208 - learning_rate: 1.5625e-05\n",
      "Epoch 46/200\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 149ms/step - AUC: 0.8990 - Precision: 0.7828 - Recall: 0.8294 - accuracy: 0.8012 - loss: 0.3981 - val_AUC: 0.6901 - val_Precision: 0.6964 - val_Recall: 0.6190 - val_accuracy: 0.6797 - val_loss: 0.9242 - learning_rate: 1.5625e-05\n",
      "Epoch 47/200\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 156ms/step - AUC: 0.8983 - Precision: 0.7857 - Recall: 0.8294 - accuracy: 0.8031 - loss: 0.4011 - val_AUC: 0.6880 - val_Precision: 0.6964 - val_Recall: 0.6190 - val_accuracy: 0.6797 - val_loss: 0.9298 - learning_rate: 1.5625e-05\n",
      "Epoch 48/200\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 133ms/step - AUC: 0.8987 - Precision: 0.8445 - Recall: 0.8391 - accuracy: 0.8337 - loss: 0.4009\n",
      "Epoch 48: ReduceLROnPlateau reducing learning rate to 7.812500371073838e-06.\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 150ms/step - AUC: 0.8992 - Precision: 0.8060 - Recall: 0.8571 - accuracy: 0.8268 - loss: 0.3992 - val_AUC: 0.6873 - val_Precision: 0.6842 - val_Recall: 0.6190 - val_accuracy: 0.6719 - val_loss: 0.9335 - learning_rate: 1.5625e-05\n",
      "Epoch 49/200\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 154ms/step - AUC: 0.8947 - Precision: 0.7865 - Recall: 0.8333 - accuracy: 0.8051 - loss: 0.4040 - val_AUC: 0.6882 - val_Precision: 0.6964 - val_Recall: 0.6190 - val_accuracy: 0.6797 - val_loss: 0.9308 - learning_rate: 7.8125e-06\n",
      "Epoch 50/200\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 146ms/step - AUC: 0.8963 - Precision: 0.7910 - Recall: 0.8413 - accuracy: 0.8110 - loss: 0.4050 - val_AUC: 0.6902 - val_Precision: 0.6842 - val_Recall: 0.6190 - val_accuracy: 0.6719 - val_loss: 0.9278 - learning_rate: 7.8125e-06\n",
      "Epoch 51/200\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 170ms/step - AUC: 0.8974 - Precision: 0.7873 - Recall: 0.8373 - accuracy: 0.8071 - loss: 0.4000 - val_AUC: 0.6905 - val_Precision: 0.6842 - val_Recall: 0.6190 - val_accuracy: 0.6719 - val_loss: 0.9276 - learning_rate: 7.8125e-06\n",
      "Epoch 52/200\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 157ms/step - AUC: 0.8938 - Precision: 0.7860 - Recall: 0.8452 - accuracy: 0.8091 - loss: 0.4067 - val_AUC: 0.6901 - val_Precision: 0.6842 - val_Recall: 0.6190 - val_accuracy: 0.6719 - val_loss: 0.9305 - learning_rate: 7.8125e-06\n",
      "Epoch 53/200\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 152ms/step - AUC: 0.8973 - Precision: 0.7709 - Recall: 0.8088 - accuracy: 0.7985 - loss: 0.4064\n",
      "Epoch 53: ReduceLROnPlateau reducing learning rate to 3.906250185536919e-06.\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 173ms/step - AUC: 0.8989 - Precision: 0.7844 - Recall: 0.8373 - accuracy: 0.8051 - loss: 0.4013 - val_AUC: 0.6910 - val_Precision: 0.6964 - val_Recall: 0.6190 - val_accuracy: 0.6797 - val_loss: 0.9292 - learning_rate: 7.8125e-06\n",
      "Epoch 54/200\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 147ms/step - AUC: 0.9025 - Precision: 0.7881 - Recall: 0.8413 - accuracy: 0.8091 - loss: 0.3933 - val_AUC: 0.6907 - val_Precision: 0.6842 - val_Recall: 0.6190 - val_accuracy: 0.6719 - val_loss: 0.9308 - learning_rate: 3.9063e-06\n",
      "Epoch 55/200\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 155ms/step - AUC: 0.9029 - Precision: 0.7934 - Recall: 0.8532 - accuracy: 0.8169 - loss: 0.3922 - val_AUC: 0.6904 - val_Precision: 0.6842 - val_Recall: 0.6190 - val_accuracy: 0.6719 - val_loss: 0.9322 - learning_rate: 3.9063e-06\n",
      "Epoch 56/200\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 162ms/step - AUC: 0.9039 - Precision: 0.7889 - Recall: 0.8452 - accuracy: 0.8110 - loss: 0.3911 - val_AUC: 0.6907 - val_Precision: 0.6842 - val_Recall: 0.6190 - val_accuracy: 0.6719 - val_loss: 0.9317 - learning_rate: 3.9063e-06\n",
      "Epoch 57/200\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 183ms/step - AUC: 0.9024 - Precision: 0.7964 - Recall: 0.8690 - accuracy: 0.8248 - loss: 0.3943 - val_AUC: 0.6907 - val_Precision: 0.6964 - val_Recall: 0.6190 - val_accuracy: 0.6797 - val_loss: 0.9326 - learning_rate: 3.9063e-06\n",
      "Epoch 58/200\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 142ms/step - AUC: 0.9005 - Precision: 0.8100 - Recall: 0.8535 - accuracy: 0.8211 - loss: 0.3928\n",
      "Epoch 58: ReduceLROnPlateau reducing learning rate to 1.9531250927684596e-06.\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 168ms/step - AUC: 0.9001 - Precision: 0.7955 - Recall: 0.8492 - accuracy: 0.8169 - loss: 0.3977 - val_AUC: 0.6901 - val_Precision: 0.6964 - val_Recall: 0.6190 - val_accuracy: 0.6797 - val_loss: 0.9327 - learning_rate: 3.9063e-06\n",
      "Epoch 59/200\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 168ms/step - AUC: 0.8979 - Precision: 0.7889 - Recall: 0.8452 - accuracy: 0.8110 - loss: 0.4038 - val_AUC: 0.6907 - val_Precision: 0.6842 - val_Recall: 0.6190 - val_accuracy: 0.6719 - val_loss: 0.9323 - learning_rate: 1.9531e-06\n",
      "Epoch 60/200\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 168ms/step - AUC: 0.9015 - Precision: 0.7962 - Recall: 0.8373 - accuracy: 0.8130 - loss: 0.3971 - val_AUC: 0.6905 - val_Precision: 0.6964 - val_Recall: 0.6190 - val_accuracy: 0.6797 - val_loss: 0.9322 - learning_rate: 1.9531e-06\n",
      "Epoch 61/200\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 156ms/step - AUC: 0.8977 - Precision: 0.7918 - Recall: 0.8452 - accuracy: 0.8130 - loss: 0.3997 - val_AUC: 0.6896 - val_Precision: 0.6964 - val_Recall: 0.6190 - val_accuracy: 0.6797 - val_loss: 0.9325 - learning_rate: 1.9531e-06\n",
      "Epoch 62/200\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 164ms/step - AUC: 0.9071 - Precision: 0.8090 - Recall: 0.8571 - accuracy: 0.8287 - loss: 0.3852 - val_AUC: 0.6893 - val_Precision: 0.6964 - val_Recall: 0.6190 - val_accuracy: 0.6797 - val_loss: 0.9331 - learning_rate: 1.9531e-06\n",
      "Epoch 63/200\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 134ms/step - AUC: 0.9058 - Precision: 0.7797 - Recall: 0.8503 - accuracy: 0.8208 - loss: 0.3908\n",
      "Epoch 63: ReduceLROnPlateau reducing learning rate to 9.765625463842298e-07.\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 152ms/step - AUC: 0.8995 - Precision: 0.7889 - Recall: 0.8452 - accuracy: 0.8110 - loss: 0.4002 - val_AUC: 0.6886 - val_Precision: 0.6964 - val_Recall: 0.6190 - val_accuracy: 0.6797 - val_loss: 0.9331 - learning_rate: 1.9531e-06\n",
      "Epoch 64/200\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 174ms/step - AUC: 0.9014 - Precision: 0.7963 - Recall: 0.8532 - accuracy: 0.8189 - loss: 0.3936 - val_AUC: 0.6888 - val_Precision: 0.6964 - val_Recall: 0.6190 - val_accuracy: 0.6797 - val_loss: 0.9331 - learning_rate: 9.7656e-07\n",
      "Epoch 65/200\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 155ms/step - AUC: 0.8974 - Precision: 0.7868 - Recall: 0.8492 - accuracy: 0.8110 - loss: 0.4007 - val_AUC: 0.6889 - val_Precision: 0.6964 - val_Recall: 0.6190 - val_accuracy: 0.6797 - val_loss: 0.9334 - learning_rate: 9.7656e-07\n",
      "Epoch 66/200\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 157ms/step - AUC: 0.9012 - Precision: 0.7889 - Recall: 0.8452 - accuracy: 0.8110 - loss: 0.3957 - val_AUC: 0.6893 - val_Precision: 0.6964 - val_Recall: 0.6190 - val_accuracy: 0.6797 - val_loss: 0.9332 - learning_rate: 9.7656e-07\n",
      "Epoch 67/200\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 171ms/step - AUC: 0.8973 - Precision: 0.7860 - Recall: 0.8452 - accuracy: 0.8091 - loss: 0.4004 - val_AUC: 0.6894 - val_Precision: 0.6964 - val_Recall: 0.6190 - val_accuracy: 0.6797 - val_loss: 0.9335 - learning_rate: 9.7656e-07\n",
      "Epoch 68/200\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 185ms/step - AUC: 0.9048 - Precision: 0.7876 - Recall: 0.8445 - accuracy: 0.8101 - loss: 0.3910\n",
      "Epoch 68: ReduceLROnPlateau reducing learning rate to 4.882812731921149e-07.\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 205ms/step - AUC: 0.9015 - Precision: 0.7852 - Recall: 0.8413 - accuracy: 0.8071 - loss: 0.3952 - val_AUC: 0.6893 - val_Precision: 0.6964 - val_Recall: 0.6190 - val_accuracy: 0.6797 - val_loss: 0.9335 - learning_rate: 9.7656e-07\n",
      "Epoch 69/200\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 195ms/step - AUC: 0.8949 - Precision: 0.7815 - Recall: 0.8373 - accuracy: 0.8031 - loss: 0.4048 - val_AUC: 0.6893 - val_Precision: 0.6964 - val_Recall: 0.6190 - val_accuracy: 0.6797 - val_loss: 0.9334 - learning_rate: 4.8828e-07\n",
      "Epoch 70/200\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 173ms/step - AUC: 0.8947 - Precision: 0.7831 - Recall: 0.8452 - accuracy: 0.8071 - loss: 0.4064 - val_AUC: 0.6893 - val_Precision: 0.6964 - val_Recall: 0.6190 - val_accuracy: 0.6797 - val_loss: 0.9335 - learning_rate: 4.8828e-07\n",
      "Epoch 71/200\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 156ms/step - AUC: 0.9022 - Precision: 0.7948 - Recall: 0.8452 - accuracy: 0.8150 - loss: 0.3918 - val_AUC: 0.6893 - val_Precision: 0.6964 - val_Recall: 0.6190 - val_accuracy: 0.6797 - val_loss: 0.9337 - learning_rate: 4.8828e-07\n",
      "Epoch 72/200\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 158ms/step - AUC: 0.8970 - Precision: 0.7881 - Recall: 0.8413 - accuracy: 0.8091 - loss: 0.4017 - val_AUC: 0.6894 - val_Precision: 0.6964 - val_Recall: 0.6190 - val_accuracy: 0.6797 - val_loss: 0.9337 - learning_rate: 4.8828e-07\n",
      "Epoch 73/200\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 132ms/step - AUC: 0.9085 - Precision: 0.8145 - Recall: 0.8673 - accuracy: 0.8390 - loss: 0.3830\n",
      "Epoch 73: ReduceLROnPlateau reducing learning rate to 2.4414063659605745e-07.\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 152ms/step - AUC: 0.8974 - Precision: 0.8022 - Recall: 0.8532 - accuracy: 0.8228 - loss: 0.4037 - val_AUC: 0.6894 - val_Precision: 0.6964 - val_Recall: 0.6190 - val_accuracy: 0.6797 - val_loss: 0.9338 - learning_rate: 4.8828e-07\n",
      "Epoch 74/200\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 163ms/step - AUC: 0.9026 - Precision: 0.7839 - Recall: 0.8492 - accuracy: 0.8091 - loss: 0.3930 - val_AUC: 0.6894 - val_Precision: 0.6964 - val_Recall: 0.6190 - val_accuracy: 0.6797 - val_loss: 0.9338 - learning_rate: 2.4414e-07\n",
      "Epoch 75/200\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 151ms/step - AUC: 0.8990 - Precision: 0.7940 - Recall: 0.8413 - accuracy: 0.8130 - loss: 0.3969 - val_AUC: 0.6894 - val_Precision: 0.6964 - val_Recall: 0.6190 - val_accuracy: 0.6797 - val_loss: 0.9338 - learning_rate: 2.4414e-07\n",
      "Epoch 76/200\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 174ms/step - AUC: 0.9014 - Precision: 0.7802 - Recall: 0.8452 - accuracy: 0.8051 - loss: 0.3951 - val_AUC: 0.6893 - val_Precision: 0.6964 - val_Recall: 0.6190 - val_accuracy: 0.6797 - val_loss: 0.9338 - learning_rate: 2.4414e-07\n",
      "Epoch 77/200\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 148ms/step - AUC: 0.9036 - Precision: 0.7940 - Recall: 0.8413 - accuracy: 0.8130 - loss: 0.3921 - val_AUC: 0.6893 - val_Precision: 0.6964 - val_Recall: 0.6190 - val_accuracy: 0.6797 - val_loss: 0.9338 - learning_rate: 2.4414e-07\n",
      "Epoch 78/200\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 142ms/step - AUC: 0.8915 - Precision: 0.7964 - Recall: 0.8378 - accuracy: 0.8094 - loss: 0.4131\n",
      "Epoch 78: ReduceLROnPlateau reducing learning rate to 1.2207031829802872e-07.\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 161ms/step - AUC: 0.9041 - Precision: 0.7978 - Recall: 0.8611 - accuracy: 0.8228 - loss: 0.3919 - val_AUC: 0.6894 - val_Precision: 0.6964 - val_Recall: 0.6190 - val_accuracy: 0.6797 - val_loss: 0.9339 - learning_rate: 2.4414e-07\n",
      "Epoch 79/200\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 149ms/step - AUC: 0.8993 - Precision: 0.7757 - Recall: 0.8373 - accuracy: 0.7992 - loss: 0.3970 - val_AUC: 0.6893 - val_Precision: 0.6964 - val_Recall: 0.6190 - val_accuracy: 0.6797 - val_loss: 0.9339 - learning_rate: 1.2207e-07\n",
      "Epoch 80/200\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 171ms/step - AUC: 0.8972 - Precision: 0.7897 - Recall: 0.8492 - accuracy: 0.8130 - loss: 0.3982 - val_AUC: 0.6893 - val_Precision: 0.6964 - val_Recall: 0.6190 - val_accuracy: 0.6797 - val_loss: 0.9339 - learning_rate: 1.2207e-07\n",
      "Epoch 81/200\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 150ms/step - AUC: 0.8986 - Precision: 0.7815 - Recall: 0.8373 - accuracy: 0.8031 - loss: 0.4017 - val_AUC: 0.6893 - val_Precision: 0.6964 - val_Recall: 0.6190 - val_accuracy: 0.6797 - val_loss: 0.9339 - learning_rate: 1.2207e-07\n",
      "Epoch 82/200\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 162ms/step - AUC: 0.9011 - Precision: 0.7910 - Recall: 0.8413 - accuracy: 0.8110 - loss: 0.3962 - val_AUC: 0.6894 - val_Precision: 0.6964 - val_Recall: 0.6190 - val_accuracy: 0.6797 - val_loss: 0.9340 - learning_rate: 1.2207e-07\n",
      "Epoch 83/200\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 134ms/step - AUC: 0.9144 - Precision: 0.7908 - Recall: 0.8583 - accuracy: 0.8199 - loss: 0.3756\n",
      "Epoch 83: ReduceLROnPlateau reducing learning rate to 1e-07.\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 154ms/step - AUC: 0.9012 - Precision: 0.7941 - Recall: 0.8571 - accuracy: 0.8189 - loss: 0.3958 - val_AUC: 0.6894 - val_Precision: 0.6964 - val_Recall: 0.6190 - val_accuracy: 0.6797 - val_loss: 0.9340 - learning_rate: 1.2207e-07\n",
      "Epoch 84/200\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 152ms/step - AUC: 0.8996 - Precision: 0.7897 - Recall: 0.8492 - accuracy: 0.8130 - loss: 0.4006 - val_AUC: 0.6894 - val_Precision: 0.6964 - val_Recall: 0.6190 - val_accuracy: 0.6797 - val_loss: 0.9340 - learning_rate: 1.0000e-07\n",
      "Epoch 85/200\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 152ms/step - AUC: 0.9002 - Precision: 0.7934 - Recall: 0.8532 - accuracy: 0.8169 - loss: 0.3982 - val_AUC: 0.6894 - val_Precision: 0.6964 - val_Recall: 0.6190 - val_accuracy: 0.6797 - val_loss: 0.9341 - learning_rate: 1.0000e-07\n",
      "Epoch 86/200\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 156ms/step - AUC: 0.8997 - Precision: 0.7934 - Recall: 0.8532 - accuracy: 0.8169 - loss: 0.3989 - val_AUC: 0.6894 - val_Precision: 0.6964 - val_Recall: 0.6190 - val_accuracy: 0.6797 - val_loss: 0.9340 - learning_rate: 1.0000e-07\n",
      "Epoch 87/200\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 150ms/step - AUC: 0.9038 - Precision: 0.7895 - Recall: 0.8333 - accuracy: 0.8071 - loss: 0.3905 - val_AUC: 0.6894 - val_Precision: 0.6964 - val_Recall: 0.6190 - val_accuracy: 0.6797 - val_loss: 0.9340 - learning_rate: 1.0000e-07\n",
      "Epoch 88/200\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 155ms/step - AUC: 0.9005 - Precision: 0.7918 - Recall: 0.8452 - accuracy: 0.8130 - loss: 0.3998 - val_AUC: 0.6894 - val_Precision: 0.6964 - val_Recall: 0.6190 - val_accuracy: 0.6797 - val_loss: 0.9340 - learning_rate: 1.0000e-07\n",
      "Epoch 89/200\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 157ms/step - AUC: 0.9014 - Precision: 0.7836 - Recall: 0.8333 - accuracy: 0.8031 - loss: 0.3973 - val_AUC: 0.6894 - val_Precision: 0.6964 - val_Recall: 0.6190 - val_accuracy: 0.6797 - val_loss: 0.9341 - learning_rate: 1.0000e-07\n",
      "Epoch 90/200\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 158ms/step - AUC: 0.8984 - Precision: 0.7875 - Recall: 0.8532 - accuracy: 0.8130 - loss: 0.4001 - val_AUC: 0.6894 - val_Precision: 0.6964 - val_Recall: 0.6190 - val_accuracy: 0.6797 - val_loss: 0.9341 - learning_rate: 1.0000e-07\n",
      "Epoch 91/200\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 158ms/step - AUC: 0.8991 - Precision: 0.7855 - Recall: 0.8571 - accuracy: 0.8130 - loss: 0.3988 - val_AUC: 0.6894 - val_Precision: 0.6964 - val_Recall: 0.6190 - val_accuracy: 0.6797 - val_loss: 0.9341 - learning_rate: 1.0000e-07\n",
      "Epoch 92/200\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 172ms/step - AUC: 0.8987 - Precision: 0.7948 - Recall: 0.8452 - accuracy: 0.8150 - loss: 0.3991 - val_AUC: 0.6894 - val_Precision: 0.6964 - val_Recall: 0.6190 - val_accuracy: 0.6797 - val_loss: 0.9341 - learning_rate: 1.0000e-07\n",
      "Epoch 93/200\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 161ms/step - AUC: 0.8988 - Precision: 0.7993 - Recall: 0.8690 - accuracy: 0.8268 - loss: 0.3996 - val_AUC: 0.6894 - val_Precision: 0.6964 - val_Recall: 0.6190 - val_accuracy: 0.6797 - val_loss: 0.9341 - learning_rate: 1.0000e-07\n",
      "Epoch 94/200\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 156ms/step - AUC: 0.8964 - Precision: 0.7881 - Recall: 0.8413 - accuracy: 0.8091 - loss: 0.4031 - val_AUC: 0.6893 - val_Precision: 0.6964 - val_Recall: 0.6190 - val_accuracy: 0.6797 - val_loss: 0.9340 - learning_rate: 1.0000e-07\n",
      "Epoch 95/200\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 158ms/step - AUC: 0.8941 - Precision: 0.7889 - Recall: 0.8452 - accuracy: 0.8110 - loss: 0.4044 - val_AUC: 0.6893 - val_Precision: 0.6964 - val_Recall: 0.6190 - val_accuracy: 0.6797 - val_loss: 0.9341 - learning_rate: 1.0000e-07\n",
      "Epoch 96/200\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 151ms/step - AUC: 0.8922 - Precision: 0.7715 - Recall: 0.8175 - accuracy: 0.7894 - loss: 0.4118 - val_AUC: 0.6893 - val_Precision: 0.6964 - val_Recall: 0.6190 - val_accuracy: 0.6797 - val_loss: 0.9340 - learning_rate: 1.0000e-07\n",
      "Epoch 97/200\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 176ms/step - AUC: 0.9004 - Precision: 0.7948 - Recall: 0.8452 - accuracy: 0.8150 - loss: 0.3968 - val_AUC: 0.6893 - val_Precision: 0.6964 - val_Recall: 0.6190 - val_accuracy: 0.6797 - val_loss: 0.9341 - learning_rate: 1.0000e-07\n",
      "Epoch 98/200\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 165ms/step - AUC: 0.9033 - Precision: 0.8022 - Recall: 0.8532 - accuracy: 0.8228 - loss: 0.3924 - val_AUC: 0.6893 - val_Precision: 0.6964 - val_Recall: 0.6190 - val_accuracy: 0.6797 - val_loss: 0.9341 - learning_rate: 1.0000e-07\n",
      "Epoch 99/200\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 159ms/step - AUC: 0.9025 - Precision: 0.7899 - Recall: 0.8651 - accuracy: 0.8189 - loss: 0.3941 - val_AUC: 0.6894 - val_Precision: 0.6964 - val_Recall: 0.6190 - val_accuracy: 0.6797 - val_loss: 0.9341 - learning_rate: 1.0000e-07\n",
      "Epoch 100/200\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 162ms/step - AUC: 0.9011 - Precision: 0.7802 - Recall: 0.8452 - accuracy: 0.8051 - loss: 0.3946 - val_AUC: 0.6894 - val_Precision: 0.6964 - val_Recall: 0.6190 - val_accuracy: 0.6797 - val_loss: 0.9341 - learning_rate: 1.0000e-07\n",
      "Epoch 101/200\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 158ms/step - AUC: 0.8961 - Precision: 0.7852 - Recall: 0.8413 - accuracy: 0.8071 - loss: 0.4020 - val_AUC: 0.6894 - val_Precision: 0.6964 - val_Recall: 0.6190 - val_accuracy: 0.6797 - val_loss: 0.9341 - learning_rate: 1.0000e-07\n",
      "Epoch 102/200\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 154ms/step - AUC: 0.8960 - Precision: 0.7860 - Recall: 0.8452 - accuracy: 0.8091 - loss: 0.4017 - val_AUC: 0.6894 - val_Precision: 0.6964 - val_Recall: 0.6190 - val_accuracy: 0.6797 - val_loss: 0.9341 - learning_rate: 1.0000e-07\n",
      "Epoch 103/200\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 158ms/step - AUC: 0.9047 - Precision: 0.7993 - Recall: 0.8690 - accuracy: 0.8268 - loss: 0.3897 - val_AUC: 0.6895 - val_Precision: 0.6964 - val_Recall: 0.6190 - val_accuracy: 0.6797 - val_loss: 0.9341 - learning_rate: 1.0000e-07\n",
      "Epoch 104/200\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 152ms/step - AUC: 0.8987 - Precision: 0.7860 - Recall: 0.8452 - accuracy: 0.8091 - loss: 0.3992 - val_AUC: 0.6897 - val_Precision: 0.6964 - val_Recall: 0.6190 - val_accuracy: 0.6797 - val_loss: 0.9341 - learning_rate: 1.0000e-07\n",
      "Epoch 105/200\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 177ms/step - AUC: 0.8981 - Precision: 0.7875 - Recall: 0.8532 - accuracy: 0.8130 - loss: 0.3977 - val_AUC: 0.6897 - val_Precision: 0.6964 - val_Recall: 0.6190 - val_accuracy: 0.6797 - val_loss: 0.9341 - learning_rate: 1.0000e-07\n",
      "Epoch 106/200\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 162ms/step - AUC: 0.8930 - Precision: 0.7839 - Recall: 0.8492 - accuracy: 0.8091 - loss: 0.4085 - val_AUC: 0.6897 - val_Precision: 0.6964 - val_Recall: 0.6190 - val_accuracy: 0.6797 - val_loss: 0.9342 - learning_rate: 1.0000e-07\n",
      "Epoch 107/200\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 157ms/step - AUC: 0.8989 - Precision: 0.7862 - Recall: 0.8611 - accuracy: 0.8150 - loss: 0.4024 - val_AUC: 0.6897 - val_Precision: 0.6964 - val_Recall: 0.6190 - val_accuracy: 0.6797 - val_loss: 0.9342 - learning_rate: 1.0000e-07\n",
      "Epoch 108/200\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 165ms/step - AUC: 0.9002 - Precision: 0.7875 - Recall: 0.8532 - accuracy: 0.8130 - loss: 0.3965 - val_AUC: 0.6897 - val_Precision: 0.6964 - val_Recall: 0.6190 - val_accuracy: 0.6797 - val_loss: 0.9342 - learning_rate: 1.0000e-07\n",
      "Epoch 109/200\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 156ms/step - AUC: 0.8936 - Precision: 0.7889 - Recall: 0.8452 - accuracy: 0.8110 - loss: 0.4105 - val_AUC: 0.6897 - val_Precision: 0.6964 - val_Recall: 0.6190 - val_accuracy: 0.6797 - val_loss: 0.9342 - learning_rate: 1.0000e-07\n",
      "Epoch 110/200\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 168ms/step - AUC: 0.8990 - Precision: 0.7912 - Recall: 0.8571 - accuracy: 0.8169 - loss: 0.4014 - val_AUC: 0.6897 - val_Precision: 0.6964 - val_Recall: 0.6190 - val_accuracy: 0.6797 - val_loss: 0.9342 - learning_rate: 1.0000e-07\n",
      "Epoch 111/200\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 176ms/step - AUC: 0.8996 - Precision: 0.8000 - Recall: 0.8413 - accuracy: 0.8169 - loss: 0.3974 - val_AUC: 0.6897 - val_Precision: 0.6964 - val_Recall: 0.6190 - val_accuracy: 0.6797 - val_loss: 0.9342 - learning_rate: 1.0000e-07\n",
      "Epoch 112/200\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 162ms/step - AUC: 0.8941 - Precision: 0.7889 - Recall: 0.8452 - accuracy: 0.8110 - loss: 0.4060 - val_AUC: 0.6897 - val_Precision: 0.6964 - val_Recall: 0.6190 - val_accuracy: 0.6797 - val_loss: 0.9342 - learning_rate: 1.0000e-07\n",
      "Epoch 113/200\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 172ms/step - AUC: 0.8997 - Precision: 0.7855 - Recall: 0.8571 - accuracy: 0.8130 - loss: 0.3963 - val_AUC: 0.6897 - val_Precision: 0.6964 - val_Recall: 0.6190 - val_accuracy: 0.6797 - val_loss: 0.9342 - learning_rate: 1.0000e-07\n",
      "Epoch 114/200\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 162ms/step - AUC: 0.8995 - Precision: 0.7927 - Recall: 0.8651 - accuracy: 0.8209 - loss: 0.3993 - val_AUC: 0.6897 - val_Precision: 0.6964 - val_Recall: 0.6190 - val_accuracy: 0.6797 - val_loss: 0.9343 - learning_rate: 1.0000e-07\n",
      "Epoch 115/200\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 158ms/step - AUC: 0.9012 - Precision: 0.8052 - Recall: 0.8532 - accuracy: 0.8248 - loss: 0.3989 - val_AUC: 0.6897 - val_Precision: 0.6964 - val_Recall: 0.6190 - val_accuracy: 0.6797 - val_loss: 0.9343 - learning_rate: 1.0000e-07\n",
      "Epoch 116/200\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 177ms/step - AUC: 0.8989 - Precision: 0.8022 - Recall: 0.8532 - accuracy: 0.8228 - loss: 0.3995 - val_AUC: 0.6897 - val_Precision: 0.6964 - val_Recall: 0.6190 - val_accuracy: 0.6797 - val_loss: 0.9343 - learning_rate: 1.0000e-07\n",
      "Epoch 117/200\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 156ms/step - AUC: 0.9030 - Precision: 0.7839 - Recall: 0.8492 - accuracy: 0.8091 - loss: 0.3922 - val_AUC: 0.6897 - val_Precision: 0.6964 - val_Recall: 0.6190 - val_accuracy: 0.6797 - val_loss: 0.9343 - learning_rate: 1.0000e-07\n",
      "Epoch 118/200\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 158ms/step - AUC: 0.8991 - Precision: 0.7910 - Recall: 0.8413 - accuracy: 0.8110 - loss: 0.4004 - val_AUC: 0.6897 - val_Precision: 0.6964 - val_Recall: 0.6190 - val_accuracy: 0.6797 - val_loss: 0.9343 - learning_rate: 1.0000e-07\n",
      "Epoch 119/200\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 156ms/step - AUC: 0.8985 - Precision: 0.7766 - Recall: 0.8413 - accuracy: 0.8012 - loss: 0.4013 - val_AUC: 0.6897 - val_Precision: 0.6964 - val_Recall: 0.6190 - val_accuracy: 0.6797 - val_loss: 0.9343 - learning_rate: 1.0000e-07\n",
      "Epoch 120/200\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 174ms/step - AUC: 0.9024 - Precision: 0.7847 - Recall: 0.8532 - accuracy: 0.8110 - loss: 0.3929 - val_AUC: 0.6897 - val_Precision: 0.6964 - val_Recall: 0.6190 - val_accuracy: 0.6797 - val_loss: 0.9343 - learning_rate: 1.0000e-07\n",
      "Epoch 121/200\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 155ms/step - AUC: 0.9014 - Precision: 0.7868 - Recall: 0.8492 - accuracy: 0.8110 - loss: 0.3971 - val_AUC: 0.6897 - val_Precision: 0.6964 - val_Recall: 0.6190 - val_accuracy: 0.6797 - val_loss: 0.9342 - learning_rate: 1.0000e-07\n",
      "Epoch 122/200\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 164ms/step - AUC: 0.8992 - Precision: 0.7940 - Recall: 0.8413 - accuracy: 0.8130 - loss: 0.4007 - val_AUC: 0.6897 - val_Precision: 0.6964 - val_Recall: 0.6190 - val_accuracy: 0.6797 - val_loss: 0.9343 - learning_rate: 1.0000e-07\n",
      "Epoch 123/200\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 150ms/step - AUC: 0.8937 - Precision: 0.7741 - Recall: 0.8294 - accuracy: 0.7953 - loss: 0.4064 - val_AUC: 0.6896 - val_Precision: 0.6964 - val_Recall: 0.6190 - val_accuracy: 0.6797 - val_loss: 0.9343 - learning_rate: 1.0000e-07\n",
      "Epoch 124/200\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 159ms/step - AUC: 0.9044 - Precision: 0.7903 - Recall: 0.8373 - accuracy: 0.8091 - loss: 0.3902 - val_AUC: 0.6896 - val_Precision: 0.6964 - val_Recall: 0.6190 - val_accuracy: 0.6797 - val_loss: 0.9343 - learning_rate: 1.0000e-07\n",
      "Epoch 125/200\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 163ms/step - AUC: 0.8931 - Precision: 0.7925 - Recall: 0.8333 - accuracy: 0.8091 - loss: 0.4095 - val_AUC: 0.6896 - val_Precision: 0.6964 - val_Recall: 0.6190 - val_accuracy: 0.6797 - val_loss: 0.9343 - learning_rate: 1.0000e-07\n",
      "Epoch 126/200\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 170ms/step - AUC: 0.9024 - Precision: 0.8022 - Recall: 0.8532 - accuracy: 0.8228 - loss: 0.3903 - val_AUC: 0.6897 - val_Precision: 0.6964 - val_Recall: 0.6190 - val_accuracy: 0.6797 - val_loss: 0.9343 - learning_rate: 1.0000e-07\n",
      "Epoch 127/200\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 163ms/step - AUC: 0.8912 - Precision: 0.7749 - Recall: 0.8333 - accuracy: 0.7972 - loss: 0.4106 - val_AUC: 0.6897 - val_Precision: 0.6964 - val_Recall: 0.6190 - val_accuracy: 0.6797 - val_loss: 0.9343 - learning_rate: 1.0000e-07\n",
      "Epoch 128/200\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 178ms/step - AUC: 0.8996 - Precision: 0.7897 - Recall: 0.8492 - accuracy: 0.8130 - loss: 0.3995 - val_AUC: 0.6897 - val_Precision: 0.6964 - val_Recall: 0.6190 - val_accuracy: 0.6797 - val_loss: 0.9343 - learning_rate: 1.0000e-07\n",
      "Epoch 129/200\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 169ms/step - AUC: 0.9002 - Precision: 0.8074 - Recall: 0.8651 - accuracy: 0.8307 - loss: 0.3955 - val_AUC: 0.6897 - val_Precision: 0.6964 - val_Recall: 0.6190 - val_accuracy: 0.6797 - val_loss: 0.9343 - learning_rate: 1.0000e-07\n",
      "Epoch 130/200\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 165ms/step - AUC: 0.9013 - Precision: 0.7897 - Recall: 0.8492 - accuracy: 0.8130 - loss: 0.3956 - val_AUC: 0.6897 - val_Precision: 0.6964 - val_Recall: 0.6190 - val_accuracy: 0.6797 - val_loss: 0.9344 - learning_rate: 1.0000e-07\n",
      "Epoch 131/200\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 170ms/step - AUC: 0.8982 - Precision: 0.7757 - Recall: 0.8373 - accuracy: 0.7992 - loss: 0.4006 - val_AUC: 0.6897 - val_Precision: 0.6964 - val_Recall: 0.6190 - val_accuracy: 0.6797 - val_loss: 0.9344 - learning_rate: 1.0000e-07\n",
      "Epoch 132/200\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 177ms/step - AUC: 0.9019 - Precision: 0.7993 - Recall: 0.8532 - accuracy: 0.8209 - loss: 0.3935 - val_AUC: 0.6897 - val_Precision: 0.6964 - val_Recall: 0.6190 - val_accuracy: 0.6797 - val_loss: 0.9344 - learning_rate: 1.0000e-07\n",
      "Epoch 133/200\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 169ms/step - AUC: 0.9035 - Precision: 0.8000 - Recall: 0.8571 - accuracy: 0.8228 - loss: 0.3905 - val_AUC: 0.6897 - val_Precision: 0.6964 - val_Recall: 0.6190 - val_accuracy: 0.6797 - val_loss: 0.9344 - learning_rate: 1.0000e-07\n",
      "Epoch 134/200\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 166ms/step - AUC: 0.9034 - Precision: 0.7897 - Recall: 0.8492 - accuracy: 0.8130 - loss: 0.3916 - val_AUC: 0.6897 - val_Precision: 0.6964 - val_Recall: 0.6190 - val_accuracy: 0.6797 - val_loss: 0.9344 - learning_rate: 1.0000e-07\n",
      "Epoch 135/200\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 154ms/step - AUC: 0.8940 - Precision: 0.7881 - Recall: 0.8413 - accuracy: 0.8091 - loss: 0.4076 - val_AUC: 0.6897 - val_Precision: 0.6964 - val_Recall: 0.6190 - val_accuracy: 0.6797 - val_loss: 0.9344 - learning_rate: 1.0000e-07\n",
      "Epoch 136/200\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 159ms/step - AUC: 0.8930 - Precision: 0.7912 - Recall: 0.8571 - accuracy: 0.8169 - loss: 0.4090 - val_AUC: 0.6897 - val_Precision: 0.6964 - val_Recall: 0.6190 - val_accuracy: 0.6797 - val_loss: 0.9344 - learning_rate: 1.0000e-07\n",
      "Epoch 137/200\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 158ms/step - AUC: 0.9045 - Precision: 0.8151 - Recall: 0.8571 - accuracy: 0.8327 - loss: 0.3900 - val_AUC: 0.6897 - val_Precision: 0.6964 - val_Recall: 0.6190 - val_accuracy: 0.6797 - val_loss: 0.9344 - learning_rate: 1.0000e-07\n",
      "Epoch 138/200\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 164ms/step - AUC: 0.8966 - Precision: 0.7786 - Recall: 0.8373 - accuracy: 0.8012 - loss: 0.4024 - val_AUC: 0.6897 - val_Precision: 0.6964 - val_Recall: 0.6190 - val_accuracy: 0.6797 - val_loss: 0.9344 - learning_rate: 1.0000e-07\n",
      "Epoch 139/200\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 154ms/step - AUC: 0.8984 - Precision: 0.7794 - Recall: 0.8413 - accuracy: 0.8031 - loss: 0.4005 - val_AUC: 0.6895 - val_Precision: 0.6964 - val_Recall: 0.6190 - val_accuracy: 0.6797 - val_loss: 0.9345 - learning_rate: 1.0000e-07\n",
      "Epoch 140/200\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 156ms/step - AUC: 0.8969 - Precision: 0.7895 - Recall: 0.8333 - accuracy: 0.8071 - loss: 0.4013 - val_AUC: 0.6897 - val_Precision: 0.6964 - val_Recall: 0.6190 - val_accuracy: 0.6797 - val_loss: 0.9344 - learning_rate: 1.0000e-07\n",
      "Epoch 141/200\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 160ms/step - AUC: 0.8961 - Precision: 0.7881 - Recall: 0.8413 - accuracy: 0.8091 - loss: 0.4030 - val_AUC: 0.6897 - val_Precision: 0.6964 - val_Recall: 0.6190 - val_accuracy: 0.6797 - val_loss: 0.9345 - learning_rate: 1.0000e-07\n",
      "Epoch 142/200\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 177ms/step - AUC: 0.9021 - Precision: 0.7993 - Recall: 0.8532 - accuracy: 0.8209 - loss: 0.3962 - val_AUC: 0.6897 - val_Precision: 0.6964 - val_Recall: 0.6190 - val_accuracy: 0.6797 - val_loss: 0.9345 - learning_rate: 1.0000e-07\n",
      "Epoch 143/200\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 161ms/step - AUC: 0.8952 - Precision: 0.7925 - Recall: 0.8333 - accuracy: 0.8091 - loss: 0.4064 - val_AUC: 0.6897 - val_Precision: 0.6964 - val_Recall: 0.6190 - val_accuracy: 0.6797 - val_loss: 0.9345 - learning_rate: 1.0000e-07\n",
      "Epoch 144/200\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 168ms/step - AUC: 0.8941 - Precision: 0.7985 - Recall: 0.8333 - accuracy: 0.8130 - loss: 0.4079 - val_AUC: 0.6897 - val_Precision: 0.6964 - val_Recall: 0.6190 - val_accuracy: 0.6797 - val_loss: 0.9345 - learning_rate: 1.0000e-07\n",
      "Epoch 145/200\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 157ms/step - AUC: 0.8998 - Precision: 0.8000 - Recall: 0.8413 - accuracy: 0.8169 - loss: 0.3965 - val_AUC: 0.6897 - val_Precision: 0.6964 - val_Recall: 0.6190 - val_accuracy: 0.6797 - val_loss: 0.9345 - learning_rate: 1.0000e-07\n",
      "Epoch 146/200\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 158ms/step - AUC: 0.9049 - Precision: 0.8007 - Recall: 0.8770 - accuracy: 0.8307 - loss: 0.3893 - val_AUC: 0.6897 - val_Precision: 0.6964 - val_Recall: 0.6190 - val_accuracy: 0.6797 - val_loss: 0.9345 - learning_rate: 1.0000e-07\n",
      "Epoch 147/200\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 159ms/step - AUC: 0.8956 - Precision: 0.7901 - Recall: 0.8214 - accuracy: 0.8031 - loss: 0.4066 - val_AUC: 0.6897 - val_Precision: 0.6964 - val_Recall: 0.6190 - val_accuracy: 0.6797 - val_loss: 0.9345 - learning_rate: 1.0000e-07\n",
      "Epoch 148/200\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 165ms/step - AUC: 0.8940 - Precision: 0.7766 - Recall: 0.8413 - accuracy: 0.8012 - loss: 0.4052 - val_AUC: 0.6897 - val_Precision: 0.6964 - val_Recall: 0.6190 - val_accuracy: 0.6797 - val_loss: 0.9345 - learning_rate: 1.0000e-07\n",
      "Epoch 149/200\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 166ms/step - AUC: 0.8987 - Precision: 0.7875 - Recall: 0.8532 - accuracy: 0.8130 - loss: 0.4004 - val_AUC: 0.6897 - val_Precision: 0.6964 - val_Recall: 0.6190 - val_accuracy: 0.6797 - val_loss: 0.9345 - learning_rate: 1.0000e-07\n",
      "Epoch 150/200\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 193ms/step - AUC: 0.8938 - Precision: 0.7852 - Recall: 0.8413 - accuracy: 0.8071 - loss: 0.4063 - val_AUC: 0.6897 - val_Precision: 0.6964 - val_Recall: 0.6190 - val_accuracy: 0.6797 - val_loss: 0.9345 - learning_rate: 1.0000e-07\n",
      "Epoch 151/200\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 171ms/step - AUC: 0.9031 - Precision: 0.8053 - Recall: 0.8373 - accuracy: 0.8189 - loss: 0.3915 - val_AUC: 0.6897 - val_Precision: 0.6964 - val_Recall: 0.6190 - val_accuracy: 0.6797 - val_loss: 0.9345 - learning_rate: 1.0000e-07\n",
      "Epoch 152/200\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 166ms/step - AUC: 0.8985 - Precision: 0.7948 - Recall: 0.8452 - accuracy: 0.8150 - loss: 0.3993 - val_AUC: 0.6897 - val_Precision: 0.6964 - val_Recall: 0.6190 - val_accuracy: 0.6797 - val_loss: 0.9345 - learning_rate: 1.0000e-07\n",
      "Epoch 153/200\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 156ms/step - AUC: 0.9009 - Precision: 0.7762 - Recall: 0.8532 - accuracy: 0.8051 - loss: 0.3956 - val_AUC: 0.6897 - val_Precision: 0.6964 - val_Recall: 0.6190 - val_accuracy: 0.6797 - val_loss: 0.9345 - learning_rate: 1.0000e-07\n",
      "Epoch 154/200\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 174ms/step - AUC: 0.9021 - Precision: 0.7802 - Recall: 0.8452 - accuracy: 0.8051 - loss: 0.3954 - val_AUC: 0.6897 - val_Precision: 0.6964 - val_Recall: 0.6190 - val_accuracy: 0.6797 - val_loss: 0.9345 - learning_rate: 1.0000e-07\n",
      "Epoch 155/200\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 161ms/step - AUC: 0.8973 - Precision: 0.7912 - Recall: 0.8571 - accuracy: 0.8169 - loss: 0.4052 - val_AUC: 0.6897 - val_Precision: 0.6964 - val_Recall: 0.6190 - val_accuracy: 0.6797 - val_loss: 0.9345 - learning_rate: 1.0000e-07\n",
      "Epoch 156/200\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 169ms/step - AUC: 0.9102 - Precision: 0.7899 - Recall: 0.8651 - accuracy: 0.8189 - loss: 0.3771 - val_AUC: 0.6897 - val_Precision: 0.6964 - val_Recall: 0.6190 - val_accuracy: 0.6797 - val_loss: 0.9345 - learning_rate: 1.0000e-07\n",
      "Epoch 157/200\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 164ms/step - AUC: 0.8996 - Precision: 0.7910 - Recall: 0.8413 - accuracy: 0.8110 - loss: 0.3961 - val_AUC: 0.6897 - val_Precision: 0.6964 - val_Recall: 0.6190 - val_accuracy: 0.6797 - val_loss: 0.9345 - learning_rate: 1.0000e-07\n",
      "Epoch 158/200\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 162ms/step - AUC: 0.8978 - Precision: 0.7897 - Recall: 0.8492 - accuracy: 0.8130 - loss: 0.4002 - val_AUC: 0.6897 - val_Precision: 0.6964 - val_Recall: 0.6190 - val_accuracy: 0.6797 - val_loss: 0.9345 - learning_rate: 1.0000e-07\n",
      "Epoch 159/200\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 163ms/step - AUC: 0.8983 - Precision: 0.7948 - Recall: 0.8452 - accuracy: 0.8150 - loss: 0.4016 - val_AUC: 0.6897 - val_Precision: 0.6964 - val_Recall: 0.6190 - val_accuracy: 0.6797 - val_loss: 0.9345 - learning_rate: 1.0000e-07\n",
      "Epoch 160/200\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 170ms/step - AUC: 0.8957 - Precision: 0.7918 - Recall: 0.8452 - accuracy: 0.8130 - loss: 0.4042 - val_AUC: 0.6897 - val_Precision: 0.6964 - val_Recall: 0.6190 - val_accuracy: 0.6797 - val_loss: 0.9345 - learning_rate: 1.0000e-07\n",
      "Epoch 161/200\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 164ms/step - AUC: 0.8962 - Precision: 0.7852 - Recall: 0.8413 - accuracy: 0.8071 - loss: 0.4024 - val_AUC: 0.6897 - val_Precision: 0.6964 - val_Recall: 0.6190 - val_accuracy: 0.6797 - val_loss: 0.9345 - learning_rate: 1.0000e-07\n",
      "Epoch 162/200\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 160ms/step - AUC: 0.8945 - Precision: 0.7868 - Recall: 0.8492 - accuracy: 0.8110 - loss: 0.4033 - val_AUC: 0.6897 - val_Precision: 0.6964 - val_Recall: 0.6190 - val_accuracy: 0.6797 - val_loss: 0.9345 - learning_rate: 1.0000e-07\n",
      "Epoch 163/200\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 172ms/step - AUC: 0.8969 - Precision: 0.7844 - Recall: 0.8373 - accuracy: 0.8051 - loss: 0.4057 - val_AUC: 0.6897 - val_Precision: 0.6964 - val_Recall: 0.6190 - val_accuracy: 0.6797 - val_loss: 0.9345 - learning_rate: 1.0000e-07\n",
      "Epoch 164/200\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 168ms/step - AUC: 0.9022 - Precision: 0.7955 - Recall: 0.8492 - accuracy: 0.8169 - loss: 0.3952 - val_AUC: 0.6897 - val_Precision: 0.6964 - val_Recall: 0.6190 - val_accuracy: 0.6797 - val_loss: 0.9345 - learning_rate: 1.0000e-07\n",
      "Epoch 165/200\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 186ms/step - AUC: 0.9013 - Precision: 0.7941 - Recall: 0.8571 - accuracy: 0.8189 - loss: 0.3941 - val_AUC: 0.6897 - val_Precision: 0.6964 - val_Recall: 0.6190 - val_accuracy: 0.6797 - val_loss: 0.9345 - learning_rate: 1.0000e-07\n",
      "Epoch 166/200\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 164ms/step - AUC: 0.8966 - Precision: 0.7910 - Recall: 0.8413 - accuracy: 0.8110 - loss: 0.4049 - val_AUC: 0.6897 - val_Precision: 0.6964 - val_Recall: 0.6190 - val_accuracy: 0.6797 - val_loss: 0.9345 - learning_rate: 1.0000e-07\n",
      "Epoch 167/200\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 171ms/step - AUC: 0.8918 - Precision: 0.7810 - Recall: 0.8492 - accuracy: 0.8071 - loss: 0.4091 - val_AUC: 0.6897 - val_Precision: 0.6964 - val_Recall: 0.6190 - val_accuracy: 0.6797 - val_loss: 0.9346 - learning_rate: 1.0000e-07\n",
      "Epoch 168/200\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 159ms/step - AUC: 0.8978 - Precision: 0.7955 - Recall: 0.8492 - accuracy: 0.8169 - loss: 0.3988 - val_AUC: 0.6897 - val_Precision: 0.6964 - val_Recall: 0.6190 - val_accuracy: 0.6797 - val_loss: 0.9346 - learning_rate: 1.0000e-07\n",
      "Epoch 169/200\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 166ms/step - AUC: 0.9034 - Precision: 0.7897 - Recall: 0.8492 - accuracy: 0.8130 - loss: 0.3928 - val_AUC: 0.6897 - val_Precision: 0.6964 - val_Recall: 0.6190 - val_accuracy: 0.6797 - val_loss: 0.9346 - learning_rate: 1.0000e-07\n",
      "Epoch 170/200\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 164ms/step - AUC: 0.8942 - Precision: 0.7963 - Recall: 0.8532 - accuracy: 0.8189 - loss: 0.4048 - val_AUC: 0.6897 - val_Precision: 0.6964 - val_Recall: 0.6190 - val_accuracy: 0.6797 - val_loss: 0.9346 - learning_rate: 1.0000e-07\n",
      "Epoch 171/200\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 175ms/step - AUC: 0.8993 - Precision: 0.8045 - Recall: 0.8492 - accuracy: 0.8228 - loss: 0.3985 - val_AUC: 0.6897 - val_Precision: 0.6964 - val_Recall: 0.6190 - val_accuracy: 0.6797 - val_loss: 0.9346 - learning_rate: 1.0000e-07\n",
      "Epoch 172/200\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 158ms/step - AUC: 0.8986 - Precision: 0.7948 - Recall: 0.8452 - accuracy: 0.8150 - loss: 0.3962 - val_AUC: 0.6897 - val_Precision: 0.6964 - val_Recall: 0.6190 - val_accuracy: 0.6797 - val_loss: 0.9346 - learning_rate: 1.0000e-07\n",
      "Epoch 173/200\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 165ms/step - AUC: 0.8972 - Precision: 0.7831 - Recall: 0.8452 - accuracy: 0.8071 - loss: 0.4014 - val_AUC: 0.6899 - val_Precision: 0.6964 - val_Recall: 0.6190 - val_accuracy: 0.6797 - val_loss: 0.9346 - learning_rate: 1.0000e-07\n",
      "Epoch 174/200\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 168ms/step - AUC: 0.9002 - Precision: 0.7955 - Recall: 0.8492 - accuracy: 0.8169 - loss: 0.3971 - val_AUC: 0.6899 - val_Precision: 0.6964 - val_Recall: 0.6190 - val_accuracy: 0.6797 - val_loss: 0.9347 - learning_rate: 1.0000e-07\n",
      "Epoch 175/200\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 175ms/step - AUC: 0.8958 - Precision: 0.7917 - Recall: 0.8294 - accuracy: 0.8071 - loss: 0.4036 - val_AUC: 0.6896 - val_Precision: 0.6964 - val_Recall: 0.6190 - val_accuracy: 0.6797 - val_loss: 0.9347 - learning_rate: 1.0000e-07\n",
      "Epoch 176/200\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 159ms/step - AUC: 0.8987 - Precision: 0.7903 - Recall: 0.8373 - accuracy: 0.8091 - loss: 0.3993 - val_AUC: 0.6896 - val_Precision: 0.6964 - val_Recall: 0.6190 - val_accuracy: 0.6797 - val_loss: 0.9347 - learning_rate: 1.0000e-07\n",
      "Epoch 177/200\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 165ms/step - AUC: 0.9002 - Precision: 0.7895 - Recall: 0.8333 - accuracy: 0.8071 - loss: 0.4000 - val_AUC: 0.6896 - val_Precision: 0.6964 - val_Recall: 0.6190 - val_accuracy: 0.6797 - val_loss: 0.9347 - learning_rate: 1.0000e-07\n",
      "Epoch 178/200\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 156ms/step - AUC: 0.8974 - Precision: 0.7865 - Recall: 0.8333 - accuracy: 0.8051 - loss: 0.4019 - val_AUC: 0.6896 - val_Precision: 0.6964 - val_Recall: 0.6190 - val_accuracy: 0.6797 - val_loss: 0.9347 - learning_rate: 1.0000e-07\n",
      "Epoch 179/200\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 170ms/step - AUC: 0.8991 - Precision: 0.7786 - Recall: 0.8373 - accuracy: 0.8012 - loss: 0.3973 - val_AUC: 0.6896 - val_Precision: 0.6964 - val_Recall: 0.6190 - val_accuracy: 0.6797 - val_loss: 0.9347 - learning_rate: 1.0000e-07\n",
      "Epoch 180/200\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 174ms/step - AUC: 0.8912 - Precision: 0.7934 - Recall: 0.8532 - accuracy: 0.8169 - loss: 0.4138 - val_AUC: 0.6899 - val_Precision: 0.6964 - val_Recall: 0.6190 - val_accuracy: 0.6797 - val_loss: 0.9347 - learning_rate: 1.0000e-07\n",
      "Epoch 181/200\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 156ms/step - AUC: 0.9018 - Precision: 0.7883 - Recall: 0.8571 - accuracy: 0.8150 - loss: 0.3954 - val_AUC: 0.6896 - val_Precision: 0.6964 - val_Recall: 0.6190 - val_accuracy: 0.6797 - val_loss: 0.9347 - learning_rate: 1.0000e-07\n",
      "Epoch 182/200\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 136ms/step - AUC: 0.9006 - Precision: 0.7873 - Recall: 0.8373 - accuracy: 0.8071 - loss: 0.3913 - val_AUC: 0.6896 - val_Precision: 0.6964 - val_Recall: 0.6190 - val_accuracy: 0.6797 - val_loss: 0.9347 - learning_rate: 1.0000e-07\n",
      "Epoch 183/200\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 179ms/step - AUC: 0.8956 - Precision: 0.7881 - Recall: 0.8413 - accuracy: 0.8091 - loss: 0.4021 - val_AUC: 0.6895 - val_Precision: 0.6964 - val_Recall: 0.6190 - val_accuracy: 0.6797 - val_loss: 0.9347 - learning_rate: 1.0000e-07\n",
      "Epoch 184/200\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 165ms/step - AUC: 0.8956 - Precision: 0.7910 - Recall: 0.8413 - accuracy: 0.8110 - loss: 0.4061 - val_AUC: 0.6895 - val_Precision: 0.6964 - val_Recall: 0.6190 - val_accuracy: 0.6797 - val_loss: 0.9347 - learning_rate: 1.0000e-07\n",
      "Epoch 185/200\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 131ms/step - AUC: 0.8964 - Precision: 0.7807 - Recall: 0.8333 - accuracy: 0.8012 - loss: 0.4028 - val_AUC: 0.6896 - val_Precision: 0.6964 - val_Recall: 0.6190 - val_accuracy: 0.6797 - val_loss: 0.9347 - learning_rate: 1.0000e-07\n",
      "Epoch 186/200\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 138ms/step - AUC: 0.9016 - Precision: 0.7868 - Recall: 0.8492 - accuracy: 0.8110 - loss: 0.3954 - val_AUC: 0.6896 - val_Precision: 0.6964 - val_Recall: 0.6190 - val_accuracy: 0.6797 - val_loss: 0.9347 - learning_rate: 1.0000e-07\n",
      "Epoch 187/200\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 152ms/step - AUC: 0.9027 - Precision: 0.7862 - Recall: 0.8611 - accuracy: 0.8150 - loss: 0.3931 - val_AUC: 0.6899 - val_Precision: 0.6964 - val_Recall: 0.6190 - val_accuracy: 0.6797 - val_loss: 0.9347 - learning_rate: 1.0000e-07\n",
      "Epoch 188/200\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 157ms/step - AUC: 0.8999 - Precision: 0.7926 - Recall: 0.8492 - accuracy: 0.8150 - loss: 0.3955 - val_AUC: 0.6899 - val_Precision: 0.6964 - val_Recall: 0.6190 - val_accuracy: 0.6797 - val_loss: 0.9347 - learning_rate: 1.0000e-07\n",
      "Epoch 189/200\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 183ms/step - AUC: 0.9020 - Precision: 0.8007 - Recall: 0.8770 - accuracy: 0.8307 - loss: 0.3920 - val_AUC: 0.6899 - val_Precision: 0.6964 - val_Recall: 0.6190 - val_accuracy: 0.6797 - val_loss: 0.9347 - learning_rate: 1.0000e-07\n",
      "Epoch 190/200\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 166ms/step - AUC: 0.8989 - Precision: 0.7901 - Recall: 0.8214 - accuracy: 0.8031 - loss: 0.3979 - val_AUC: 0.6899 - val_Precision: 0.6964 - val_Recall: 0.6190 - val_accuracy: 0.6797 - val_loss: 0.9347 - learning_rate: 1.0000e-07\n",
      "Epoch 191/200\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 179ms/step - AUC: 0.9000 - Precision: 0.7891 - Recall: 0.8611 - accuracy: 0.8169 - loss: 0.3993 - val_AUC: 0.6899 - val_Precision: 0.6964 - val_Recall: 0.6190 - val_accuracy: 0.6797 - val_loss: 0.9348 - learning_rate: 1.0000e-07\n",
      "Epoch 192/200\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 178ms/step - AUC: 0.9041 - Precision: 0.8029 - Recall: 0.8730 - accuracy: 0.8307 - loss: 0.3875 - val_AUC: 0.6899 - val_Precision: 0.6964 - val_Recall: 0.6190 - val_accuracy: 0.6797 - val_loss: 0.9348 - learning_rate: 1.0000e-07\n",
      "Epoch 193/200\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 213ms/step - AUC: 0.9043 - Precision: 0.7948 - Recall: 0.8452 - accuracy: 0.8150 - loss: 0.3891 - val_AUC: 0.6899 - val_Precision: 0.6964 - val_Recall: 0.6190 - val_accuracy: 0.6797 - val_loss: 0.9348 - learning_rate: 1.0000e-07\n",
      "Epoch 194/200\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 228ms/step - AUC: 0.9036 - Precision: 0.7963 - Recall: 0.8532 - accuracy: 0.8189 - loss: 0.3925 - val_AUC: 0.6899 - val_Precision: 0.6964 - val_Recall: 0.6190 - val_accuracy: 0.6797 - val_loss: 0.9348 - learning_rate: 1.0000e-07\n",
      "Epoch 195/200\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 177ms/step - AUC: 0.9019 - Precision: 0.7912 - Recall: 0.8571 - accuracy: 0.8169 - loss: 0.3942 - val_AUC: 0.6901 - val_Precision: 0.6964 - val_Recall: 0.6190 - val_accuracy: 0.6797 - val_loss: 0.9348 - learning_rate: 1.0000e-07\n",
      "Epoch 196/200\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 183ms/step - AUC: 0.9019 - Precision: 0.8037 - Recall: 0.8611 - accuracy: 0.8268 - loss: 0.3927 - val_AUC: 0.6901 - val_Precision: 0.6964 - val_Recall: 0.6190 - val_accuracy: 0.6797 - val_loss: 0.9348 - learning_rate: 1.0000e-07\n",
      "Epoch 197/200\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 162ms/step - AUC: 0.9005 - Precision: 0.7948 - Recall: 0.8452 - accuracy: 0.8150 - loss: 0.3934 - val_AUC: 0.6901 - val_Precision: 0.6964 - val_Recall: 0.6190 - val_accuracy: 0.6797 - val_loss: 0.9348 - learning_rate: 1.0000e-07\n",
      "Epoch 198/200\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 163ms/step - AUC: 0.9039 - Precision: 0.7948 - Recall: 0.8452 - accuracy: 0.8150 - loss: 0.3873 - val_AUC: 0.6901 - val_Precision: 0.6964 - val_Recall: 0.6190 - val_accuracy: 0.6797 - val_loss: 0.9348 - learning_rate: 1.0000e-07\n",
      "Epoch 199/200\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 129ms/step - AUC: 0.8989 - Precision: 0.7963 - Recall: 0.8532 - accuracy: 0.8189 - loss: 0.4029 - val_AUC: 0.6901 - val_Precision: 0.6964 - val_Recall: 0.6190 - val_accuracy: 0.6797 - val_loss: 0.9348 - learning_rate: 1.0000e-07\n",
      "Epoch 200/200\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 125ms/step - AUC: 0.9007 - Precision: 0.7992 - Recall: 0.8373 - accuracy: 0.8150 - loss: 0.3999 - val_AUC: 0.6901 - val_Precision: 0.6964 - val_Recall: 0.6190 - val_accuracy: 0.6797 - val_loss: 0.9348 - learning_rate: 1.0000e-07\n"
     ]
    }
   ],
   "source": [
    "# CELL 5 - Train & Evaluasi\n",
    "# Class weight\n",
    "classes = np.unique(y_train)\n",
    "weights = compute_class_weight('balanced', classes=classes, y=y_train)\n",
    "class_weight_dict = {0: weights[0], 1: weights[1]}\n",
    "print(f\"Class weights: {class_weight_dict}\")\n",
    "\n",
    "# Callbacks\n",
    "callbacks = [\n",
    "    EarlyStopping(monitor='val_auc', mode='max', patience=15, restore_best_weights=True, verbose=1),\n",
    "    ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=5, min_lr=1e-7, verbose=1),\n",
    "    ModelCheckpoint('best_smiles2vec.keras', monitor='val_auc', mode='max', save_best_only=True, verbose=1)\n",
    "]\n",
    "\n",
    "# Build & Train\n",
    "model = build_model(\n",
    "    embedding_dim=64,\n",
    "    use_conv=False,        # pure SMILES2Vec\n",
    "    lstm_units=128,\n",
    "    dropout_rate=0.5,\n",
    "    learning_rate=0.001\n",
    ")\n",
    "\n",
    "history = model.fit(\n",
    "    X_train, y_train,\n",
    "    validation_data=(X_test, y_test),\n",
    "    epochs=200,\n",
    "    batch_size=32,\n",
    "    class_weight=class_weight_dict,\n",
    "    callbacks=callbacks,\n",
    "    verbose=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "24a5749b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step\n",
      "\n",
      "=== SMILES2VEC + LSTM (BASE) ===\n",
      "ROC-AUC: 0.6916\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     Neutral       0.67      0.74      0.70        65\n",
      "   Inhibitor       0.70      0.62      0.66        63\n",
      "\n",
      "    accuracy                           0.68       128\n",
      "   macro avg       0.68      0.68      0.68       128\n",
      "weighted avg       0.68      0.68      0.68       128\n",
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 500x400 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# CELL 6 - Evaluasi Lengkap\n",
    "from tensorflow.keras.models import load_model\n",
    "model = load_model('best_smiles2vec.keras')\n",
    "\n",
    "y_pred_prob = model.predict(X_test).flatten()\n",
    "y_pred = (y_pred_prob > 0.5).astype(int)\n",
    "\n",
    "print(\"\\n=== SMILES2VEC + LSTM (BASE) ===\")\n",
    "print(f\"ROC-AUC: {roc_auc_score(y_test, y_pred_prob):.4f}\")\n",
    "print(classification_report(y_test, y_pred, target_names=['Neutral', 'Inhibitor']))\n",
    "\n",
    "# Confusion Matrix\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "plt.figure(figsize=(5,4))\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues',\n",
    "            xticklabels=['Neutral', 'Inhibitor'],\n",
    "            yticklabels=['Neutral', 'Inhibitor'])\n",
    "plt.ylabel('True')\n",
    "plt.xlabel('Predicted')\n",
    "plt.title('Confusion Matrix - SMILES2Vec')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc2f6434",
   "metadata": {},
   "source": [
    "# C\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "469bbc2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CELL 1 - Import\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Embedding, Conv1D, LSTM, Dense, Dropout, BatchNormalization\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau, ModelCheckpoint\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "from sklearn.metrics import classification_report, confusion_matrix, roc_auc_score\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "a243dbde",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Distribusi label:\n",
      "target\n",
      "0    0.504717\n",
      "1    0.495283\n",
      "Name: proportion, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# CELL 2 - Load & Preprocess\n",
    "df = pd.read_csv('/home/dito-adistya/Dito/TA/Coding/LSTM-MBA/data/GSARPC3.csv')\n",
    "df['smiles'] = df['smiles'].str.upper()\n",
    "\n",
    "# Encode label\n",
    "df['target'] = df['categories'].apply(lambda x: 1 if x == \"inhibitor\" else 0)\n",
    "print(\"Distribusi label:\")\n",
    "print(df['target'].value_counts(normalize=True))\n",
    "\n",
    "# Stratified split\n",
    "df_train, df_test = train_test_split(\n",
    "    df, test_size=0.2, random_state=42, stratify=df['target']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "1b1f875b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train: (508, 168) | vocab: 28 | max_len: 168\n"
     ]
    }
   ],
   "source": [
    "# CELL 3 - SMILES → Integer Sequence (WITH PADDING & mask_zero)\n",
    "all_chars = set(''.join(df['smiles']))\n",
    "charset = sorted(all_chars)\n",
    "char_to_int = {c: i+1 for i, c in enumerate(charset)}  # 1,2,3,...\n",
    "char_to_int['<PAD>'] = 0  # padding token\n",
    "vocab_size = len(char_to_int)\n",
    "\n",
    "MAX_LEN = min(250, max(len(s) for s in df['smiles']) + 5)\n",
    "\n",
    "def smiles_to_seq(smiles_list, max_len):\n",
    "    seqs = []\n",
    "    for s in smiles_list:\n",
    "        seq = [char_to_int.get(c, 0) for c in s]\n",
    "        if len(seq) > max_len:\n",
    "            seq = seq[:max_len]\n",
    "        else:\n",
    "            seq += [0] * (max_len - len(seq))  # PAD\n",
    "        seqs.append(seq)\n",
    "    return np.array(seqs, dtype=np.int32)\n",
    "\n",
    "X_train = smiles_to_seq(df_train['smiles'].tolist(), MAX_LEN)\n",
    "X_test = smiles_to_seq(df_test['smiles'].tolist(), MAX_LEN)\n",
    "y_train = df_train['target'].values.astype(np.float32)\n",
    "y_test = df_test['target'].values.astype(np.float32)\n",
    "\n",
    "print(f\"X_train: {X_train.shape} | vocab: {vocab_size} | max_len: {MAX_LEN}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13f15391",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CELL 4 - FIXED MODEL (NO BUG, RINGKAS, KUAT)\n",
    "def build_model(\n",
    "    embedding_dim=128,\n",
    "    use_conv=True,\n",
    "    conv_filters=64,\n",
    "    conv_kernel_size=5,\n",
    "    lstm_units=128,      # cukup untuk 636 data\n",
    "    dropout_rate=0.5,\n",
    "    learning_rate=0.001  # mulai lebih tinggi!\n",
    "):\n",
    "    model = Sequential()\n",
    "    \n",
    "    model.add(Embedding(\n",
    "        input_dim=vocab_size,\n",
    "        output_dim=embedding_dim,\n",
    "        input_length=MAX_LEN,\n",
    "        mask_zero=True\n",
    "    ))\n",
    "    \n",
    "    if use_conv:\n",
    "        model.add(Conv1D(conv_filters, conv_kernel_size, activation='relu', padding='same'))\n",
    "        model.add(BatchNormalization())\n",
    "    \n",
    "    # HANYA 1 LSTM → RINGKAS & STABIL\n",
    "    model.add(LSTM(lstm_units, return_sequences=False))\n",
    "    model.add(Dropout(dropout_rate))\n",
    "    model.add(Dense(64, activation='relu'))\n",
    "    model.add(Dropout(dropout_rate))\n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "    model.compile(\n",
    "        optimizer=Adam(learning_rate=learning_rate),\n",
    "        loss='binary_crossentropy',\n",
    "        metrics=['accuracy', 'AUC']\n",
    "    )\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "0ab8ee50",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/dito-adistya/miniconda3/envs/py311/lib/python3.11/site-packages/keras/src/layers/core/embedding.py:97: UserWarning: Argument `input_length` is deprecated. Just remove it.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 293ms/step - AUC: 0.5144 - Precision: 0.5172 - Recall: 0.4167 - accuracy: 0.5177 - loss: 0.6930 - val_AUC: 0.5796 - val_Precision: 0.5469 - val_Recall: 0.5556 - val_accuracy: 0.5547 - val_loss: 0.6907 - learning_rate: 0.0010\n",
      "Epoch 2/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/dito-adistya/miniconda3/envs/py311/lib/python3.11/site-packages/keras/src/callbacks/early_stopping.py:99: UserWarning: Early stopping conditioned on metric `val_auc` which is not available. Available metrics are: AUC,Precision,Recall,accuracy,loss,val_AUC,val_Precision,val_Recall,val_accuracy,val_loss\n",
      "  current = self.get_monitor_value(logs)\n",
      "/home/dito-adistya/miniconda3/envs/py311/lib/python3.11/site-packages/keras/src/callbacks/model_checkpoint.py:276: UserWarning: Can save best model only with val_auc available.\n",
      "  if self._should_save_model(epoch, batch, logs, filepath):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 233ms/step - AUC: 0.5418 - Precision: 0.5188 - Recall: 0.5476 - accuracy: 0.5236 - loss: 0.6902 - val_AUC: 0.6239 - val_Precision: 0.5600 - val_Recall: 0.6667 - val_accuracy: 0.5781 - val_loss: 0.6851 - learning_rate: 0.0010\n",
      "Epoch 3/100\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 246ms/step - AUC: 0.5754 - Precision: 0.5594 - Recall: 0.5794 - accuracy: 0.5650 - loss: 0.6853 - val_AUC: 0.6418 - val_Precision: 0.5634 - val_Recall: 0.6349 - val_accuracy: 0.5781 - val_loss: 0.6715 - learning_rate: 0.0010\n",
      "Epoch 4/100\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 237ms/step - AUC: 0.6096 - Precision: 0.5887 - Recall: 0.5794 - accuracy: 0.5906 - loss: 0.6770 - val_AUC: 0.6656 - val_Precision: 0.5909 - val_Recall: 0.6190 - val_accuracy: 0.6016 - val_loss: 0.6661 - learning_rate: 0.0010\n",
      "Epoch 5/100\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 261ms/step - AUC: 0.6538 - Precision: 0.5793 - Recall: 0.7976 - accuracy: 0.6122 - loss: 0.6705 - val_AUC: 0.6736 - val_Precision: 0.6182 - val_Recall: 0.5397 - val_accuracy: 0.6094 - val_loss: 0.6509 - learning_rate: 0.0010\n",
      "Epoch 6/100\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 273ms/step - AUC: 0.6767 - Precision: 0.6226 - Recall: 0.6548 - accuracy: 0.6319 - loss: 0.6450 - val_AUC: 0.6696 - val_Precision: 0.6129 - val_Recall: 0.6032 - val_accuracy: 0.6172 - val_loss: 0.6489 - learning_rate: 0.0010\n",
      "Epoch 7/100\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 235ms/step - AUC: 0.6927 - Precision: 0.6411 - Recall: 0.7302 - accuracy: 0.6634 - loss: 0.6379 - val_AUC: 0.6868 - val_Precision: 0.7000 - val_Recall: 0.5556 - val_accuracy: 0.6641 - val_loss: 0.6276 - learning_rate: 0.0010\n",
      "Epoch 8/100\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 257ms/step - AUC: 0.7134 - Precision: 0.6557 - Recall: 0.6349 - accuracy: 0.6535 - loss: 0.6225 - val_AUC: 0.6648 - val_Precision: 0.6271 - val_Recall: 0.5873 - val_accuracy: 0.6250 - val_loss: 0.6452 - learning_rate: 0.0010\n",
      "Epoch 9/100\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 287ms/step - AUC: 0.7115 - Precision: 0.6264 - Recall: 0.6786 - accuracy: 0.6398 - loss: 0.6254 - val_AUC: 0.6923 - val_Precision: 0.6800 - val_Recall: 0.5397 - val_accuracy: 0.6484 - val_loss: 0.6258 - learning_rate: 0.0010\n",
      "Epoch 10/100\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 269ms/step - AUC: 0.7277 - Precision: 0.6426 - Recall: 0.7063 - accuracy: 0.6594 - loss: 0.6116 - val_AUC: 0.6847 - val_Precision: 0.6604 - val_Recall: 0.5556 - val_accuracy: 0.6406 - val_loss: 0.6334 - learning_rate: 0.0010\n",
      "Epoch 11/100\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 270ms/step - AUC: 0.7531 - Precision: 0.6667 - Recall: 0.7143 - accuracy: 0.6811 - loss: 0.5867 - val_AUC: 0.6907 - val_Precision: 0.6731 - val_Recall: 0.5556 - val_accuracy: 0.6484 - val_loss: 0.6276 - learning_rate: 0.0010\n",
      "Epoch 12/100\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 270ms/step - AUC: 0.7533 - Precision: 0.6968 - Recall: 0.6111 - accuracy: 0.6752 - loss: 0.5925 - val_AUC: 0.6961 - val_Precision: 0.7368 - val_Recall: 0.4444 - val_accuracy: 0.6484 - val_loss: 0.6475 - learning_rate: 0.0010\n",
      "Epoch 13/100\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 279ms/step - AUC: 0.7576 - Precision: 0.6619 - Recall: 0.7381 - accuracy: 0.6831 - loss: 0.5897 - val_AUC: 0.6773 - val_Precision: 0.6744 - val_Recall: 0.4603 - val_accuracy: 0.6250 - val_loss: 0.6508 - learning_rate: 0.0010\n",
      "Epoch 14/100\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 216ms/step - AUC: 0.7825 - Precision: 0.7269 - Recall: 0.6548 - accuracy: 0.7067 - loss: 0.5601 - val_AUC: 0.6941 - val_Precision: 0.7381 - val_Recall: 0.4921 - val_accuracy: 0.6641 - val_loss: 0.6434 - learning_rate: 0.0010\n",
      "Epoch 15/100\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 217ms/step - AUC: 0.8108 - Precision: 0.7356 - Recall: 0.7619 - accuracy: 0.7461 - loss: 0.5352 - val_AUC: 0.7081 - val_Precision: 0.7083 - val_Recall: 0.5397 - val_accuracy: 0.6641 - val_loss: 0.6422 - learning_rate: 0.0010\n",
      "Epoch 16/100\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 224ms/step - AUC: 0.8151 - Precision: 0.7434 - Recall: 0.6667 - accuracy: 0.7205 - loss: 0.5265 - val_AUC: 0.7084 - val_Precision: 0.7250 - val_Recall: 0.4603 - val_accuracy: 0.6484 - val_loss: 0.6159 - learning_rate: 0.0010\n",
      "Epoch 17/100\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 267ms/step - AUC: 0.7947 - Precision: 0.7008 - Recall: 0.7063 - accuracy: 0.7047 - loss: 0.5470 - val_AUC: 0.7183 - val_Precision: 0.7619 - val_Recall: 0.5079 - val_accuracy: 0.6797 - val_loss: 0.6303 - learning_rate: 0.0010\n",
      "Epoch 18/100\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 231ms/step - AUC: 0.8347 - Precision: 0.7806 - Recall: 0.7341 - accuracy: 0.7657 - loss: 0.5028 - val_AUC: 0.7188 - val_Precision: 0.6923 - val_Recall: 0.5714 - val_accuracy: 0.6641 - val_loss: 0.6753 - learning_rate: 0.0010\n",
      "Epoch 19/100\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 232ms/step - AUC: 0.8258 - Precision: 0.7099 - Recall: 0.8254 - accuracy: 0.7461 - loss: 0.5177 - val_AUC: 0.7221 - val_Precision: 0.7826 - val_Recall: 0.5714 - val_accuracy: 0.7109 - val_loss: 0.7217 - learning_rate: 0.0010\n",
      "Epoch 20/100\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 221ms/step - AUC: 0.8308 - Precision: 0.7292 - Recall: 0.8333 - accuracy: 0.7638 - loss: 0.5144 - val_AUC: 0.6983 - val_Precision: 0.6792 - val_Recall: 0.5714 - val_accuracy: 0.6562 - val_loss: 0.6605 - learning_rate: 0.0010\n",
      "Epoch 21/100\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 235ms/step - AUC: 0.8527 - Precision: 0.7745 - Recall: 0.7222 - accuracy: 0.7579 - loss: 0.4803 - val_AUC: 0.7269 - val_Precision: 0.7037 - val_Recall: 0.6032 - val_accuracy: 0.6797 - val_loss: 0.6652 - learning_rate: 0.0010\n",
      "Epoch 22/100\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 298ms/step - AUC: 0.8628 - Precision: 0.7698 - Recall: 0.7698 - accuracy: 0.7717 - loss: 0.4597 - val_AUC: 0.7315 - val_Precision: 0.7143 - val_Recall: 0.6349 - val_accuracy: 0.6953 - val_loss: 0.6744 - learning_rate: 0.0010\n",
      "Epoch 23/100\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 309ms/step - AUC: 0.8686 - Precision: 0.7711 - Recall: 0.7619 - accuracy: 0.7697 - loss: 0.4510 - val_AUC: 0.7435 - val_Precision: 0.6667 - val_Recall: 0.6349 - val_accuracy: 0.6641 - val_loss: 0.6749 - learning_rate: 0.0010\n",
      "Epoch 24/100\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 293ms/step - AUC: 0.8693 - Precision: 0.7585 - Recall: 0.7976 - accuracy: 0.7736 - loss: 0.4451 - val_AUC: 0.7182 - val_Precision: 0.6349 - val_Recall: 0.6349 - val_accuracy: 0.6406 - val_loss: 0.7532 - learning_rate: 0.0010\n",
      "Epoch 25/100\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 343ms/step - AUC: 0.8568 - Precision: 0.7295 - Recall: 0.8135 - accuracy: 0.7579 - loss: 0.4741 - val_AUC: 0.7281 - val_Precision: 0.7447 - val_Recall: 0.5556 - val_accuracy: 0.6875 - val_loss: 0.6795 - learning_rate: 0.0010\n",
      "Epoch 26/100\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 327ms/step - AUC: 0.8888 - Precision: 0.8138 - Recall: 0.7976 - accuracy: 0.8091 - loss: 0.4242 - val_AUC: 0.7162 - val_Precision: 0.6379 - val_Recall: 0.5873 - val_accuracy: 0.6328 - val_loss: 0.7490 - learning_rate: 0.0010\n",
      "Epoch 27/100\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 262ms/step - AUC: 0.8943 - Precision: 0.7679 - Recall: 0.8532 - accuracy: 0.7992 - loss: 0.4127 - val_AUC: 0.7324 - val_Precision: 0.6557 - val_Recall: 0.6349 - val_accuracy: 0.6562 - val_loss: 0.7415 - learning_rate: 5.0000e-04\n",
      "Epoch 28/100\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 267ms/step - AUC: 0.9145 - Precision: 0.8259 - Recall: 0.8095 - accuracy: 0.8209 - loss: 0.3685 - val_AUC: 0.7348 - val_Precision: 0.7308 - val_Recall: 0.6032 - val_accuracy: 0.6953 - val_loss: 0.7813 - learning_rate: 5.0000e-04\n",
      "Epoch 29/100\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 320ms/step - AUC: 0.9174 - Precision: 0.8157 - Recall: 0.8254 - accuracy: 0.8209 - loss: 0.3619 - val_AUC: 0.7344 - val_Precision: 0.7193 - val_Recall: 0.6508 - val_accuracy: 0.7031 - val_loss: 0.7774 - learning_rate: 5.0000e-04\n",
      "Epoch 30/100\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 355ms/step - AUC: 0.9233 - Precision: 0.8446 - Recall: 0.8413 - accuracy: 0.8445 - loss: 0.3515 - val_AUC: 0.7480 - val_Precision: 0.7193 - val_Recall: 0.6508 - val_accuracy: 0.7031 - val_loss: 0.7404 - learning_rate: 5.0000e-04\n",
      "Epoch 31/100\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 265ms/step - AUC: 0.9272 - Precision: 0.8189 - Recall: 0.8611 - accuracy: 0.8366 - loss: 0.3403 - val_AUC: 0.7299 - val_Precision: 0.7273 - val_Recall: 0.6349 - val_accuracy: 0.7031 - val_loss: 0.8383 - learning_rate: 5.0000e-04\n",
      "Epoch 32/100\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 262ms/step - AUC: 0.9262 - Precision: 0.8508 - Recall: 0.8373 - accuracy: 0.8465 - loss: 0.3430 - val_AUC: 0.7617 - val_Precision: 0.7069 - val_Recall: 0.6508 - val_accuracy: 0.6953 - val_loss: 0.7561 - learning_rate: 5.0000e-04\n",
      "Epoch 33/100\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 269ms/step - AUC: 0.9282 - Precision: 0.8014 - Recall: 0.8968 - accuracy: 0.8386 - loss: 0.3460 - val_AUC: 0.7586 - val_Precision: 0.7143 - val_Recall: 0.6349 - val_accuracy: 0.6953 - val_loss: 0.7049 - learning_rate: 5.0000e-04\n",
      "Epoch 34/100\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 225ms/step - AUC: 0.9363 - Precision: 0.8450 - Recall: 0.8651 - accuracy: 0.8543 - loss: 0.3210 - val_AUC: 0.7540 - val_Precision: 0.7143 - val_Recall: 0.6349 - val_accuracy: 0.6953 - val_loss: 0.8383 - learning_rate: 5.0000e-04\n",
      "Epoch 35/100\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 224ms/step - AUC: 0.9426 - Precision: 0.8635 - Recall: 0.8532 - accuracy: 0.8602 - loss: 0.3079 - val_AUC: 0.7383 - val_Precision: 0.7018 - val_Recall: 0.6349 - val_accuracy: 0.6875 - val_loss: 0.7972 - learning_rate: 5.0000e-04\n",
      "Epoch 36/100\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 210ms/step - AUC: 0.9398 - Precision: 0.8321 - Recall: 0.8849 - accuracy: 0.8543 - loss: 0.3120 - val_AUC: 0.7642 - val_Precision: 0.7636 - val_Recall: 0.6667 - val_accuracy: 0.7344 - val_loss: 0.7547 - learning_rate: 5.0000e-04\n",
      "Epoch 37/100\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 212ms/step - AUC: 0.9478 - Precision: 0.8491 - Recall: 0.8929 - accuracy: 0.8681 - loss: 0.2910 - val_AUC: 0.7585 - val_Precision: 0.7241 - val_Recall: 0.6667 - val_accuracy: 0.7109 - val_loss: 0.8120 - learning_rate: 2.5000e-04\n",
      "Epoch 38/100\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 220ms/step - AUC: 0.9560 - Precision: 0.8566 - Recall: 0.9008 - accuracy: 0.8760 - loss: 0.2649 - val_AUC: 0.7458 - val_Precision: 0.7193 - val_Recall: 0.6508 - val_accuracy: 0.7031 - val_loss: 0.8416 - learning_rate: 2.5000e-04\n",
      "Epoch 39/100\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 225ms/step - AUC: 0.9614 - Precision: 0.8755 - Recall: 0.8929 - accuracy: 0.8839 - loss: 0.2503 - val_AUC: 0.7330 - val_Precision: 0.7193 - val_Recall: 0.6508 - val_accuracy: 0.7031 - val_loss: 0.9277 - learning_rate: 2.5000e-04\n",
      "Epoch 40/100\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 204ms/step - AUC: 0.9580 - Precision: 0.8519 - Recall: 0.9127 - accuracy: 0.8780 - loss: 0.2580 - val_AUC: 0.7470 - val_Precision: 0.7593 - val_Recall: 0.6508 - val_accuracy: 0.7266 - val_loss: 0.9063 - learning_rate: 2.5000e-04\n",
      "Epoch 41/100\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 211ms/step - AUC: 0.9610 - Precision: 0.8493 - Recall: 0.9167 - accuracy: 0.8780 - loss: 0.2495 - val_AUC: 0.7366 - val_Precision: 0.7069 - val_Recall: 0.6508 - val_accuracy: 0.6953 - val_loss: 0.9587 - learning_rate: 2.5000e-04\n",
      "Epoch 42/100\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 257ms/step - AUC: 0.9610 - Precision: 0.8636 - Recall: 0.9048 - accuracy: 0.8819 - loss: 0.2514 - val_AUC: 0.7446 - val_Precision: 0.7593 - val_Recall: 0.6508 - val_accuracy: 0.7266 - val_loss: 0.9414 - learning_rate: 2.5000e-04\n",
      "Epoch 43/100\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 231ms/step - AUC: 0.9655 - Precision: 0.8545 - Recall: 0.9087 - accuracy: 0.8780 - loss: 0.2365 - val_AUC: 0.7292 - val_Precision: 0.7069 - val_Recall: 0.6508 - val_accuracy: 0.6953 - val_loss: 1.0613 - learning_rate: 2.5000e-04\n",
      "Epoch 44/100\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 238ms/step - AUC: 0.9656 - Precision: 0.8657 - Recall: 0.9206 - accuracy: 0.8898 - loss: 0.2379 - val_AUC: 0.7600 - val_Precision: 0.7500 - val_Recall: 0.6667 - val_accuracy: 0.7266 - val_loss: 0.8955 - learning_rate: 2.5000e-04\n",
      "Epoch 45/100\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 240ms/step - AUC: 0.9644 - Precision: 0.8598 - Recall: 0.9008 - accuracy: 0.8780 - loss: 0.2374 - val_AUC: 0.7315 - val_Precision: 0.6949 - val_Recall: 0.6508 - val_accuracy: 0.6875 - val_loss: 1.0868 - learning_rate: 2.5000e-04\n",
      "Epoch 46/100\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 240ms/step - AUC: 0.9753 - Precision: 0.8855 - Recall: 0.9206 - accuracy: 0.9016 - loss: 0.2025 - val_AUC: 0.7408 - val_Precision: 0.7069 - val_Recall: 0.6508 - val_accuracy: 0.6953 - val_loss: 1.0385 - learning_rate: 2.5000e-04\n",
      "Epoch 47/100\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 267ms/step - AUC: 0.9749 - Precision: 0.8684 - Recall: 0.9167 - accuracy: 0.8898 - loss: 0.2032 - val_AUC: 0.7435 - val_Precision: 0.7193 - val_Recall: 0.6508 - val_accuracy: 0.7031 - val_loss: 1.0395 - learning_rate: 1.2500e-04\n",
      "Epoch 48/100\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 277ms/step - AUC: 0.9757 - Precision: 0.8876 - Recall: 0.9087 - accuracy: 0.8976 - loss: 0.2000 - val_AUC: 0.7403 - val_Precision: 0.7241 - val_Recall: 0.6667 - val_accuracy: 0.7109 - val_loss: 1.0533 - learning_rate: 1.2500e-04\n",
      "Epoch 49/100\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 318ms/step - AUC: 0.9768 - Precision: 0.8902 - Recall: 0.9325 - accuracy: 0.9094 - loss: 0.1967 - val_AUC: 0.7484 - val_Precision: 0.7241 - val_Recall: 0.6667 - val_accuracy: 0.7109 - val_loss: 1.0538 - learning_rate: 1.2500e-04\n",
      "Epoch 50/100\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 289ms/step - AUC: 0.9768 - Precision: 0.9055 - Recall: 0.9127 - accuracy: 0.9094 - loss: 0.1963 - val_AUC: 0.7479 - val_Precision: 0.7193 - val_Recall: 0.6508 - val_accuracy: 0.7031 - val_loss: 1.0926 - learning_rate: 1.2500e-04\n",
      "Epoch 51/100\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 269ms/step - AUC: 0.9776 - Precision: 0.8839 - Recall: 0.9365 - accuracy: 0.9075 - loss: 0.1901 - val_AUC: 0.7426 - val_Precision: 0.7455 - val_Recall: 0.6508 - val_accuracy: 0.7188 - val_loss: 1.1068 - learning_rate: 1.2500e-04\n",
      "Epoch 52/100\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 294ms/step - AUC: 0.9827 - Precision: 0.9176 - Recall: 0.9286 - accuracy: 0.9232 - loss: 0.1730 - val_AUC: 0.7477 - val_Precision: 0.7321 - val_Recall: 0.6508 - val_accuracy: 0.7109 - val_loss: 1.1021 - learning_rate: 1.2500e-04\n",
      "Epoch 53/100\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 251ms/step - AUC: 0.9784 - Precision: 0.9134 - Recall: 0.9206 - accuracy: 0.9173 - loss: 0.1878 - val_AUC: 0.7426 - val_Precision: 0.7241 - val_Recall: 0.6667 - val_accuracy: 0.7109 - val_loss: 1.0869 - learning_rate: 1.2500e-04\n",
      "Epoch 54/100\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 252ms/step - AUC: 0.9810 - Precision: 0.9077 - Recall: 0.9365 - accuracy: 0.9213 - loss: 0.1755 - val_AUC: 0.7267 - val_Precision: 0.7321 - val_Recall: 0.6508 - val_accuracy: 0.7109 - val_loss: 1.1954 - learning_rate: 1.2500e-04\n",
      "Epoch 55/100\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 268ms/step - AUC: 0.9816 - Precision: 0.9176 - Recall: 0.9286 - accuracy: 0.9232 - loss: 0.1762 - val_AUC: 0.7324 - val_Precision: 0.7593 - val_Recall: 0.6508 - val_accuracy: 0.7266 - val_loss: 1.1717 - learning_rate: 1.2500e-04\n",
      "Epoch 56/100\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 272ms/step - AUC: 0.9822 - Precision: 0.9237 - Recall: 0.9127 - accuracy: 0.9193 - loss: 0.1712 - val_AUC: 0.7357 - val_Precision: 0.7455 - val_Recall: 0.6508 - val_accuracy: 0.7188 - val_loss: 1.2022 - learning_rate: 1.2500e-04\n",
      "Epoch 57/100\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 262ms/step - AUC: 0.9828 - Precision: 0.9105 - Recall: 0.9286 - accuracy: 0.9193 - loss: 0.1701 - val_AUC: 0.7437 - val_Precision: 0.7593 - val_Recall: 0.6508 - val_accuracy: 0.7266 - val_loss: 1.1882 - learning_rate: 6.2500e-05\n",
      "Epoch 58/100\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 256ms/step - AUC: 0.9852 - Precision: 0.9252 - Recall: 0.9325 - accuracy: 0.9291 - loss: 0.1602 - val_AUC: 0.7379 - val_Precision: 0.7593 - val_Recall: 0.6508 - val_accuracy: 0.7266 - val_loss: 1.1908 - learning_rate: 6.2500e-05\n",
      "Epoch 59/100\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 293ms/step - AUC: 0.9865 - Precision: 0.9255 - Recall: 0.9365 - accuracy: 0.9311 - loss: 0.1524 - val_AUC: 0.7300 - val_Precision: 0.7593 - val_Recall: 0.6508 - val_accuracy: 0.7266 - val_loss: 1.2118 - learning_rate: 6.2500e-05\n",
      "Epoch 60/100\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 274ms/step - AUC: 0.9864 - Precision: 0.9176 - Recall: 0.9286 - accuracy: 0.9232 - loss: 0.1539 - val_AUC: 0.7335 - val_Precision: 0.7593 - val_Recall: 0.6508 - val_accuracy: 0.7266 - val_loss: 1.2185 - learning_rate: 6.2500e-05\n",
      "Epoch 61/100\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 271ms/step - AUC: 0.9872 - Precision: 0.9216 - Recall: 0.9325 - accuracy: 0.9272 - loss: 0.1487 - val_AUC: 0.7272 - val_Precision: 0.7593 - val_Recall: 0.6508 - val_accuracy: 0.7266 - val_loss: 1.2327 - learning_rate: 6.2500e-05\n",
      "Epoch 62/100\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 259ms/step - AUC: 0.9859 - Precision: 0.9388 - Recall: 0.9127 - accuracy: 0.9272 - loss: 0.1539 - val_AUC: 0.7348 - val_Precision: 0.7593 - val_Recall: 0.6508 - val_accuracy: 0.7266 - val_loss: 1.2508 - learning_rate: 6.2500e-05\n",
      "Epoch 63/100\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 298ms/step - AUC: 0.9872 - Precision: 0.9317 - Recall: 0.9206 - accuracy: 0.9272 - loss: 0.1517 - val_AUC: 0.7324 - val_Precision: 0.7455 - val_Recall: 0.6508 - val_accuracy: 0.7188 - val_loss: 1.2286 - learning_rate: 6.2500e-05\n",
      "Epoch 64/100\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 265ms/step - AUC: 0.9885 - Precision: 0.9294 - Recall: 0.9405 - accuracy: 0.9350 - loss: 0.1422 - val_AUC: 0.7266 - val_Precision: 0.7455 - val_Recall: 0.6508 - val_accuracy: 0.7188 - val_loss: 1.2694 - learning_rate: 6.2500e-05\n",
      "Epoch 65/100\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 262ms/step - AUC: 0.9883 - Precision: 0.9280 - Recall: 0.9206 - accuracy: 0.9252 - loss: 0.1404 - val_AUC: 0.7310 - val_Precision: 0.7455 - val_Recall: 0.6508 - val_accuracy: 0.7188 - val_loss: 1.2712 - learning_rate: 6.2500e-05\n",
      "Epoch 66/100\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 277ms/step - AUC: 0.9900 - Precision: 0.9363 - Recall: 0.9325 - accuracy: 0.9350 - loss: 0.1341 - val_AUC: 0.7299 - val_Precision: 0.7455 - val_Recall: 0.6508 - val_accuracy: 0.7188 - val_loss: 1.3055 - learning_rate: 6.2500e-05\n",
      "Epoch 67/100\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 272ms/step - AUC: 0.9863 - Precision: 0.9252 - Recall: 0.9325 - accuracy: 0.9291 - loss: 0.1502 - val_AUC: 0.7244 - val_Precision: 0.7321 - val_Recall: 0.6508 - val_accuracy: 0.7109 - val_loss: 1.3060 - learning_rate: 3.1250e-05\n",
      "Epoch 68/100\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 287ms/step - AUC: 0.9887 - Precision: 0.9320 - Recall: 0.9246 - accuracy: 0.9291 - loss: 0.1401 - val_AUC: 0.7244 - val_Precision: 0.7455 - val_Recall: 0.6508 - val_accuracy: 0.7188 - val_loss: 1.3174 - learning_rate: 3.1250e-05\n",
      "Epoch 69/100\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 273ms/step - AUC: 0.9889 - Precision: 0.9438 - Recall: 0.9325 - accuracy: 0.9390 - loss: 0.1387 - val_AUC: 0.7242 - val_Precision: 0.7321 - val_Recall: 0.6508 - val_accuracy: 0.7109 - val_loss: 1.3163 - learning_rate: 3.1250e-05\n",
      "Epoch 70/100\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 282ms/step - AUC: 0.9880 - Precision: 0.9258 - Recall: 0.9405 - accuracy: 0.9331 - loss: 0.1425 - val_AUC: 0.7252 - val_Precision: 0.7321 - val_Recall: 0.6508 - val_accuracy: 0.7109 - val_loss: 1.3116 - learning_rate: 3.1250e-05\n",
      "Epoch 71/100\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 258ms/step - AUC: 0.9895 - Precision: 0.9157 - Recall: 0.9484 - accuracy: 0.9311 - loss: 0.1343 - val_AUC: 0.7238 - val_Precision: 0.7455 - val_Recall: 0.6508 - val_accuracy: 0.7188 - val_loss: 1.3207 - learning_rate: 3.1250e-05\n",
      "Epoch 72/100\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 271ms/step - AUC: 0.9889 - Precision: 0.9328 - Recall: 0.9365 - accuracy: 0.9350 - loss: 0.1386 - val_AUC: 0.7252 - val_Precision: 0.7321 - val_Recall: 0.6508 - val_accuracy: 0.7109 - val_loss: 1.3366 - learning_rate: 3.1250e-05\n",
      "Epoch 73/100\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 286ms/step - AUC: 0.9910 - Precision: 0.9407 - Recall: 0.9444 - accuracy: 0.9429 - loss: 0.1286 - val_AUC: 0.7269 - val_Precision: 0.7321 - val_Recall: 0.6508 - val_accuracy: 0.7109 - val_loss: 1.3355 - learning_rate: 3.1250e-05\n",
      "Epoch 74/100\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 270ms/step - AUC: 0.9888 - Precision: 0.9291 - Recall: 0.9365 - accuracy: 0.9331 - loss: 0.1376 - val_AUC: 0.7263 - val_Precision: 0.7455 - val_Recall: 0.6508 - val_accuracy: 0.7188 - val_loss: 1.3421 - learning_rate: 3.1250e-05\n",
      "Epoch 75/100\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 267ms/step - AUC: 0.9895 - Precision: 0.9323 - Recall: 0.9286 - accuracy: 0.9311 - loss: 0.1354 - val_AUC: 0.7265 - val_Precision: 0.7455 - val_Recall: 0.6508 - val_accuracy: 0.7188 - val_loss: 1.3438 - learning_rate: 3.1250e-05\n",
      "Epoch 76/100\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 271ms/step - AUC: 0.9891 - Precision: 0.9283 - Recall: 0.9246 - accuracy: 0.9272 - loss: 0.1369 - val_AUC: 0.7283 - val_Precision: 0.7455 - val_Recall: 0.6508 - val_accuracy: 0.7188 - val_loss: 1.3424 - learning_rate: 3.1250e-05\n",
      "Epoch 77/100\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 272ms/step - AUC: 0.9909 - Precision: 0.9402 - Recall: 0.9365 - accuracy: 0.9390 - loss: 0.1272 - val_AUC: 0.7274 - val_Precision: 0.7321 - val_Recall: 0.6508 - val_accuracy: 0.7109 - val_loss: 1.3454 - learning_rate: 1.5625e-05\n",
      "Epoch 78/100\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 264ms/step - AUC: 0.9889 - Precision: 0.9365 - Recall: 0.9365 - accuracy: 0.9370 - loss: 0.1364 - val_AUC: 0.7266 - val_Precision: 0.7455 - val_Recall: 0.6508 - val_accuracy: 0.7188 - val_loss: 1.3577 - learning_rate: 1.5625e-05\n",
      "Epoch 79/100\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 266ms/step - AUC: 0.9902 - Precision: 0.9363 - Recall: 0.9325 - accuracy: 0.9350 - loss: 0.1278 - val_AUC: 0.7264 - val_Precision: 0.7455 - val_Recall: 0.6508 - val_accuracy: 0.7188 - val_loss: 1.3620 - learning_rate: 1.5625e-05\n",
      "Epoch 80/100\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 270ms/step - AUC: 0.9886 - Precision: 0.9323 - Recall: 0.9286 - accuracy: 0.9311 - loss: 0.1380 - val_AUC: 0.7267 - val_Precision: 0.7321 - val_Recall: 0.6508 - val_accuracy: 0.7109 - val_loss: 1.3592 - learning_rate: 1.5625e-05\n",
      "Epoch 81/100\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 261ms/step - AUC: 0.9906 - Precision: 0.9438 - Recall: 0.9325 - accuracy: 0.9390 - loss: 0.1286 - val_AUC: 0.7263 - val_Precision: 0.7321 - val_Recall: 0.6508 - val_accuracy: 0.7109 - val_loss: 1.3644 - learning_rate: 1.5625e-05\n",
      "Epoch 82/100\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 281ms/step - AUC: 0.9911 - Precision: 0.9447 - Recall: 0.9484 - accuracy: 0.9469 - loss: 0.1252 - val_AUC: 0.7267 - val_Precision: 0.7321 - val_Recall: 0.6508 - val_accuracy: 0.7109 - val_loss: 1.3645 - learning_rate: 1.5625e-05\n",
      "Epoch 83/100\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 270ms/step - AUC: 0.9903 - Precision: 0.9407 - Recall: 0.9444 - accuracy: 0.9429 - loss: 0.1307 - val_AUC: 0.7243 - val_Precision: 0.7321 - val_Recall: 0.6508 - val_accuracy: 0.7109 - val_loss: 1.3722 - learning_rate: 1.5625e-05\n",
      "Epoch 84/100\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 291ms/step - AUC: 0.9915 - Precision: 0.9453 - Recall: 0.9603 - accuracy: 0.9528 - loss: 0.1224 - val_AUC: 0.7244 - val_Precision: 0.7321 - val_Recall: 0.6508 - val_accuracy: 0.7109 - val_loss: 1.3737 - learning_rate: 1.5625e-05\n",
      "Epoch 85/100\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 289ms/step - AUC: 0.9918 - Precision: 0.9440 - Recall: 0.9365 - accuracy: 0.9409 - loss: 0.1211 - val_AUC: 0.7241 - val_Precision: 0.7321 - val_Recall: 0.6508 - val_accuracy: 0.7109 - val_loss: 1.3760 - learning_rate: 1.5625e-05\n",
      "Epoch 86/100\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 271ms/step - AUC: 0.9911 - Precision: 0.9320 - Recall: 0.9246 - accuracy: 0.9291 - loss: 0.1258 - val_AUC: 0.7242 - val_Precision: 0.7321 - val_Recall: 0.6508 - val_accuracy: 0.7109 - val_loss: 1.3878 - learning_rate: 1.5625e-05\n",
      "Epoch 87/100\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 275ms/step - AUC: 0.9919 - Precision: 0.9375 - Recall: 0.9524 - accuracy: 0.9449 - loss: 0.1214 - val_AUC: 0.7216 - val_Precision: 0.7321 - val_Recall: 0.6508 - val_accuracy: 0.7109 - val_loss: 1.3895 - learning_rate: 7.8125e-06\n",
      "Epoch 88/100\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 260ms/step - AUC: 0.9906 - Precision: 0.9370 - Recall: 0.9444 - accuracy: 0.9409 - loss: 0.1277 - val_AUC: 0.7215 - val_Precision: 0.7321 - val_Recall: 0.6508 - val_accuracy: 0.7109 - val_loss: 1.3905 - learning_rate: 7.8125e-06\n",
      "Epoch 89/100\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 281ms/step - AUC: 0.9896 - Precision: 0.9363 - Recall: 0.9325 - accuracy: 0.9350 - loss: 0.1336 - val_AUC: 0.7239 - val_Precision: 0.7321 - val_Recall: 0.6508 - val_accuracy: 0.7109 - val_loss: 1.3912 - learning_rate: 7.8125e-06\n",
      "Epoch 90/100\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 261ms/step - AUC: 0.9902 - Precision: 0.9360 - Recall: 0.9286 - accuracy: 0.9331 - loss: 0.1296 - val_AUC: 0.7214 - val_Precision: 0.7321 - val_Recall: 0.6508 - val_accuracy: 0.7109 - val_loss: 1.3907 - learning_rate: 7.8125e-06\n",
      "Epoch 91/100\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 281ms/step - AUC: 0.9907 - Precision: 0.9249 - Recall: 0.9286 - accuracy: 0.9272 - loss: 0.1261 - val_AUC: 0.7214 - val_Precision: 0.7321 - val_Recall: 0.6508 - val_accuracy: 0.7109 - val_loss: 1.3930 - learning_rate: 7.8125e-06\n",
      "Epoch 92/100\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 281ms/step - AUC: 0.9918 - Precision: 0.9412 - Recall: 0.9524 - accuracy: 0.9469 - loss: 0.1227 - val_AUC: 0.7219 - val_Precision: 0.7321 - val_Recall: 0.6508 - val_accuracy: 0.7109 - val_loss: 1.3968 - learning_rate: 7.8125e-06\n",
      "Epoch 93/100\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 288ms/step - AUC: 0.9908 - Precision: 0.9435 - Recall: 0.9286 - accuracy: 0.9370 - loss: 0.1263 - val_AUC: 0.7253 - val_Precision: 0.7321 - val_Recall: 0.6508 - val_accuracy: 0.7109 - val_loss: 1.3982 - learning_rate: 7.8125e-06\n",
      "Epoch 94/100\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 281ms/step - AUC: 0.9917 - Precision: 0.9474 - Recall: 0.9286 - accuracy: 0.9390 - loss: 0.1226 - val_AUC: 0.7220 - val_Precision: 0.7321 - val_Recall: 0.6508 - val_accuracy: 0.7109 - val_loss: 1.3977 - learning_rate: 7.8125e-06\n",
      "Epoch 95/100\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 305ms/step - AUC: 0.9911 - Precision: 0.9405 - Recall: 0.9405 - accuracy: 0.9409 - loss: 0.1245 - val_AUC: 0.7234 - val_Precision: 0.7321 - val_Recall: 0.6508 - val_accuracy: 0.7109 - val_loss: 1.3979 - learning_rate: 7.8125e-06\n",
      "Epoch 96/100\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 266ms/step - AUC: 0.9909 - Precision: 0.9451 - Recall: 0.9563 - accuracy: 0.9508 - loss: 0.1272 - val_AUC: 0.7217 - val_Precision: 0.7273 - val_Recall: 0.6349 - val_accuracy: 0.7031 - val_loss: 1.4007 - learning_rate: 7.8125e-06\n",
      "Epoch 97/100\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 275ms/step - AUC: 0.9913 - Precision: 0.9516 - Recall: 0.9365 - accuracy: 0.9449 - loss: 0.1259 - val_AUC: 0.7219 - val_Precision: 0.7321 - val_Recall: 0.6508 - val_accuracy: 0.7109 - val_loss: 1.4022 - learning_rate: 3.9063e-06\n",
      "Epoch 98/100\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 264ms/step - AUC: 0.9909 - Precision: 0.9363 - Recall: 0.9325 - accuracy: 0.9350 - loss: 0.1262 - val_AUC: 0.7249 - val_Precision: 0.7321 - val_Recall: 0.6508 - val_accuracy: 0.7109 - val_loss: 1.4015 - learning_rate: 3.9063e-06\n",
      "Epoch 99/100\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 266ms/step - AUC: 0.9916 - Precision: 0.9400 - Recall: 0.9325 - accuracy: 0.9370 - loss: 0.1221 - val_AUC: 0.7254 - val_Precision: 0.7321 - val_Recall: 0.6508 - val_accuracy: 0.7109 - val_loss: 1.4009 - learning_rate: 3.9063e-06\n",
      "Epoch 100/100\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 266ms/step - AUC: 0.9911 - Precision: 0.9474 - Recall: 0.9286 - accuracy: 0.9390 - loss: 0.1233 - val_AUC: 0.7258 - val_Precision: 0.7321 - val_Recall: 0.6508 - val_accuracy: 0.7109 - val_loss: 1.4011 - learning_rate: 3.9063e-06\n"
     ]
    }
   ],
   "source": [
    "# CELL 5 - TRAIN DENGAN SETTING AMAN\n",
    "model = build_model(\n",
    "    embedding_dim=128,\n",
    "    use_conv=False,\n",
    "    conv_filters=64,\n",
    "    conv_kernel_size=5,\n",
    "    lstm_units=128,\n",
    "    dropout_rate=0.5,\n",
    "    learning_rate=0.001  # mulai tinggi!\n",
    ")\n",
    "\n",
    "callbacks = [\n",
    "    EarlyStopping(monitor='val_auc', mode='max', patience=20, restore_best_weights=True),\n",
    "    ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=10, min_lr=1e-6),  # lebih sabar\n",
    "    ModelCheckpoint('fixed_model.keras', monitor='val_auc', mode='max', save_best_only=True)\n",
    "]\n",
    "\n",
    "history = model.fit(\n",
    "    X_train, y_train,\n",
    "    validation_data=(X_test, y_test),\n",
    "    epochs=100,\n",
    "    batch_size=32,           # naikkan!\n",
    "    class_weight=class_weight_dict,\n",
    "    callbacks=callbacks,\n",
    "    verbose=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "0b3f37e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 70ms/step\n",
      "\n",
      "=== SMILES2VEC + LSTM (BASE) ===\n",
      "ROC-AUC: 0.7363\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     Neutral       0.69      0.77      0.73        65\n",
      "   Inhibitor       0.73      0.65      0.69        63\n",
      "\n",
      "    accuracy                           0.71       128\n",
      "   macro avg       0.71      0.71      0.71       128\n",
      "weighted avg       0.71      0.71      0.71       128\n",
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 500x400 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# CELL 6 - Evaluasi Lengkap\n",
    "from tensorflow.keras.models import load_model\n",
    "model = load_model('fixed_model.keras')\n",
    "\n",
    "y_pred_prob = model.predict(X_test).flatten()\n",
    "y_pred = (y_pred_prob > 0.5).astype(int)\n",
    "\n",
    "print(\"\\n=== SMILES2VEC + LSTM (BASE) ===\")\n",
    "print(f\"ROC-AUC: {roc_auc_score(y_test, y_pred_prob):.4f}\")\n",
    "print(classification_report(y_test, y_pred, target_names=['Neutral', 'Inhibitor']))\n",
    "\n",
    "# Confusion Matrix\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "plt.figure(figsize=(5,4))\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues',\n",
    "            xticklabels=['Neutral', 'Inhibitor'],\n",
    "            yticklabels=['Neutral', 'Inhibitor'])\n",
    "plt.ylabel('True')\n",
    "plt.xlabel('Predicted')\n",
    "plt.title('Confusion Matrix - SMILES2Vec')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "7512f691",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y_train distribusi: [256 252]\n",
      "Class weights (0:Neutral, 1:Inhibitor): {0: 0.9921875, 1: 1.007936507936508}\n"
     ]
    }
   ],
   "source": [
    "# HITUNG ULANG & PRINT\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "\n",
    "classes = np.unique(y_train)\n",
    "weights = compute_class_weight(class_weight='balanced', classes=classes, y=y_train)\n",
    "class_weight_dict = {int(classes[0]): weights[0], int(classes[1]): weights[1]}\n",
    "\n",
    "print(\"y_train distribusi:\", np.bincount(y_train.astype(int)))\n",
    "print(\"Class weights (0:Neutral, 1:Inhibitor):\", class_weight_dict)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py311",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
