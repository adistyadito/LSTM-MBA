{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "447beaee",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-10-09 10:27:57.768254: I external/local_xla/xla/tsl/cuda/cudart_stub.cc:31] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2025-10-09 10:27:58.352958: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2025-10-09 10:28:00.505448: I external/local_xla/xla/tsl/cuda/cudart_stub.cc:31] Could not find cuda drivers on your machine, GPU will not be used.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, LSTM, Dropout, Reshape\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from rdkit import Chem\n",
    "from rdkit.Chem import rdFingerprintGenerator\n",
    "import pandas as pd # Tambahkan impor Pandas\n",
    "\n",
    "# Atur seed untuk reproducibility\n",
    "tf.random.set_seed(42)\n",
    "np.random.seed(42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c7e61fd4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data kosong = cid           0\n",
      "smiles        0\n",
      "acvalue       0\n",
      "categories    0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Baca CSV tanpa header\n",
    "df = pd.read_csv(\"https://raw.githubusercontent.com/adistyadito/LSTM-MBA/refs/heads/main/GSARPC3.csv\")\n",
    "\n",
    "# Tampilkan beberapa baris pertama\n",
    "df\n",
    "\n",
    "# Check for missing values\n",
    "print(f'Data kosong = {df.isnull().sum()}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "860af389",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Embedding, LSTM, Dense, Dropout, Reshape\n",
    "from tensorflow.keras.optimizers import Adam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "034b4abd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from rdkit import Chem\n",
    "from rdkit.Chem import AllChem # Tetep perlu buat beberapa hal di RDKit\n",
    "from rdkit.Chem import rdFingerprintGenerator # Import generator\n",
    "smiles_clean = df['smiles'].tolist()\n",
    "\n",
    "mols = []\n",
    "for smiles in smiles_clean:\n",
    "    mol = Chem.MolFromSmiles(smiles)\n",
    "    if mol is not None:\n",
    "        mols.append(mol)\n",
    "    else:\n",
    "        print(f\"Warning: Could not create mol object for SMILES: {smiles}\")\n",
    "        pass # Skip adding None\n",
    "\n",
    "# --- Langkah 4: Generate Fingerprint dari List Objek Molekul (mols) ---\n",
    "# Parameter fingerprint\n",
    "radius = 2\n",
    "nBits = 1024 # Ukuran vektor fingerprint\n",
    "\n",
    "# Bikin generatornya\n",
    "fpgen = rdFingerprintGenerator.GetMorganGenerator(radius=radius, fpSize=nBits)\n",
    "\n",
    "fingerprints = []\n",
    "# Sekarang lu iterasi di list 'mols' yang isinya objek molekul\n",
    "for mol in mols:\n",
    "    # Cek lagi kalau-kalau ada None di list mols (meskipun seharusnya nggak ada kalau langkah 3 bener)\n",
    "    if mol is not None:\n",
    "        # Panggil generator untuk bikin fingerprint\n",
    "        fp = fpgen.GetFingerprint(mol)\n",
    "        # Ubah BitVector ke numpy array\n",
    "        fingerprints.append(np.array(fp))\n",
    "    else:\n",
    "        # Handle kalau ada None di mols (misalnya append vektor nol)\n",
    "        fingerprints.append(np.zeros(nBits))\n",
    "\n",
    "# Konversi list fingerprints jadi NumPy array besar (Ini X lu)\n",
    "X = np.array(fingerprints)\n",
    "\n",
    "# --- Langkah 5: Siapkan Data Target (y) ---\n",
    "# Pastiin nama kolom target lu bener\n",
    "df['label'] = df['categories'].map({'inhibitor': 1, 'neutral': 0})\n",
    "y = df['label'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "65183f03",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ====================================================================\n",
    "# B. FUNGSI UNTUK MEMBANGUN MODEL (Wajib untuk CV)\n",
    "# ====================================================================\n",
    "\n",
    "def build_lstm_model(nBits, units=32, dropout_rate=0.7, learning_rate=0.001):\n",
    "    \"\"\"Membangun Model LSTM dengan hyperparameter yang ditentukan.\"\"\"\n",
    "    model = Sequential()\n",
    "    \n",
    "    # Input dan Reshape ke 3D (samples, 1, nBits)\n",
    "    model.add(tf.keras.Input(shape=(nBits,)))\n",
    "    model.add(Reshape((1, nBits))) \n",
    "\n",
    "    # Layer LSTM (Ganti ke 'relu' sesuai request)\n",
    "    model.add(LSTM(units, activation='tanh', recurrent_activation='sigmoid', return_sequences=False))\n",
    "\n",
    "    # Layer Dropout (Dinaikkan untuk regulasi)\n",
    "    model.add(Dropout(dropout_rate))\n",
    "\n",
    "    # Output Layer (untuk binary classification)\n",
    "    model.add(Dense(1, activation='sigmoid')) \n",
    "\n",
    "    # Compile\n",
    "    model.compile(optimizer=Adam(learning_rate=learning_rate),\n",
    "                  loss='binary_crossentropy',\n",
    "                  metrics=['accuracy', 'AUC'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e55cb5b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==========================================\n",
      "--- FOLD 1/5 ---\n",
      "==========================================\n",
      "Mulai Training...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-10-09 10:28:11.660836: E external/local_xla/xla/stream_executor/cuda/cuda_platform.cc:51] failed call to cuInit: INTERNAL: CUDA error: Failed call to cuInit: UNKNOWN ERROR (303)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 36ms/step - AUC: 0.6454 - accuracy: 0.5965 - loss: 0.6753 - val_AUC: 0.8632 - val_accuracy: 0.7188 - val_loss: 0.6365\n",
      "Epoch 2/100\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - AUC: 0.8235 - accuracy: 0.7382 - loss: 0.6072 - val_AUC: 0.8907 - val_accuracy: 0.7812 - val_loss: 0.5757\n",
      "Epoch 3/100\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - AUC: 0.8527 - accuracy: 0.7697 - loss: 0.5570 - val_AUC: 0.9020 - val_accuracy: 0.8125 - val_loss: 0.5134\n",
      "Epoch 4/100\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - AUC: 0.8773 - accuracy: 0.7972 - loss: 0.4902 - val_AUC: 0.8977 - val_accuracy: 0.8281 - val_loss: 0.4658\n",
      "Epoch 5/100\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - AUC: 0.9107 - accuracy: 0.8425 - loss: 0.4403 - val_AUC: 0.8963 - val_accuracy: 0.8281 - val_loss: 0.4387\n",
      "Epoch 6/100\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - AUC: 0.9151 - accuracy: 0.8406 - loss: 0.4014 - val_AUC: 0.8939 - val_accuracy: 0.8281 - val_loss: 0.4243\n",
      "Epoch 7/100\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - AUC: 0.9203 - accuracy: 0.8484 - loss: 0.3790 - val_AUC: 0.8919 - val_accuracy: 0.8281 - val_loss: 0.4163\n",
      "Epoch 8/100\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - AUC: 0.9415 - accuracy: 0.8681 - loss: 0.3391 - val_AUC: 0.8985 - val_accuracy: 0.8281 - val_loss: 0.4059\n",
      "Epoch 9/100\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - AUC: 0.9487 - accuracy: 0.8839 - loss: 0.3155 - val_AUC: 0.8951 - val_accuracy: 0.8203 - val_loss: 0.4061\n",
      "Epoch 10/100\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - AUC: 0.9510 - accuracy: 0.8799 - loss: 0.3098 - val_AUC: 0.8958 - val_accuracy: 0.8203 - val_loss: 0.4048\n",
      "Epoch 11/100\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - AUC: 0.9518 - accuracy: 0.8898 - loss: 0.2984 - val_AUC: 0.8955 - val_accuracy: 0.8203 - val_loss: 0.4057\n",
      "Epoch 12/100\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - AUC: 0.9595 - accuracy: 0.8917 - loss: 0.2763 - val_AUC: 0.8968 - val_accuracy: 0.8359 - val_loss: 0.4061\n",
      "Epoch 13/100\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - AUC: 0.9577 - accuracy: 0.8976 - loss: 0.2754 - val_AUC: 0.8979 - val_accuracy: 0.8359 - val_loss: 0.4056\n",
      "Epoch 14/100\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - AUC: 0.9689 - accuracy: 0.9094 - loss: 0.2473 - val_AUC: 0.8974 - val_accuracy: 0.8438 - val_loss: 0.4074\n",
      "Epoch 15/100\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - AUC: 0.9641 - accuracy: 0.9055 - loss: 0.2583 - val_AUC: 0.8971 - val_accuracy: 0.8438 - val_loss: 0.4075\n",
      "Epoch 16/100\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - AUC: 0.9717 - accuracy: 0.9232 - loss: 0.2335 - val_AUC: 0.8951 - val_accuracy: 0.8438 - val_loss: 0.4172\n",
      "Epoch 17/100\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - AUC: 0.9706 - accuracy: 0.9173 - loss: 0.2349 - val_AUC: 0.8954 - val_accuracy: 0.8438 - val_loss: 0.4196\n",
      "Epoch 18/100\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - AUC: 0.9658 - accuracy: 0.9035 - loss: 0.2445 - val_AUC: 0.8956 - val_accuracy: 0.8359 - val_loss: 0.4259\n",
      "Epoch 19/100\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - AUC: 0.9729 - accuracy: 0.9193 - loss: 0.2283 - val_AUC: 0.8946 - val_accuracy: 0.8438 - val_loss: 0.4294\n",
      "Epoch 20/100\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - AUC: 0.9763 - accuracy: 0.9114 - loss: 0.2141 - val_AUC: 0.8930 - val_accuracy: 0.8438 - val_loss: 0.4423\n",
      "Epoch 20: early stopping\n",
      "Restoring model weights from the end of the best epoch: 10.\n",
      "\n",
      "Evaluasi Fold...\n",
      "Fold 1 Selesai di Epoch 20.\n",
      "Fold 1 - FINAL METRICS (Val): AUC: 0.8958, Acc: 0.8203, MCC: 0.6410, Loss: 0.4048\n",
      "\n",
      "==========================================\n",
      "--- FOLD 2/5 ---\n",
      "==========================================\n",
      "Mulai Training...\n",
      "Epoch 1/100\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 26ms/step - AUC: 0.6528 - accuracy: 0.5933 - loss: 0.6698 - val_AUC: 0.8181 - val_accuracy: 0.7795 - val_loss: 0.6390\n",
      "Epoch 2/100\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - AUC: 0.8150 - accuracy: 0.7387 - loss: 0.6050 - val_AUC: 0.8426 - val_accuracy: 0.7480 - val_loss: 0.5802\n",
      "Epoch 3/100\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - AUC: 0.8550 - accuracy: 0.7800 - loss: 0.5364 - val_AUC: 0.8460 - val_accuracy: 0.7717 - val_loss: 0.5306\n",
      "Epoch 4/100\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - AUC: 0.8656 - accuracy: 0.7760 - loss: 0.4902 - val_AUC: 0.8674 - val_accuracy: 0.7559 - val_loss: 0.4875\n",
      "Epoch 5/100\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - AUC: 0.8898 - accuracy: 0.8153 - loss: 0.4464 - val_AUC: 0.8895 - val_accuracy: 0.8189 - val_loss: 0.4451\n",
      "Epoch 6/100\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - AUC: 0.9027 - accuracy: 0.8428 - loss: 0.4195 - val_AUC: 0.9033 - val_accuracy: 0.8189 - val_loss: 0.4158\n",
      "Epoch 7/100\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - AUC: 0.9162 - accuracy: 0.8310 - loss: 0.3878 - val_AUC: 0.9120 - val_accuracy: 0.8268 - val_loss: 0.3934\n",
      "Epoch 8/100\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - AUC: 0.9320 - accuracy: 0.8703 - loss: 0.3487 - val_AUC: 0.9203 - val_accuracy: 0.8346 - val_loss: 0.3755\n",
      "Epoch 9/100\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - AUC: 0.9330 - accuracy: 0.8684 - loss: 0.3447 - val_AUC: 0.9252 - val_accuracy: 0.8346 - val_loss: 0.3640\n",
      "Epoch 10/100\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - AUC: 0.9444 - accuracy: 0.8861 - loss: 0.3190 - val_AUC: 0.9296 - val_accuracy: 0.8425 - val_loss: 0.3510\n",
      "Epoch 11/100\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - AUC: 0.9443 - accuracy: 0.8802 - loss: 0.3120 - val_AUC: 0.9299 - val_accuracy: 0.8425 - val_loss: 0.3451\n",
      "Epoch 12/100\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - AUC: 0.9449 - accuracy: 0.8802 - loss: 0.3110 - val_AUC: 0.9315 - val_accuracy: 0.8346 - val_loss: 0.3490\n",
      "Epoch 13/100\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - AUC: 0.9451 - accuracy: 0.8900 - loss: 0.3101 - val_AUC: 0.9365 - val_accuracy: 0.8504 - val_loss: 0.3340\n",
      "Epoch 14/100\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - AUC: 0.9593 - accuracy: 0.9018 - loss: 0.2727 - val_AUC: 0.9319 - val_accuracy: 0.8346 - val_loss: 0.3457\n",
      "Epoch 15/100\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - AUC: 0.9538 - accuracy: 0.8998 - loss: 0.2813 - val_AUC: 0.9328 - val_accuracy: 0.8583 - val_loss: 0.3363\n",
      "Epoch 16/100\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - AUC: 0.9567 - accuracy: 0.9037 - loss: 0.2753 - val_AUC: 0.9342 - val_accuracy: 0.8583 - val_loss: 0.3320\n",
      "Epoch 17/100\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - AUC: 0.9682 - accuracy: 0.9116 - loss: 0.2477 - val_AUC: 0.9315 - val_accuracy: 0.8583 - val_loss: 0.3354\n",
      "Epoch 18/100\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - AUC: 0.9641 - accuracy: 0.9057 - loss: 0.2580 - val_AUC: 0.9266 - val_accuracy: 0.8504 - val_loss: 0.3426\n",
      "Epoch 19/100\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - AUC: 0.9724 - accuracy: 0.9116 - loss: 0.2314 - val_AUC: 0.9289 - val_accuracy: 0.8583 - val_loss: 0.3352\n",
      "Epoch 20/100\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - AUC: 0.9692 - accuracy: 0.9175 - loss: 0.2350 - val_AUC: 0.9267 - val_accuracy: 0.8504 - val_loss: 0.3401\n",
      "Epoch 21/100\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - AUC: 0.9660 - accuracy: 0.9155 - loss: 0.2374 - val_AUC: 0.9297 - val_accuracy: 0.8583 - val_loss: 0.3350\n",
      "Epoch 22/100\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - AUC: 0.9798 - accuracy: 0.9391 - loss: 0.2017 - val_AUC: 0.9272 - val_accuracy: 0.8425 - val_loss: 0.3452\n",
      "Epoch 23/100\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - AUC: 0.9726 - accuracy: 0.9175 - loss: 0.2203 - val_AUC: 0.9241 - val_accuracy: 0.8425 - val_loss: 0.3532\n",
      "Epoch 24/100\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - AUC: 0.9727 - accuracy: 0.9116 - loss: 0.2186 - val_AUC: 0.9231 - val_accuracy: 0.8583 - val_loss: 0.3491\n",
      "Epoch 25/100\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - AUC: 0.9813 - accuracy: 0.9391 - loss: 0.1914 - val_AUC: 0.9240 - val_accuracy: 0.8583 - val_loss: 0.3523\n",
      "Epoch 26/100\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - AUC: 0.9800 - accuracy: 0.9253 - loss: 0.1947 - val_AUC: 0.9235 - val_accuracy: 0.8504 - val_loss: 0.3527\n",
      "Epoch 26: early stopping\n",
      "Restoring model weights from the end of the best epoch: 16.\n",
      "\n",
      "Evaluasi Fold...\n",
      "Fold 2 Selesai di Epoch 26.\n",
      "Fold 2 - FINAL METRICS (Val): AUC: 0.9342, Acc: 0.8583, MCC: 0.7168, Loss: 0.3320\n",
      "\n",
      "==========================================\n",
      "--- FOLD 3/5 ---\n",
      "==========================================\n",
      "Mulai Training...\n",
      "Epoch 1/100\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 26ms/step - AUC: 0.5571 - accuracy: 0.5265 - loss: 0.6881 - val_AUC: 0.8193 - val_accuracy: 0.7559 - val_loss: 0.6442\n",
      "Epoch 2/100\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - AUC: 0.8214 - accuracy: 0.7603 - loss: 0.6108 - val_AUC: 0.8552 - val_accuracy: 0.7795 - val_loss: 0.5818\n",
      "Epoch 3/100\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - AUC: 0.8580 - accuracy: 0.8075 - loss: 0.5458 - val_AUC: 0.8720 - val_accuracy: 0.7559 - val_loss: 0.5224\n",
      "Epoch 4/100\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - AUC: 0.8860 - accuracy: 0.8134 - loss: 0.4814 - val_AUC: 0.8852 - val_accuracy: 0.7717 - val_loss: 0.4789\n",
      "Epoch 5/100\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - AUC: 0.9031 - accuracy: 0.8251 - loss: 0.4314 - val_AUC: 0.8921 - val_accuracy: 0.7795 - val_loss: 0.4493\n",
      "Epoch 6/100\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - AUC: 0.9001 - accuracy: 0.8291 - loss: 0.4170 - val_AUC: 0.9012 - val_accuracy: 0.8031 - val_loss: 0.4205\n",
      "Epoch 7/100\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - AUC: 0.9162 - accuracy: 0.8507 - loss: 0.3878 - val_AUC: 0.9090 - val_accuracy: 0.8110 - val_loss: 0.4051\n",
      "Epoch 8/100\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - AUC: 0.9353 - accuracy: 0.8762 - loss: 0.3443 - val_AUC: 0.9167 - val_accuracy: 0.8110 - val_loss: 0.3868\n",
      "Epoch 9/100\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - AUC: 0.9344 - accuracy: 0.8782 - loss: 0.3390 - val_AUC: 0.9182 - val_accuracy: 0.8189 - val_loss: 0.3854\n",
      "Epoch 10/100\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - AUC: 0.9481 - accuracy: 0.8841 - loss: 0.3067 - val_AUC: 0.9191 - val_accuracy: 0.8268 - val_loss: 0.3799\n",
      "Epoch 10: early stopping\n",
      "Restoring model weights from the end of the best epoch: 1.\n",
      "\n",
      "Evaluasi Fold...\n",
      "WARNING:tensorflow:5 out of the last 12 calls to <function TensorFlowTrainer.make_predict_function.<locals>.one_step_on_data_distributed at 0x7c1ea427bd80> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Fold 3 Selesai di Epoch 10.\n",
      "Fold 3 - FINAL METRICS (Val): AUC: 0.8193, Acc: 0.7559, MCC: 0.5503, Loss: 0.6442\n",
      "\n",
      "==========================================\n",
      "--- FOLD 4/5 ---\n",
      "==========================================\n",
      "Mulai Training...\n",
      "Epoch 1/100\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 25ms/step - AUC: 0.6678 - accuracy: 0.6365 - loss: 0.6632 - val_AUC: 0.7946 - val_accuracy: 0.7165 - val_loss: 0.6254\n",
      "Epoch 2/100\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - AUC: 0.8059 - accuracy: 0.7446 - loss: 0.5945 - val_AUC: 0.8374 - val_accuracy: 0.7559 - val_loss: 0.5622\n",
      "Epoch 3/100\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - AUC: 0.8577 - accuracy: 0.7760 - loss: 0.5264 - val_AUC: 0.8511 - val_accuracy: 0.7953 - val_loss: 0.5111\n",
      "Epoch 4/100\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - AUC: 0.8829 - accuracy: 0.8075 - loss: 0.4739 - val_AUC: 0.8600 - val_accuracy: 0.7953 - val_loss: 0.4750\n",
      "Epoch 5/100\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - AUC: 0.9098 - accuracy: 0.8291 - loss: 0.4202 - val_AUC: 0.8615 - val_accuracy: 0.8031 - val_loss: 0.4545\n",
      "Epoch 6/100\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - AUC: 0.9207 - accuracy: 0.8389 - loss: 0.3849 - val_AUC: 0.8672 - val_accuracy: 0.8110 - val_loss: 0.4421\n",
      "Epoch 7/100\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - AUC: 0.9343 - accuracy: 0.8625 - loss: 0.3567 - val_AUC: 0.8733 - val_accuracy: 0.8031 - val_loss: 0.4334\n",
      "Epoch 8/100\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - AUC: 0.9335 - accuracy: 0.8644 - loss: 0.3416 - val_AUC: 0.8744 - val_accuracy: 0.8031 - val_loss: 0.4301\n",
      "Epoch 9/100\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - AUC: 0.9450 - accuracy: 0.8821 - loss: 0.3157 - val_AUC: 0.8764 - val_accuracy: 0.8110 - val_loss: 0.4297\n",
      "Epoch 10/100\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - AUC: 0.9519 - accuracy: 0.8900 - loss: 0.2976 - val_AUC: 0.8736 - val_accuracy: 0.8189 - val_loss: 0.4336\n",
      "Epoch 10: early stopping\n",
      "Restoring model weights from the end of the best epoch: 1.\n",
      "\n",
      "Evaluasi Fold...\n",
      "WARNING:tensorflow:6 out of the last 13 calls to <function TensorFlowTrainer.make_predict_function.<locals>.one_step_on_data_distributed at 0x7c1e940799e0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Fold 4 Selesai di Epoch 10.\n",
      "Fold 4 - FINAL METRICS (Val): AUC: 0.7946, Acc: 0.7165, MCC: 0.4371, Loss: 0.6254\n",
      "\n",
      "==========================================\n",
      "--- FOLD 5/5 ---\n",
      "==========================================\n",
      "Mulai Training...\n",
      "Epoch 1/100\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 23ms/step - AUC: 0.6513 - accuracy: 0.6071 - loss: 0.6641 - val_AUC: 0.7949 - val_accuracy: 0.7480 - val_loss: 0.6378\n",
      "Epoch 2/100\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - AUC: 0.8315 - accuracy: 0.7760 - loss: 0.5815 - val_AUC: 0.8033 - val_accuracy: 0.7559 - val_loss: 0.5917\n",
      "Epoch 3/100\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - AUC: 0.8577 - accuracy: 0.7937 - loss: 0.5321 - val_AUC: 0.8109 - val_accuracy: 0.7638 - val_loss: 0.5502\n",
      "Epoch 4/100\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - AUC: 0.8834 - accuracy: 0.8330 - loss: 0.4716 - val_AUC: 0.8245 - val_accuracy: 0.7717 - val_loss: 0.5196\n",
      "Epoch 5/100\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - AUC: 0.9191 - accuracy: 0.8507 - loss: 0.4021 - val_AUC: 0.8383 - val_accuracy: 0.7795 - val_loss: 0.5015\n",
      "Epoch 6/100\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - AUC: 0.9248 - accuracy: 0.8546 - loss: 0.3754 - val_AUC: 0.8420 - val_accuracy: 0.7874 - val_loss: 0.4954\n",
      "Epoch 7/100\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - AUC: 0.9282 - accuracy: 0.8507 - loss: 0.3603 - val_AUC: 0.8398 - val_accuracy: 0.7953 - val_loss: 0.4903\n",
      "Epoch 8/100\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - AUC: 0.9328 - accuracy: 0.8743 - loss: 0.3401 - val_AUC: 0.8445 - val_accuracy: 0.8031 - val_loss: 0.4864\n",
      "Epoch 9/100\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - AUC: 0.9514 - accuracy: 0.8939 - loss: 0.2998 - val_AUC: 0.8513 - val_accuracy: 0.8031 - val_loss: 0.4817\n",
      "Epoch 10/100\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - AUC: 0.9450 - accuracy: 0.8802 - loss: 0.3127 - val_AUC: 0.8557 - val_accuracy: 0.7953 - val_loss: 0.4811\n",
      "Epoch 10: early stopping\n",
      "Restoring model weights from the end of the best epoch: 1.\n",
      "\n",
      "Evaluasi Fold...\n",
      "Fold 5 Selesai di Epoch 10.\n",
      "Fold 5 - FINAL METRICS (Val): AUC: 0.7949, Acc: 0.7480, MCC: 0.4960, Loss: 0.6378\n",
      "\n",
      "===== HASIL AKHIR (Cross-Validation) =====\n",
      "AUC: 0.8478 ± 0.0569\n",
      "Accuracy: 0.7798 ± 0.0517\n",
      "MCC: 0.5682 ± 0.1001\n",
      "Loss: 0.5288 ± 0.1331\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import matthews_corrcoef\n",
    "\n",
    "# ====================================================================\n",
    "# C. IMPLEMENTASI STRATIFIED K-FOLD CROSS-VALIDATION (dengan MCC)\n",
    "# ====================================================================\n",
    "\n",
    "# Hyperparameter yang akan difiksasi\n",
    "N_BITS = 1024 \n",
    "N_SPLITS = 5      # Jumlah Fold\n",
    "BATCH_SIZE = 32\n",
    "EPOCHS = 100    # Dibuat besar, Early Stopping yang akan mengontrol\n",
    "\n",
    "# Inisialisasi Stratified K-Fold\n",
    "skf = StratifiedKFold(n_splits=N_SPLITS, shuffle=True, random_state=42)\n",
    "fold_results = []\n",
    "fold_no = 1\n",
    "\n",
    "# Definisikan Callback Early Stopping\n",
    "early_stopping_callback = EarlyStopping(\n",
    "    monitor='val_loss', \n",
    "    patience=10, \n",
    "    restore_best_weights=True,\n",
    "    verbose=1 \n",
    ")\n",
    "\n",
    "# Loop untuk setiap Fold\n",
    "for train_index, val_index in skf.split(X, y):\n",
    "    print(f\"\\n==========================================\")\n",
    "    print(f\"--- FOLD {fold_no}/{N_SPLITS} ---\")\n",
    "    print(f\"==========================================\")\n",
    "    \n",
    "    # A. Pembagian Data per Fold\n",
    "    X_train, X_val = X[train_index], X[val_index]\n",
    "    y_train, y_val = y[train_index], y[val_index]\n",
    "\n",
    "    # B. Buat Ulang Model BARU\n",
    "    model_cv = build_lstm_model(nBits=N_BITS)\n",
    "    \n",
    "    # C. Training Model\n",
    "    print(\"Mulai Training...\")\n",
    "    history = model_cv.fit(\n",
    "        X_train, y_train,\n",
    "        epochs=EPOCHS, \n",
    "        batch_size=BATCH_SIZE,\n",
    "        validation_data=(X_val, y_val), \n",
    "        callbacks=[early_stopping_callback],\n",
    "        verbose=1\n",
    "    )\n",
    "    \n",
    "    # D. Evaluasi dan Simpan Hasil\n",
    "    print(\"\\nEvaluasi Fold...\")\n",
    "    loss, accuracy, auc = model_cv.evaluate(X_val, y_val, verbose=0)\n",
    "    \n",
    "    # Hitung prediksi buat MCC\n",
    "    y_val_pred_prob = model_cv.predict(X_val, verbose=0)\n",
    "    y_val_pred = (y_val_pred_prob > 0.5).astype(\"int32\")\n",
    "    mcc = matthews_corrcoef(y_val, y_val_pred)\n",
    "    \n",
    "    print(f\"Fold {fold_no} Selesai di Epoch {len(history.history['loss'])}.\")\n",
    "    print(f\"Fold {fold_no} - FINAL METRICS (Val): AUC: {auc:.4f}, Acc: {accuracy:.4f}, MCC: {mcc:.4f}, Loss: {loss:.4f}\")\n",
    "    \n",
    "    fold_results.append({'AUC': auc, 'Accuracy': accuracy, 'MCC': mcc, 'Loss': loss})\n",
    "\n",
    "    fold_no += 1\n",
    "\n",
    "# Setelah semua fold, lo bisa bikin summary\n",
    "print(\"\\n===== HASIL AKHIR (Cross-Validation) =====\")\n",
    "for metric in ['AUC', 'Accuracy', 'MCC', 'Loss']:\n",
    "    values = [f[metric] for f in fold_results]\n",
    "    print(f\"{metric}: {np.mean(values):.4f} ± {np.std(values):.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c336c842",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XGB AUC: 0.790072496947497\n",
      "XGB Accuracy: 0.7280511811023622\n",
      "XGB Results - AUC: 0.7901, Accuracy: 0.7281\n"
     ]
    }
   ],
   "source": [
    "from xgboost import XGBClassifier\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "xgb = XGBClassifier(eval_metric=\"logloss\")\n",
    "\n",
    "# Get AUC scores\n",
    "auc_scores = cross_val_score(xgb, X, y, cv=5, scoring=\"roc_auc\")\n",
    "print(\"XGB AUC:\", auc_scores.mean())\n",
    "\n",
    "# Get Accuracy scores\n",
    "acc_scores = cross_val_score(xgb, X, y, cv=5, scoring=\"accuracy\")\n",
    "print(\"XGB Accuracy:\", acc_scores.mean())\n",
    "\n",
    "# Optional: Show both metrics together\n",
    "print(f\"XGB Results - AUC: {auc_scores.mean():.4f}, Accuracy: {acc_scores.mean():.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1803d7e9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py311",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
