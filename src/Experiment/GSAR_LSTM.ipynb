{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "NtWs_gRbiiNa",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NtWs_gRbiiNa",
        "outputId": "c667cbec-ab33-450e-bb8c-b54dc2da9ca5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting rdkit\n",
            "  Downloading rdkit-2025.3.6-cp311-cp311-manylinux_2_28_x86_64.whl.metadata (4.1 kB)\n",
            "Requirement already satisfied: numpy in /home/dito-adistya/miniconda3/envs/py311/lib/python3.11/site-packages (from rdkit) (2.3.3)\n",
            "Requirement already satisfied: Pillow in /home/dito-adistya/miniconda3/envs/py311/lib/python3.11/site-packages (from rdkit) (11.3.0)\n",
            "Downloading rdkit-2025.3.6-cp311-cp311-manylinux_2_28_x86_64.whl (36.2 MB)\n",
            "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m36.2/36.2 MB\u001b[0m \u001b[31m2.1 MB/s\u001b[0m  \u001b[33m0:00:17\u001b[0m\u001b[0m eta \u001b[36m0:00:01\u001b[0m[36m0:00:01\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: rdkit\n",
            "Successfully installed rdkit-2025.3.6\n"
          ]
        }
      ],
      "source": [
        "!pip install rdkit"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "e622c5e3-da15-4454-9afc-ba501d9e1e62",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e622c5e3-da15-4454-9afc-ba501d9e1e62",
        "outputId": "a74bed9e-69fd-4d2f-a86c-add4b6bfad3f",
        "scrolled": true
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2025-10-15 11:21:41.373456: I external/local_xla/xla/tsl/cuda/cudart_stub.cc:31] Could not find cuda drivers on your machine, GPU will not be used.\n",
            "2025-10-15 11:21:41.969897: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "2025-10-15 11:21:44.207605: I external/local_xla/xla/tsl/cuda/cudart_stub.cc:31] Could not find cuda drivers on your machine, GPU will not be used.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Packages imported successfully.\n"
          ]
        }
      ],
      "source": [
        "# prompt: import essential packages\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import sklearn\n",
        "import tensorflow as tf\n",
        "#import torch\n",
        "from sklearn.preprocessing import StandardScaler, LabelEncoder # Atau OneHotEncoder\n",
        "from rdkit import Chem\n",
        "from rdkit.Chem import Descriptors\n",
        "from rdkit.Chem import AllChem # Untuk MACCS Keys\n",
        "\n",
        "print(\"Packages imported successfully.\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e27ea89e-438b-4211-846e-a0c3c75cc537",
      "metadata": {
        "id": "e27ea89e-438b-4211-846e-a0c3c75cc537"
      },
      "source": [
        "# Import Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "id": "5b692e63-3803-4334-a08c-274d1581d2c0",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5b692e63-3803-4334-a08c-274d1581d2c0",
        "outputId": "dca522fa-423b-4ee5-e36e-ff905a48cf02"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Data kosong = cid           0\n",
            "smiles        0\n",
            "acvalue       0\n",
            "categories    0\n",
            "dtype: int64\n"
          ]
        }
      ],
      "source": [
        "# Baca CSV tanpa header\n",
        "df = pd.read_csv(\"https://raw.githubusercontent.com/adistyadito/LSTM-MBA/refs/heads/main/GSARPC3.csv\")\n",
        "\n",
        "# Tampilkan beberapa baris pertama\n",
        "df\n",
        "\n",
        "# Check for missing values\n",
        "print(f'Data kosong = {df.isnull().sum()}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "2c7b6dfe",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Name</th>\n",
              "      <th>PubchemFP0</th>\n",
              "      <th>PubchemFP1</th>\n",
              "      <th>PubchemFP2</th>\n",
              "      <th>PubchemFP3</th>\n",
              "      <th>PubchemFP4</th>\n",
              "      <th>PubchemFP5</th>\n",
              "      <th>PubchemFP6</th>\n",
              "      <th>PubchemFP7</th>\n",
              "      <th>PubchemFP8</th>\n",
              "      <th>...</th>\n",
              "      <th>PubchemFP871</th>\n",
              "      <th>PubchemFP872</th>\n",
              "      <th>PubchemFP873</th>\n",
              "      <th>PubchemFP874</th>\n",
              "      <th>PubchemFP875</th>\n",
              "      <th>PubchemFP876</th>\n",
              "      <th>PubchemFP877</th>\n",
              "      <th>PubchemFP878</th>\n",
              "      <th>PubchemFP879</th>\n",
              "      <th>PubchemFP880</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>44244736</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>44244911</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>44245235</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>10451021</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>44245073</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>631</th>\n",
              "      <td>145958114</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>632</th>\n",
              "      <td>145950639</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>633</th>\n",
              "      <td>3168508</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>634</th>\n",
              "      <td>145952863</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>635</th>\n",
              "      <td>145955648</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>636 rows × 882 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "          Name  PubchemFP0  PubchemFP1  PubchemFP2  PubchemFP3  PubchemFP4  \\\n",
              "0     44244736           1           1           1           0           0   \n",
              "1     44244911           1           1           1           0           0   \n",
              "2     44245235           1           1           1           0           0   \n",
              "3     10451021           1           1           1           0           0   \n",
              "4     44245073           1           1           1           0           0   \n",
              "..         ...         ...         ...         ...         ...         ...   \n",
              "631  145958114           1           1           1           0           0   \n",
              "632  145950639           1           1           1           0           0   \n",
              "633    3168508           1           1           0           0           0   \n",
              "634  145952863           1           1           1           0           0   \n",
              "635  145955648           1           1           1           0           0   \n",
              "\n",
              "     PubchemFP5  PubchemFP6  PubchemFP7  PubchemFP8  ...  PubchemFP871  \\\n",
              "0             0           0           0           0  ...             0   \n",
              "1             0           0           0           0  ...             0   \n",
              "2             0           0           0           0  ...             0   \n",
              "3             0           0           0           0  ...             0   \n",
              "4             0           0           0           0  ...             0   \n",
              "..          ...         ...         ...         ...  ...           ...   \n",
              "631           0           0           0           0  ...             0   \n",
              "632           0           0           0           0  ...             0   \n",
              "633           0           0           0           0  ...             0   \n",
              "634           0           0           0           0  ...             0   \n",
              "635           0           0           0           0  ...             0   \n",
              "\n",
              "     PubchemFP872  PubchemFP873  PubchemFP874  PubchemFP875  PubchemFP876  \\\n",
              "0               0             0             0             0             0   \n",
              "1               0             0             0             0             0   \n",
              "2               0             0             0             0             0   \n",
              "3               0             0             0             0             0   \n",
              "4               0             0             0             0             0   \n",
              "..            ...           ...           ...           ...           ...   \n",
              "631             0             0             0             0             0   \n",
              "632             0             0             0             0             0   \n",
              "633             0             0             0             0             0   \n",
              "634             0             0             0             0             0   \n",
              "635             0             0             0             0             0   \n",
              "\n",
              "     PubchemFP877  PubchemFP878  PubchemFP879  PubchemFP880  \n",
              "0               0             0             0             0  \n",
              "1               0             0             0             0  \n",
              "2               0             0             0             0  \n",
              "3               0             0             0             0  \n",
              "4               0             0             0             0  \n",
              "..            ...           ...           ...           ...  \n",
              "631             0             0             0             0  \n",
              "632             0             0             0             0  \n",
              "633             0             0             0             0  \n",
              "634             0             0             0             0  \n",
              "635             0             0             0             0  \n",
              "\n",
              "[636 rows x 882 columns]"
            ]
          },
          "execution_count": 3,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df = pd.read_csv('/home/dito-adistya/Dito/TA/Coding/LSTM-MBA/data/outputFingerprint.csv')\n",
        "df"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0facd50c-cdca-4e3d-9680-6bf49b0002c4",
      "metadata": {
        "id": "0facd50c-cdca-4e3d-9680-6bf49b0002c4"
      },
      "source": [
        "**Preprocess**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "id": "81cb23a5-e2e7-41a3-8de2-a3bcf785468e",
      "metadata": {
        "id": "81cb23a5-e2e7-41a3-8de2-a3bcf785468e"
      },
      "outputs": [],
      "source": [
        "from rdkit import Chem\n",
        "from rdkit.Chem import AllChem # Tetep perlu buat beberapa hal di RDKit\n",
        "from rdkit.Chem import rdFingerprintGenerator # Import generator\n",
        "smiles_clean = df['smiles'].tolist()\n",
        "\n",
        "mols = []\n",
        "for smiles in smiles_clean:\n",
        "    mol = Chem.MolFromSmiles(smiles)\n",
        "    if mol is not None:\n",
        "        mols.append(mol)\n",
        "    else:\n",
        "        print(f\"Warning: Could not create mol object for SMILES: {smiles}\")\n",
        "        pass # Skip adding None\n",
        "\n",
        "# --- Langkah 4: Generate Fingerprint dari List Objek Molekul (mols) ---\n",
        "# Parameter fingerprint\n",
        "radius = 2\n",
        "nBits = 1024 # Ukuran vektor fingerprint\n",
        "\n",
        "# Bikin generatornya\n",
        "fpgen = rdFingerprintGenerator.GetMorganGenerator(radius=radius, fpSize=nBits)\n",
        "\n",
        "fingerprints = []\n",
        "# Sekarang lu iterasi di list 'mols' yang isinya objek molekul\n",
        "for mol in mols:\n",
        "    # Cek lagi kalau-kalau ada None di list mols (meskipun seharusnya nggak ada kalau langkah 3 bener)\n",
        "    if mol is not None:\n",
        "        # Panggil generator untuk bikin fingerprint\n",
        "        fp = fpgen.GetFingerprint(mol)\n",
        "        # Ubah BitVector ke numpy array\n",
        "        fingerprints.append(np.array(fp))\n",
        "    else:\n",
        "        # Handle kalau ada None di mols (misalnya append vektor nol)\n",
        "        fingerprints.append(np.zeros(nBits))\n",
        "\n",
        "# Konversi list fingerprints jadi NumPy array besar (Ini X lu)\n",
        "X = np.array(fingerprints)\n",
        "\n",
        "# --- Langkah 5: Siapkan Data Target (y) ---\n",
        "# Pastiin nama kolom target lu bener\n",
        "df['label'] = df['categories'].map({'inhibitor': 1, 'neutral': 0})\n",
        "y = df['label'].values\n",
        "\n",
        "# --- Langkah 6: Split Data (Train/Test/Validation) ---\n",
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "id": "UT3CZSt5XEnR",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UT3CZSt5XEnR",
        "outputId": "d184ff75-0bab-426c-936c-874b24576c69"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "DataFrame Original:\n",
            "        cid                                             smiles  acvalue  \\\n",
            "0  44244736  COC1=C(C(=C(C=C1)C2=C(OC(=N2)C3=CC=CC=C3F)SC4=...   0.0030   \n",
            "1  44244911  CC1=NN=C(S1)SC2=C(N=C(O2)C3=CC=CC=C3F)C4=C(C(=...   0.0035   \n",
            "2  44245235  COC1=C(C(=C(C=C1)C2=C(OC(=N2)C3=CN=CC=C3)SC4=N...   0.0047   \n",
            "3  10451021  CC(=CC1=CC(=C(C=C1)OC)O)C(=O)C2=CC(=C(C(=C2)OC...   0.0090   \n",
            "4  44245073  CC1=CN=C(N=C1C)SC2=C(N=C(O2)C3=CC=CC=C3Cl)C4=C...   0.0180   \n",
            "\n",
            "  categories  label  \n",
            "0  inhibitor      1  \n",
            "1  inhibitor      1  \n",
            "2  inhibitor      1  \n",
            "3  inhibitor      1  \n",
            "4  inhibitor      1  \n",
            "\n",
            "List of RDKit Mol Objects (first 5):\n",
            "Mol object 1: 34 atoms\n",
            "Mol object 2: 31 atoms\n",
            "Mol object 3: 30 atoms\n",
            "Mol object 4: 26 atoms\n",
            "Mol object 5: 33 atoms\n",
            "\n",
            "NumPy Array of Fingerprints (X - shape):\n",
            "(636, 1024)\n",
            "\n",
            "NumPy Array of Fingerprints (X - first row):\n",
            "[0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0]\n"
          ]
        }
      ],
      "source": [
        "# prompt: print df yang asli dengan dataset yang diproses dari mols from smiles dan yang sudah diproses dengan fingerprint\n",
        "\n",
        "print(\"\\nDataFrame Original:\")\n",
        "print(df.head())\n",
        "\n",
        "print(\"\\nList of RDKit Mol Objects (first 5):\")\n",
        "# Print first 5 mol objects to show they were created\n",
        "for i, mol in enumerate(mols[:5]):\n",
        "    if mol:\n",
        "        print(f\"Mol object {i+1}: {mol.GetNumAtoms()} atoms\")\n",
        "    else:\n",
        "         print(f\"Mol object {i+1}: None\")\n",
        "\n",
        "print(\"\\nNumPy Array of Fingerprints (X - shape):\")\n",
        "print(X.shape)\n",
        "print(\"\\nNumPy Array of Fingerprints (X - first row):\")\n",
        "print(X[0][:20]) # Print first 20 bits of the first fingerprint\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "ZiYU0_w3YEcz",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 406
        },
        "id": "ZiYU0_w3YEcz",
        "outputId": "dc15debf-c2c5-4a6e-df81-1aec292163ad"
      },
      "outputs": [
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# prompt: coba draw salah satu smiles\n",
        "\n",
        "from rdkit.Chem.Draw import IPythonConsole\n",
        "from rdkit.Chem import Draw\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Pilih salah satu objek molekul dari list `mols`\n",
        "# Misalnya, kita ambil molekul pertama\n",
        "mol_to_draw = mols[0]\n",
        "\n",
        "# Jika mol_to_draw bukan None, maka gambar\n",
        "if mol_to_draw is not None:\n",
        "  # Gambar molekul\n",
        "  img = Draw.MolToImage(mol_to_draw)\n",
        "\n",
        "  # Tampilkan gambar\n",
        "  plt.imshow(img)\n",
        "  plt.axis('off') # Matikan sumbu\n",
        "  plt.show()\n",
        "else:\n",
        "  print(\"Objek molekul pertama tidak valid.\")\n",
        "\n",
        "# Anda juga bisa mencoba menggambar molekul lain, misalnya molekul ke-50:\n",
        "# mol_to_draw_50 = mols[49] # Indeks dimulai dari 0\n",
        "# if mol_to_draw_50 is not None:\n",
        "#   img_50 = Draw.MolToImage(mol_to_draw_50)\n",
        "#   plt.imshow(img_50)\n",
        "#   plt.axis('off')\n",
        "#   plt.show()\n",
        "# else:\n",
        "#    print(\"Objek molekul ke-50 tidak valid.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "OekkKlPmYLqX",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 167
        },
        "id": "OekkKlPmYLqX",
        "outputId": "78f9fe64-b483-4f14-fab0-25f452f9731e"
      },
      "outputs": [
        {
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAcIAAACWCAIAAADCEh9HAAAABmJLR0QA/wD/AP+gvaeTAAAgAElEQVR4nO3daVhT19YH8JUQ5pkAMokYL6gMIoKiFYIDOICIA7wOFRS1Fhz6arVardZaWxS9Wvu22KL2Og8FqzgUFRCZbJVJQUBABRTLoAkQTCCEJOf9cLxcrp0gOQGTrN/jh5TkrLN42v7d52SfvWkEQQBCCCFZ0fu7AYQQUm4YowghJBeMUYQQkgvGKEIIyQVjFCGE5IIxiv4Kh8O5du3a8uXLCwoK+rsXhN5SNJzwhLqIxeKKioqysrLS0tKCgoKysrKqqioAoNFodDr90qVLQUFB/d0jQm8djFG11tDQ8ODBg/v37z948KC4uPjhw4cikaj7B4yMjFxdXR8/fvzixQtzc/M7d+4MGTKkv7pF6O2EMap2fvzxx8TERB6PV1xc/OLFi+5v0el0Fovl7u4+YsSIwYMH0+n0Fy9eiMXi9evXz5kz59KlS8OGDfvll19MTU37q3mE3kIYo+olMTFx/vz5UqmU/EcjIyNHR0dnZ2cPDw9bW1sajdZ1OV9dXU3+t8FkMjkcDp/P9/HxKSoq8vPzS0lJ0dLS6tffA6G3CKO/G0B9KiMjQyqV2tvb79mzRywWNzY2FhcXFxcXJyQkdHR0dP+kgYGBq6srOTIVi8UGBgbJycne3t6ZmZnR0dE//PBDf/0KCL1tcDSqRiQSiZ2dXUNDQ25ubmNjY3BwcPd3ra2tPT09XVxcnJ2dPT09hw8fTqe/OZGjsLCQzWYLBIJ9+/Z9+OGHfdg7Qm8vjFE1cv369enTpzs6OlZWVj5//nz+/PkjRowgx5uurq6GhoY9KXLhwoWwsDDyRUhIiIJbRkgJYIyqkfDw8FOnTn3++efbtm2Tp05MTMwnn3xiYGCQnZ09cuRIqtpDSElhjKoLgUBgZWUlEAgeP37MYrHkrLZixYrDhw/b2NjcvXvXzs6Okg4RUlL4FJO6uHjxIp/Pf+edd+TPUACIi4ubOHFiXV1dSEiIQCCQvyBCygtjVF2cPn0aAN59911Kqmlqap4/f97R0bGwsDAiIqJrBhVCaggv6tXCixcvyGmhdXV15ubmVJWtqKgYN25cc3Pz5s2bY2JiqCqLkHLB0ahaOHPmjFgsDgwMpDBDAWDo0KFJSUlaWlq7du1at24dhZURUiIYo2qB2iv6LgRBsNnsffv2AcB3332Hl/ZIPWGMqr5Hjx7l5+cbGRnNmDGDwrLt7e0sFisqKsrd3Z38iUQiobA+QsoCHwZVfSdPngSAsLAwXV1dCstevny5pqamqKiIfL5+9erVmpqaFNZHSFngaFTFEQShoCt6suyCBQsSEhIUUR8hZYExquJ++eWXqqoqW1tbNptNYdmmpqYbN24wGAwmk9nY2Dh8+HAPDw8K6yOkRDBGVdyRI0cAYNGiRRoaGk1NTVSVPXv2rEgkmjp16s8//0zWp6oyQkoHY1TFnTt3DgC8vb1TU1P/8Y9/nD17lpKy5BV9aGjo5cuXaTTaggULKCmLkDLCGFVxAwYMAID/+7//Kyoqam5uXrp06Z07d+Ss+eTJkzt37ujr64tEIoFA4OvrO3jwYCqaRUgpYYyquJSUFDs7u4yMjLKyspUrVwqFwtmzZz979kyemqdOnSIIIjQ09Pz584BfLiG1hzGq4pycnC5fvqyvr3/06NFBgwYFBAQ0NDQEBgbyeDyZa5J3BqZPn56enq6lpTV37lzq+kVI+WCMqj4PD4+TJ0/S6fTNmzcvWbLE1dW1tLR0wYIFss2Wv3v3bkVFhbW19bNnzyQSyYwZM5hMJuU9I6REMEbVwuzZs2NiYqRS6fLly7/88ktLS8tr165t2LBBhlLkl0sLFy4kx6R4RY8QEEhtvP/++wBgY2Nz4cIFbW1tAIiLi+tVhc7OTvI7q59++gkATE1NhUKhgrpFSFngaFSNfPPNN5MmTaqrq9u5c+ehQ4doNNoHH3xATvzsoZSUFHKyfX5+PgCEhYWRcYyQOsMYVSOampqJiYlOTk737t1LSkrasmWLRCJZuHBhSUlJDyt0dHQ4OTm9++67eEWPUBdctlntVFVVeXt7czicTZs21dbWnjlzxsHB4e7du5aWlj2skJaWFhAQYG9vX11d/ftNmBFSN/j/gNphsVgXLlzQ0tKKjY0dN26ct7d3TU3N8uXL//ooDodz8+bNr776aunSpYsXLwaA6dOnY4YiBDgaVVtHjx5dunSppqbmmTNn4uPj4+LinJycut4Vi8XPnj0rLS0tKCgoKCgoKyurqqrqfri2tratrW1eXp6ZmVmf947Q2wVjVH1t3Lhx7969ZmZmv/76q7GxcXFxcVFRUXFx8YMHD8rKykQiUfcPGxoaurm5ubm5jRw50snJaePGjQUFBWw2OzU1lVxvFCG1hTGqvqRS6dy5c5OSkgwMDPh8fve36HQ6i8Vyd3cfMWKEm5ubu7v74MGDaTRa1wfq6uq8vb2fP38eGRn5r3/9q897R+gtgjGq1l68eDFw4EA9PT2pVOro6Ojs7Ozp6enp6Tly5EgDA4O/PvbevXu+vr4CgWDv3r2yzeRHSDVgjKq1EydOLF68+J133rl9+7YMh1+8eDE0NBQAfvrpp1mzZlHdHULKAb9pVWvkk53kN+8y6HrGdOHChXl5eZS2hpDSwNGo+mpsbLSzs6PT6XV1dfIsLxIVFRUfH29jY3P37l07OzsKO0RIKeBoVH2dPn1aLBbLv0RT1zOmM2fOFAgEVLWHkLLAGFVfVO0Y2v0Z0/DwcKlUSkV3CCkNjFE1VdXaaurrazFgQFBQkPzVzMzMrl27Zm5ufvHixS1btvT28PZ2OH8eAEAqhVu35G8HoT6FMaqmrr961RIe/uGvv1K1RFP3Z0zj4+N7dWxrK6xeDenpIJXC0aOUtINQ32H0dwOoHxAA15ubAWCKuTmFZX19fb///vulS5euWbPG0dFx0qRJXW/x+Xwul8vltnE4w7lc6PrT1ARcLqxeDfPnQ1wceHtT2A5CfQRjVB3d4/PrOjqstLRGGhpSWzkyMvLhw4d79+6dNWvWiBEjeDwel8vlcrnko6U2NmPr6n79/VHBwaCpCWvWwP791LaDUF/AGFVH17lcAJhuZqaIezq7d+9OTk5ubW3tPqXfwMDAzMzM1lbfxQWYzP/8MTQEBgNYLKiuhgkT4OxZBTSEkIJhjKqdToK42dICANMUszgTnU4XiUS1tbXx8fEODg6NjY1isbhrWNrcvOjFi1MPH76+om9rAwDYsgUCAwEAduyAn38GgoBuj+8j9LbDGFU72TweTyweqqc3RFdXEfXr6+sfPXpkYGCwdOnSvXv3/v6LewODk3z+65jU0QEmE/T1YeJEAICtW+HoUbC3h4AARbSGkEJgjKqd4Xp671lb2ypsD6XMzEwA8PHxYTAYzs7OgYGBTCbTzMyM+W+WlmJTU03yol5P77+OdXAAqRTi4zFGkTLBGFUjtR0dn9XUOOvp2Whrz1DY5vJZWVkAwGazASAkJCQkJKTnxy5fDp9/DpcuwW+/ga2tghpEiGI4b1SNEAThZWi4fuDABT3edkkG5GjUz89PhmOtrCAkBMRi+OEHqtvqpq2t7eLFi1wuV4HnQOoElyZRI8+Ewq01NW76+mONjHyNjRVxCg6HY2lpqaur29zcLNuq+OnpMHky2NlBdTUwFHCxVF1d7erq2tbWpqGhMXLkyPHjx/v4+Pj7+5uamlJ/MqQeMEbVyDOh8OempmgbGwWe48KF8o8+ejRpUvDhwzLXcHGBsjJISoLe3A/okbq6Oj8/v8ePHzMYDIIgJBIJ+XMNDQ0PDw82m+3n5+fj44MbTKFewXujaoRGo2kpeiZRZuawqqphsi5gSnr/fdG5cxcvXboXErKbqr4AgMPhTJky5fHjxyNHjkxPT8/Pz29ubi4rK7t9+3Z2dnZ+fn5+fv7+/fsBgMVi+fv7jx8/fuLEiQMHDqSwB6SScDSKKOXhAffvQ0YGyHRvlNTS0mJra9ve3l5RUeHo6EhJXzweb/LkyQUFBW5ubrdu3TI1NbWwsGhqamKxWOPHjx8zZoypqWllZWVGRkZubq5QKOw6cPjw4Ww2e/DgwQsXLsRIRX8IYxRRh8cDJhMYDGhuBvkmpUZGRh47dmzjxo2xsbHy9yUQCKZNm5aTk+Po6JiZmWltbc3hcBYtWnT79u3ue/kNHjyYzWb7+vqam5uXl5fn5ORkZ2fzeDzyXUtLy9LSUnNKVyFAqgFjFFHnyhWYORN8fSErS85Kubm53t7e5ubmtbW1Ojo68pRqb28PDAzMyMiwt7fPysoaNGhQ11sSiaS8vPz27dtpaWk3b95samrqesvKysrX13fs2LGmpqaNjY2ffvppZ2fnqVOn5F+eFakgAiGqbNhAABBbt1JSzNPTEwBOnTolT5GOjg5yQVVbW9snT578xSclEklJSUl8fHxYWJiFhUX3/0d+++237du3A8DKlSvlaQapKoxRRB1fXwKAuHFDzjL3798nCOLQoUMAMH78eJnriMXisLAwALCwsCgtLe35gVKptKSkJC4ubt68eWw2myCI3NxcALC3t5e5GaTC8KIeUaSqCp48AQDw8ZH5xihBEDt27Pj888+PHz8+e/ZsS0tLsVgcHBw8depUX1/f4cOH97yUVCoNDw8/c+aMiYnJzZs3R40aJVtLXdVsbW0bGhpKSkpcXFzkKYVUDz7FhKhw4gQcOgQdHfD999DYKFuN9vb2efPm7dixQ0NDg8/nR0VFtbe3GxsbX7hw4f3333d2dh4wYEBwcHBsbGxBQcFf7/hEEER0dPSZM2eMjIxSUlLkzFAAoNPp06ZNA4Cff/5ZzlJIBfXzaBiphpkzX7/IzSV27JChQH19/ZgxYwDA0NDw7Nmz5CP5BgYGcXFx5MW1tbV19/9umUxmSEjI/v378/PzxWLxG9XWr18PAHp6ehkZGXL+Zl0SEhIAwM/Pj6qCSGVgjCIqzJr1+sWjR8T69b09uri4mPwCncViJScnOzk5AYCtrW1hYWH3jz158uT48eMrVqwYPHhw90g1MDDw9/ffvn17amqqUCjcvHkzAGhpaSUnJ1Pyy5F4PJ6mpiaDwWhubqawLFIBGKOICu+9R5SXEwRB7NlDXL5MbN1KfPMN8btB4h+6fv26sbExAIwbNy4hIcHExAQAvL296+vr/+KoqqqqY8eORUZGDhkypHukkrOjNDU1L1++TMlv1h253kpCQgLllQmCePjwYU5OjiIqI0XDGEVUaG4mNm8m1q4l4uOJykpCQ4MAILy8iIKCvz4uPj6ewWAAwLx58+Li4jQ1NQEgNDRUIBD0/OT19fUJCQkffPCBp6cnjUYzNjZev349QRAPHjzg8/ly/V7/bc+ePQCwZMkSCmuSnjx5Ymtrq6+vn5ubS3lxpGgYo0gBLl8mBg0iAAg6nVixguDxfv8RsVi8evVqAKDRaJ9++ummTZvI15s2bZJIJDKfmVxsf9myZaGhoQBw/vx5OX6NN5WUlACApaWlPB3+Xm1tLXmbYvz48dTmPuobGKNIMV69Ij78kGAwCADC1pZ/8WL3N1tbW8lZ8dra2keOHAkODiZfHz9+XM7T3r9/HwCsra2//PJLMk/lLPgGBwcHAKBwzNjY2EhO5Bo7dmxraytVZVFfwhhFilRURIwbR9Dp77m6Tpo0qZy8f0oQ5NjTysrq6tWr5GwkJpOZmZlJyTnt7e0B4McffyTzVCqVUlKWtHLlSgDYvn07JdWam5s9PDwAwN3dncvlUlIT9T2MUaRgEkn18ePkF0d6enoxMTEikai9vX3ZsmVJSUlWVlYA4OjoWFFRQdUJV6xYAQA7d+4k87Tg7+7P9srVq1cBYPTo0RTUammpnzvX2sDAxcXl5cuXFBRE/QRjFPWFhoaG8PBwGo1GhmZaWlpiYqKenh4ABAQEUDuFKCkpifzevytPKSze1tamp6dHp9MbGhrkKvTqFfHOOwQAZ+rUuro6irpD/QNjFPWd1NRUcv1QGo1GRmp0dHRnZye1Z+Hz+To6OnQ6/cSJE+Q9R2rrT58+HQCOHTsmewmhkJg6lQAgBg4kqqsp6wz1E3wYFPUdf3//0tLS3bt36+vrm5ubb9269eDBgwyqd1zS19dns9lSqVQkEuno6OTm5r548UL+sgUFBYsXL+5aMurgwYNlZWWyFOrshNBQuHEDBgyA1FRwcJC/N9S/MEZRn9LU1Ny0aROLxXr58iU5J0kRAgMDAeDmzZtknqakpMhZsKSkZNq0aSdOnPj666+fPHliZGSUm5vr4uJiaWnZw8f8X5NIYP58uHoVLCzg1i0YOlTOxtDbAGMU9QNyDXnFbXFMzqC6fv06eQEu53oijx8/njJlCofDmTZtGkEQX331lUAg8PX1tba2fvny5dWrVz/++GMvLy8LCwveggWwfz/k58O/N8t7E50ODg5gbAzXrkFvFqxCbzPc0g71A3LrTcXFKIvFcnJyqqystLGxAYAbN26IxWLZ7h7U1tYGBATU19f7+/vPmjUrOjqaRqPFx8cvW7YMAOrq6sjF83NycsRtbcbnzsG5cwAAhobg4wNsNrDZ4O0NsbHw8iUIBLB6NezbB2vXAm7rpEr6++YsUkfvv/8+AHz33XeKO8XatWsBYPPmzeRCJ9nZ2TIUaWhoGDp0KAC888478fHxdDqdRqMdPHjwDz/c8vQpcfw4sWwZ4ehIALz+w2AQSUnE3r0EQRACAREcLM8vhd5OeFGP+gGTyQRFjkYBgPwiKDk5mXwhw3X9y5cvJ02aVFFR4eHhERUVtWrVKqlUunv37ujo6D/8vLG9PUREwJEjUFkJv/0GZ85AVBSEhsLjxzBuHACAnh5oaAAulK5yMEZRP+iDGGWz2YaGhkVFRV5eXgCQnJzcq8N5PN60adPKysrc3Nw2b9783nvvicXinTt3bty4sUfH29jAggXw3Xdw9ixYW8PTp69/3tkJNFrvfhP01sN7o6gfsNl2P/3kZ2WlqbhTaGlpTZ48OSkpqaWlZejQod7e3p2dneQKUn9LIBDMmDGjsLDQ0dFx27ZtERERHR0d69at27p1qyytzJ0LixdDfT1UVsKiRbJUQG83jFHUDxwd9Wi0TGNjA4WeJTAwMCkp6caNG+Xl5T0/qr29fcaMGTk5Ofb29rGxsREREUKhcPXq1fv375exD21tOHcOfvsNTExAX1/GIugthjGK+gGDwQQAsViBF/UA4OnpSafT09PTXVxcfHx8/P39J02aRN5P+DMikSg0NDQjI8POzi4uLi4iIoLP5y9ZsuTrr7+WtxtbW3kroLcV7gyK+oFQWFlaOlRb29HVtVJBp3j58uWECRPKysrodHrXxHg6nT5ixAg2m+3n5+fr6/vGfvQAcPjw4RUrVlhZWR0+fHjJkiVcLjc0NPTcuXMaGhoK6hOpAIxR1A/EYm5RkTmDYeburpABKY/Hmzx5ckFBgZubW3Jyck1NTdfsTqFQ2PUxFovl7+8/fvx4Pz8/cjMogiA+//xzLy+v5cuXNzQ0zJo1KzExkfLHVZGKwRhF/UJaUKAJAKNGiWg0igd6bW1t06ZNy87OdnR0zMzM7L6lqFgsLioqIvM0KyurtbW16y0WizV+/HgfHx9nZ+dFixY9ffo0ICDgypUr2tra1LaHVA/GKOofRUVMsbjJ3Z1D3ielSnt7e1BQ0K1bt+zt7bOyssgx5h8SiUR5eXlZWVlZWVm3b99+9eoV+XPyJsCECROSk5N1dXUp7A2pKoxR1D+eP/+QIMTW1p8xGGaUFRWJpP/zP/saG7+urc3KymKxWD08TiwW37t3LysrKyMjIyMjQyAQVFZW/uMf/6CsMaTScPo96h8aGkyCkDQ3J1BWUSyGefPoly5tePbs1/T0nmcoADAYjNGjR69fv/7KlSsTJkwgCCIrK4uyxpCqwxhF/UAqbWtrK7C3j7OwiKKqIixeDElJYGJCu3JloJOTzJXIRfZ6+9QTUmcYo6gf0Ol62tpDqqsXCAR3KChHEBAdDWfOgJERpKTAqFHyFJsxYwYApKamikQiCnpDagBjFPUpiaSlrm4bQYjs7Pba2x+qq9tOQdEtW+DQIdDXh59/htGj5Sw2cOBAV1fX1tbWnJwcCnpDagAnxKE/1dyc2NJymcEwt7PbTaNRMO+ntTX16dNlIlEtQXTQaHoaGkYMxpsT4HtBKgWpFBgMiIiAc+fg4EHw8ZG/SQAIDAwsKSlJTk6eNGkSJQWRasMYRX+qqen04MGn6HQKnnyXStvr63c0NOwFkOrrezOZyxgMZmdn44ABa2Ws+O23UFICWlpgZgaffQYVFaClJX+fpKCgoKQjR0bV1FBVEKk2nPCE/hSfn9XY+JWurruNzbb6+l0mJjN1dUfIUEcg+LWmZolQWEmjaVpZbbG23ibvlPvmZlizBk6dAgD43/+FVatAju+Ufk/a2Um3tgYuF548gd5844/UE94bRX/KwIA9ZMhFghBxOEfr6raVlbmXlrrU1X3W0VHVwwpCofDYsZjych+hsFJPb+Tw4fk2Np9R8NhSXd1/NtR0cgKqh410TU2YPBkAAL+vRz2AMYr+QGdnA0FIGhr21NVtb2+/r6s7wsJiJYPBFArL6ut3lJQ4VlZO5HD+JRLx/qJIcXHx2LFjIyM/uXt3nJXVpmHD7so2mP0D9vbw6NHr1w8eKGR/zcBAAIxR1CN4UY/eJJUKysvHMhgDWKwfaTQNDQ0j8q9bgpC8enWrqelEc/MFqVQglTLmzh3g7u4REREREhKi1e3WZGdn5xdffBETEyMWi4cNG3bixPHRo8dQ3OXp05CVBRoaMHw4rFlDcXEAePkSrKxASwu4XNDTo74+UiX9tgsUeltVV0fk50NJyVCxmPeHHxCLeRzOvy5dWkKnv76aMTMzi4qKysnJkUqlJSUlnp6eAECj0VasWMHn8xXY6+XLRHQ00d6ukOJjxhAAxJUrCimOVAjGKPovjY3f5OdDYaFBe3vp3374+fPne/bsGTHiP5fqVlZW5LCUxWJlZmYqvF0PDwKAuH5dIcU/+4wAIKKjFVIcqRC8N4r+QyC4+/z5BgBwcPhBR8f5bz9va2v70UcfFRUVlZaWbt++ncVicTgcPT29RYsW3b9/n81mK7zjoCAAgN7v+tkjM2dCQMDrTT0R+nN4bxS9JhY3PXzoKRLVDBiwzs5Oln2HJBIJuWecRCKh9c3+l3fuwLhxMHgwVPV08kDvfPstPH4MYjGsXQu44BP6EzgaRQAAEonk008/EIvBwGC8rW1sbw/funWrl5fXlStXCILQ1tbuowwFgDFjwNISqquhN5vW9VRmJnC5cOAAfPEF9HBfZaSWMEYRAMD27dt37TodGckYNCiBRuv1vseVlZUFBQXNzc0AoKOjo4AG/wSdDlOmAChmZlJe3uvZoyYmQBBQWQkHDkBhIUgk1J8LKTOMUQRXr17dtWuXhobG3r0HdXRsZKhAbnBEfnHf17tuKO72qKUl1Ne/fi0WQ3IyrFsHnp5gYgIBAfDZZ5CWBh0d1J8XKRt8pl7dPX36dMmSJVKpdM+ePQEBAbIV6ejogH/HaJ+ORgFg6tRNEydee/48p7XVyMiIyspz50JEBLx6BQ8fQkgIDBkCS5ZAdjY8eQJpaZCWBgC3vb13GBmRW42OGTMGN25STxijak0oFM6dO5fL5c6cOXPDhg3y1AEA8pZoX8eoqekvnZ0PKivT0tLmzJlDZWV9ffjxRygvh8BAsLICAJg4EQCgoQGysyEnB27fTtPVTU1NTU1NBQAdHR1vb+8JEyb4+/v7ULTWFFIKGKOq79WrV1wul8vlcjicpqYm7r81NTXl5eVVVlY6OjqeOHFCnu+F/n1Rb+7nl2xj09dzPwIDA3NycpKTkymOUQBgMMDV9c0fWllBWBiEhQHAysZG56ysrKyszMzM0tLSzMzMzMzMe/fuYYyqFYxR1XHo0KGUlBRTU9PuQcnlcv96FXdtbe3AwEBjY2N5Ts1iHdPWBgCLzExzb295KskiKChoy5YtycnJBEH03SQBAACwGDAgLCwsLCwMALhcbk5OTkZGxpgxVD/5it5uOG9URXzyyScxMTF/+JaBgQGTyWQymebm5kwm08zMjPxHU1PT2trarVu3amlp5ebmdn8YqbeGDYOKCjh5EsLDgc2GzEyZK8lo0KBBz549KygoGCXfDiIIyQBHoyri+vXrAODu7r5q1SpDQ0NNTU0NDQ0ajSYQCF6+fNnczbNnz8gXzs7OaWlptbW133///eLFi+/evasl68rHQiEAAPk3ch/fGiVNmzbt0KFDycnJGKOoH/Tvs6iIElevXgUAKyurtra2NT1e7sjLy4sgCD6fT27I/umnn8rcwIABBABx7BgBQMycSd0v1mOXLl0CgKCgoH44N1J7OBpVBbt27QKAjz76SFdXl7xaNzc377p47/6CvK4n6evrA4C+vv6xY8f8/PxiYmKCgoJku6/X76NRf3///Px8HIqifoH3RpVeenr65MmTmUxmTU2NgYGM+yZt2LBh3759w4YNKyws1NXV7e3hOjrQ0QFHjsDy5RARAcePy9YFQkoJn2JSel9++SUArFu3TuYMJYu4urqWl5dv27ZNhsOXLIFFi2DQIAgJAXd3mbtASCnhaFS53b17d+zYsUZGRk+fPjUxMZGnVGFh4dixYyUSSXp6up+fX28Pv3kT8vLg448hLw9aWkDW56EQUj44GlVuO3fuBIA1a9bImaEAMGrUqI8//lgqlUZGRr569aq3h9fXw+XLcO8ecDj/eRIdIXWAo1ElVlRU5OHhoaenV11dbWFhIX9BsVg8bty4/Pz8qKio7777rodHPXoEublAEKCrC2fPQmQkcLkQESF/OwgpBxyNKrEvvviCIIioqChKMhQAGAzG8ePHdXR04uPjr1279hefFIshJwc+/hi8vMDJCSIigMcDfX2YPx+OHaOkF4SUBsaosiovL79w4YK2tmosdioAAASzSURBVPaHH35IYVlnZ+ft27cTBLF8+XJy/dDunj9/fvJk2uzZYGICvr4QGwsFBWBmBvPmvV4xLjQU+HwK20FICeBFvbKKiIg4efLkypUr4+LiqK0slUonTJiQnZ0dHh5+4sQJiURy//79K1euXL16tbCw0NDQqL39ZWenJosFM2ZAcDD4+YGmJjQ1AYMBRkbQ1AQEAUwmtU0h9PbCGFVKVVVVQ4cOpdFolZWVDg4Oiqjv7u7O5/N9fHzKysqamprInxsYGPj7+8+eHT95sqWtLeWnRUgp4VNMSik2NlYsFkdGRlKeoTU1NTk5OfPnz3/vvfeOHj2ak5MDACwWy9/ff8aMGVOmTMGViRF6A8ao8qmtrT1+/LiGhsamTZsoL7579+74+Ph79+5VVFS0tLQEBgYeOHDA0dGR8hMhpDLwol75TJgwITMz09/fPzU19datW5aWli4uLpRUrq+vZ7FYnZ2d58+fnzNnDoVTqRBSYfhNvfIxNjam0Wg8Hi8hIWHy5Mnh4eGdnZ2UVI6NjRUKhaGhoadOnSIIIjo6GjMUob+FMap8tm3bZmhomJeXx+fzhwwZcu/evS+++EL+shwO54cffqDRaGFhYRcvXtTW1l63bp38ZRFSeRijysfLy+urr74CgPXr1+/Zs0dDQyMmJiY3N1fOsvv27ePz+cHBwUlJSVKpdPny5TY2smy2jJC6wXujymrOnDkXL14MCAhwc3Pbv3+/zGvckXg8noODQ0tLS2Ji4oIFCxQ3lQoh1YOjUWX1/fffW1papqamDhkyRJ417khff/11S0tLQEBASkqKWCwODw/HDEWoh3A0qsTOnTu3YMECfX3906dPh4WFybzGnUAgcHBw4HA4iYmJ7777rkQiKSsrc3JyUkTPCKkeHI0qsfnz58+bN08gEOzdu3fTpk0yr3F38OBBDoczbty47OxskUgUFhaGGYpQz2GMKre4uDgrK6vbt2+bmJh4eXlVV1dv3LixVxWEQuGBAwcA4IMPPjhy5AiNRtu8ebNimkVINWGMKjcmk3n48GEA+OSTT7Zt29aTNe7ecOTIkbq6Og8Pj/v377e1tc2cOVOeDesRUkN4b1QVLF269OjRo6NGjZozZ87WrVttbGwePHhgZmb2twd2dnY6Ojo+ffr01KlTq1at4vF4ubm5o0eP7oOeEVIZOBpVBQcOHBg0aFBhYaFUKvX19a2rq1u7dm1PDmxubvb09HRzc6usrOTxeFOmTMEMRai3cDSqItLT0/39/TU0NBISEhYtWhQcHHzy5ElNTc2eHMvhcIYPH87hcDIzM9lstqJbRUjFYIyqjjVr1nz77bfOzs6JiYnOzs5vvNva2srhcDgcTlNTE5fL5XK5XS9SU1M5HI6Xl1deXl6/dI6QUsMYVR1tbW0jR4589OiRnZ3dlClTugcll8sVi8V/cSyDwThw4MCqVav6rFuEVAbGqEq5dOnS7Nmz//DfqZGRkZmZmYWFBZPJNDMzYzKZXS9EIpGHh4e7u3vfN4yQCsAYVTW//vrrP//5z8DAwO5ByWQye3ifFCHUWxijCCEkF5zwhBBCcsEYRQghuWCMIoSQXDBGEUJILhijCCEkl/8HYFinVdu5xawAAAJfelRYdHJka2l0UEtMIHJka2l0IDIwMjUuMDMuMgAAeJx7v2/tPQYgEABiJgYIUAJiNSBuYGRjSADSjMwcDBpAmpmJzQFMs+CmM0A0MyMSA1UFhwOqSewQmhmfCbjM5GRQALlOAExRxUQBqOvg/kX3P5TPzcDIwMikwMScwcTMksDCmsHEypbAxg6kOBQ4ODOYOLkSuLgTuHkymLh5FXj5Mpj4+BP4BTKYBAQTBIUymISEGThFGEREGUTFMpjExBPEJTKYJCQTJKUymKSkE6RlMphkZBNY5BTk5BmYFRQUFBnYmRJ4OBKEeBNkRRNkxBOcWIGuYGNiZ2NlYWbl4uTg4Wbj4xcQFOJlFROVlRFnk5CUkpYRF1/ECHQrAyxSTSv/OBT0ZtiDOJ7utx1muxjvA7EXL1/jMOm1pR2Iva2022HT47T9ILbCGkuH5dO5wezVF+QcfgulgvW2mCQ6nLT4C2a/sJzvcHjSeTB7j1KzfbP+AjB7wdxve636J4DNnLZm0341/U6w+AS21v0Prik6gNhyp17aVX/SALOVOhkOaMtmg9lndQ/sr9i9CMw+KCN3YF7ccTD7+pSaAw+v7AOzO5v7DvxbPhHMtmCMP7CRMwrMLimuP3Aj/j/YrrggyT2eobPB7hd7OX//3g3MB0Ds+pNL91suTQazM/j1D6xrqAOzbx+NOHCwehWYbew450Af5zow28Fl+4FP0W1gNlvmogMCjmZgdqNo6oFSVX0wO8BP6wBz7TGwXX0T3tnLV18As3crCzlYZLiA1RQ8nuEw9bEomC3efNxhxjYdMFsMABZWrafmlWyEAAADHnpUWHRNT0wgcmRraXQgMjAyNS4wMy4yAAB4nH1WW27bMBD89yl4ARPcF7n72dhpURRxgCbtHfrf+6OzUkI5LVHJWkjUaDmcWS58Knl8v3779bvMg6+nUyntP7+IKD+ltXZ6KnlTHh6/fL2Vy+unh/eRy/OP2+tLES3i+AbnR+yn1+en9xEqlzKqe4zopdVorg0f1bYdx5dcnkuvbqzG5dwqDWu9L4CChFYlTLvgNTnZdvM3ToHTKuZEkQmjURAvgAYg52sSSqCBga8y9g2oTupJzEOdaYEbwEk1cs/11xjOYQucbwxjgGIA15n6csUBHNXGquG4YSO1tsARnNmk46aUGrOz6GolRFD7TKmiB2fyAb1Xa4Fil0Q2CYbMXKHN0OXsUm4YVuudYWftEt6WwHTmzBh3GfCz9iHdVgKR7ZNbIySD681NXFfIvufU0awZComlyXr2dOcsNbQbUlmNLruf/yDTn7NiRWI24JQZRBorZOw51RUeYUXauuuq1qDM5232IOUUPsJoWZWorJc0s7VADacKTGJL5fnNI9aQRpu0NuDCCpomJTSMMS2YmPWwWEHfbBpiAiOSNJK2lfps+/rFRxu9nLE9efS2EpX7LqrnnoiEqvi67Hlzyurg0ZzyIwofvCTgO7QNE0gM1q5jLDcnv3llI1TGvkDMv4Li95IAvEUxbYWInhQrCyQ3FFXvMlBL59zMvq4V4a2LoMNothupKBVfTy/IqXXg6Jo8RLnRsiWmVVnzOrJ5gnF419WOerxdP3TnvV8/PN+uR7/Ok4+2jIciR/PVvI4em6cdnRQPpR/9UnGNoy0qLj+6H+FtHE1OcdF9M9MMRHdNSzPQJIcK1gw0+aEJ0TYyKVIyRKDJkpImAk2ilEwRaHKlJItAky66gWagyTibdga+392UnHly5k1M/A5BkzMCT86coiLw5MzJGYEnZ07OCDw5c3JG4MmZkzMCT86cnBF4cuaUGUHui5xgmkzKkpQRZFKWLAL4flRBqowgk7EkY7+rk01jOeyVTeK4M0aS7ibIHPGd3CFElut9cebz+x8R3J/+APi5pGqT0MCiAAABi3pUWHRTTUlMRVMgcmRraXQgMjAyNS4wMy4yAAB4nC1Su47cMBD7lZS7gFaY9wMuD0h7RT7B/aVIex8fjvZcWDJNznAofXzefD8+P54/r9ct9+PPrV+33fPYP33+HVjPp/5+fsnzvvnX9yN3Vdei3VRGta7Y5WK+XrQ5nSLW5VvbLUDiYg9dl231YhlSEzd2gBJPrJdsNSGZSqKWPkh0ha1Lhs06MjeXQiXeFZq9XrxDCnqQ8MNA0k1RdRArtkb/aivhUdF45C3OWK8xK2Q8g0jJyAcjaviEF1QXVoeF2VnrmCLPmW6QdlRFQ/fogWSnuspA/Sbp1krk80IYkgEPL0N0Ajog04oE5DvlsGxzV8qBKE8p2WV5IPTJNlunTcS7YQSTjlFH6H1sIfVqDEmJkzgIaUss2cgu7ciISnPpjql0OE5sC13LtQ7FknzNYZCe5m3hBUaHWp85zNVjGVpzvoe1MuSKFUdgb1WzCcx0O2N6gihC4CUU9+fCTFw4UBCyzg3p9BpBCCOb5/d/Y6yLwh4/1qsAAAAASUVORK5CYII=",
            "text/plain": [
              "<rdkit.Chem.rdchem.Mol at 0x7e4f4c106810>"
            ]
          },
          "execution_count": 12,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "mll"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "rchf46MnYK_b",
      "metadata": {
        "id": "rchf46MnYK_b"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "D3Erre2tXTV5",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 423
        },
        "id": "D3Erre2tXTV5",
        "outputId": "acad598b-f107-4967-c217-6d82f9993d99"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>cid</th>\n",
              "      <th>smiles</th>\n",
              "      <th>acvalue</th>\n",
              "      <th>categories</th>\n",
              "      <th>label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>44244736</td>\n",
              "      <td>COC1=C(C(=C(C=C1)C2=C(OC(=N2)C3=CC=CC=C3F)SC4=...</td>\n",
              "      <td>0.0030</td>\n",
              "      <td>inhibitor</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>44244911</td>\n",
              "      <td>CC1=NN=C(S1)SC2=C(N=C(O2)C3=CC=CC=C3F)C4=C(C(=...</td>\n",
              "      <td>0.0035</td>\n",
              "      <td>inhibitor</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>44245235</td>\n",
              "      <td>COC1=C(C(=C(C=C1)C2=C(OC(=N2)C3=CN=CC=C3)SC4=N...</td>\n",
              "      <td>0.0047</td>\n",
              "      <td>inhibitor</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>10451021</td>\n",
              "      <td>CC(=CC1=CC(=C(C=C1)OC)O)C(=O)C2=CC(=C(C(=C2)OC...</td>\n",
              "      <td>0.0090</td>\n",
              "      <td>inhibitor</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>44245073</td>\n",
              "      <td>CC1=CN=C(N=C1C)SC2=C(N=C(O2)C3=CC=CC=C3Cl)C4=C...</td>\n",
              "      <td>0.0180</td>\n",
              "      <td>inhibitor</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>631</th>\n",
              "      <td>145958114</td>\n",
              "      <td>COC1=CC=C(C=C1)C(=O)C=CC2=CC=C(C=C2)N3C=C(N=N3...</td>\n",
              "      <td>100.0000</td>\n",
              "      <td>neutral</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>632</th>\n",
              "      <td>145950639</td>\n",
              "      <td>C1=CC=C(C=C1)C2=C(N=NC(=N2)SCC3=CN(N=N3)CC4=CC...</td>\n",
              "      <td>100.0000</td>\n",
              "      <td>neutral</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>633</th>\n",
              "      <td>3168508</td>\n",
              "      <td>C1=CC=C(C=C1)C2=C(N=NC(=N2)SCCC(=O)O)C3=CC=CC=C3</td>\n",
              "      <td>100.0000</td>\n",
              "      <td>neutral</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>634</th>\n",
              "      <td>145952863</td>\n",
              "      <td>CC(C)CC(C(=O)NO)NC(=O)NCC1=CN(N=N1)CC2=CC=CC=C...</td>\n",
              "      <td>119.1000</td>\n",
              "      <td>neutral</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>635</th>\n",
              "      <td>145955648</td>\n",
              "      <td>CC(C)CC(C(=O)NO)NC(=O)NCC1=CN(N=N1)CC2=CC(=CC=...</td>\n",
              "      <td>122.9000</td>\n",
              "      <td>neutral</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>636 rows × 5 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "           cid                                             smiles   acvalue  \\\n",
              "0     44244736  COC1=C(C(=C(C=C1)C2=C(OC(=N2)C3=CC=CC=C3F)SC4=...    0.0030   \n",
              "1     44244911  CC1=NN=C(S1)SC2=C(N=C(O2)C3=CC=CC=C3F)C4=C(C(=...    0.0035   \n",
              "2     44245235  COC1=C(C(=C(C=C1)C2=C(OC(=N2)C3=CN=CC=C3)SC4=N...    0.0047   \n",
              "3     10451021  CC(=CC1=CC(=C(C=C1)OC)O)C(=O)C2=CC(=C(C(=C2)OC...    0.0090   \n",
              "4     44245073  CC1=CN=C(N=C1C)SC2=C(N=C(O2)C3=CC=CC=C3Cl)C4=C...    0.0180   \n",
              "..         ...                                                ...       ...   \n",
              "631  145958114  COC1=CC=C(C=C1)C(=O)C=CC2=CC=C(C=C2)N3C=C(N=N3...  100.0000   \n",
              "632  145950639  C1=CC=C(C=C1)C2=C(N=NC(=N2)SCC3=CN(N=N3)CC4=CC...  100.0000   \n",
              "633    3168508   C1=CC=C(C=C1)C2=C(N=NC(=N2)SCCC(=O)O)C3=CC=CC=C3  100.0000   \n",
              "634  145952863  CC(C)CC(C(=O)NO)NC(=O)NCC1=CN(N=N1)CC2=CC=CC=C...  119.1000   \n",
              "635  145955648  CC(C)CC(C(=O)NO)NC(=O)NCC1=CN(N=N1)CC2=CC(=CC=...  122.9000   \n",
              "\n",
              "    categories  label  \n",
              "0    inhibitor      1  \n",
              "1    inhibitor      1  \n",
              "2    inhibitor      1  \n",
              "3    inhibitor      1  \n",
              "4    inhibitor      1  \n",
              "..         ...    ...  \n",
              "631    neutral      0  \n",
              "632    neutral      0  \n",
              "633    neutral      0  \n",
              "634    neutral      0  \n",
              "635    neutral      0  \n",
              "\n",
              "[636 rows x 5 columns]"
            ]
          },
          "execution_count": 7,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "id": "ijeTryIBXUjM",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 443
        },
        "id": "ijeTryIBXUjM",
        "outputId": "5d909d4d-62e4-4344-c134-4eb926c14dcf"
      },
      "outputs": [
        {
          "ename": "NameError",
          "evalue": "name 'df_fingerprints' is not defined",
          "output_type": "error",
          "traceback": [
            "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
            "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
            "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[8]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[43mdf_fingerprints\u001b[49m\n",
            "\u001b[31mNameError\u001b[39m: name 'df_fingerprints' is not defined"
          ]
        }
      ],
      "source": [
        "df_fingerprints"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "id": "763b5af1-e4a7-4e1c-a74f-d719997e396f",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "763b5af1-e4a7-4e1c-a74f-d719997e396f",
        "outputId": "cfbdf2aa-ac35-48de-f650-9bab80175062"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "--- Train Data ---\n",
            "Total samples: 508\n",
            "Label 0: 261\n",
            "Label 1: 247\n",
            "------------------\n",
            "--- Test Data ---\n",
            "Total samples: 128\n",
            "Label 0: 60\n",
            "Label 1: 68\n",
            "-----------------\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "# Anggap X_train, X_test, y_train, y_test udah ada dari hasil train_test_split lu di atas\n",
        "\n",
        "# --- Statistik Data Train ---\n",
        "train_size = X_train.shape[0]\n",
        "# Hitung jumlah Label 0 di y_train\n",
        "train_label_0_count = np.sum(y_train == 0)\n",
        "# Hitung jumlah Label 1 di y_train\n",
        "train_label_1_count = np.sum(y_train == 1) # Atau train_size - train_label_0_count\n",
        "\n",
        "print(\"--- Train Data ---\")\n",
        "print(f\"Total samples: {train_size}\")\n",
        "print(f\"Label 0: {train_label_0_count}\")\n",
        "print(f\"Label 1: {train_label_1_count}\")\n",
        "print(\"-\" * 18) # Garis pemisah\n",
        "\n",
        "# --- Statistik Data Test ---\n",
        "test_size = X_test.shape[0]\n",
        "# Hitung jumlah Label 0 di y_test\n",
        "test_label_0_count = np.sum(y_test == 0)\n",
        "# Hitung jumlah Label 1 di y_test\n",
        "test_label_1_count = np.sum(y_test == 1) # Atau test_size - test_label_0_count\n",
        "\n",
        "print(\"--- Test Data ---\")\n",
        "print(f\"Total samples: {test_size}\")\n",
        "print(f\"Label 0: {test_label_0_count}\")\n",
        "print(f\"Label 1: {test_label_1_count}\")\n",
        "print(\"-\" * 17) # Garis pemisah\n",
        "\n",
        "# Kalau lu mau lihat statistik data ASLI (sebelum split)\n",
        "# Asumsi X dan y adalah data lu sebelum displit\n",
        "# total_dataset_size = X.shape[0]\n",
        "# total_label_0_count = np.sum(y == 0)\n",
        "# total_label_1_count = np.sum(y == 1)\n",
        "# print(\"\\n--- Original Dataset ---\")\n",
        "# print(f\"Total samples: {total_dataset_size}\")\n",
        "# print(f\"Label 0: {total_label_0_count}\")\n",
        "# print(f\"Label 1: {total_label_1_count}\")\n",
        "# print(\"-\" * 24)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e58b3962-0e28-4350-8267-00e17351863d",
      "metadata": {
        "id": "e58b3962-0e28-4350-8267-00e17351863d"
      },
      "source": [
        "**Split Data**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "id": "8cc1c1fd-6b9f-486d-832e-4114c725afda",
      "metadata": {
        "id": "8cc1c1fd-6b9f-486d-832e-4114c725afda"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3c501878-ea33-44d6-8400-23a3cb99ae4b",
      "metadata": {
        "id": "3c501878-ea33-44d6-8400-23a3cb99ae4b"
      },
      "source": [
        "# Modelling"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "id": "04c710ed-fda8-4ed4-aeea-6f975f72504e",
      "metadata": {
        "id": "04c710ed-fda8-4ed4-aeea-6f975f72504e"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Embedding, LSTM, Dense, Dropout, Reshape\n",
        "from tensorflow.keras.optimizers import Adam"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "1e944176-4c53-4bbc-a1e5-71f36b884d7c",
      "metadata": {
        "id": "1e944176-4c53-4bbc-a1e5-71f36b884d7c"
      },
      "source": [
        "| Baseline   | Layer | Units       | Act  | LR    | Rec. Act | Dropout |\n",
        "|------------|-------|-------------|------|-------|----------|---------|\n",
        "| Baseline 1 | 1     | [128]       | tanh | 0.001 | sigmoid  | 0.2     |\n",
        "| Baseline 2 | 2     | [128,64]    | tanh | 0.001 | sigmoid  | 0.3     |\n",
        "| Baseline 3 | 3     | [128,64,32] | tanh | 0.001 | sigmoid  | 0.4     |"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8d9a9eff-2726-46e9-948a-97883004b74d",
      "metadata": {
        "id": "8d9a9eff-2726-46e9-948a-97883004b74d"
      },
      "source": [
        "## Baseline 1"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "fad7c4a6-12b8-4d9f-9683-3f23044707eb",
      "metadata": {
        "id": "fad7c4a6-12b8-4d9f-9683-3f23044707eb"
      },
      "source": [
        "| Baseline   | Layer | Units       | Act  | LR    | Rec. Act | Dropout |\n",
        "|------------|-------|-------------|------|-------|----------|---------|\n",
        "| Baseline 1 | 1     | [128]       | tanh | 0.001 | sigmoid  | 0.2     |"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "id": "90e65729-eb20-438a-9946-d1e67c7d6722",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "90e65729-eb20-438a-9946-d1e67c7d6722",
        "outputId": "113356f6-38e3-4a57-ef10-eb5ed12b986d"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_6\"</span>\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1mModel: \"sequential_6\"\u001b[0m\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ reshape_6 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Reshape</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1024</span>)        │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ lstm_10 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)             │       <span style=\"color: #00af00; text-decoration-color: #00af00\">135,296</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dropout_6 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)             │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_6 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)              │            <span style=\"color: #00af00; text-decoration-color: #00af00\">33</span> │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
              "</pre>\n"
            ],
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ reshape_6 (\u001b[38;5;33mReshape\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m1024\u001b[0m)        │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ lstm_10 (\u001b[38;5;33mLSTM\u001b[0m)                  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)             │       \u001b[38;5;34m135,296\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dropout_6 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)             │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_6 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)              │            \u001b[38;5;34m33\u001b[0m │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">135,329</span> (528.63 KB)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m135,329\u001b[0m (528.63 KB)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">135,329</span> (528.63 KB)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m135,329\u001b[0m (528.63 KB)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 39ms/step - AUC: 0.5895 - accuracy: 0.5486 - loss: 0.6836 - val_AUC: 0.8563 - val_accuracy: 0.8039 - val_loss: 0.6191\n",
            "Epoch 2/100\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - AUC: 0.8911 - accuracy: 0.8189 - loss: 0.5870 - val_AUC: 0.8801 - val_accuracy: 0.8333 - val_loss: 0.5490\n",
            "Epoch 3/100\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - AUC: 0.9250 - accuracy: 0.8287 - loss: 0.4978 - val_AUC: 0.8905 - val_accuracy: 0.8431 - val_loss: 0.4871\n",
            "Epoch 4/100\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - AUC: 0.9293 - accuracy: 0.8328 - loss: 0.4275 - val_AUC: 0.8959 - val_accuracy: 0.8333 - val_loss: 0.4427\n",
            "Epoch 5/100\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - AUC: 0.9446 - accuracy: 0.8631 - loss: 0.3700 - val_AUC: 0.9056 - val_accuracy: 0.8333 - val_loss: 0.4127\n",
            "Epoch 6/100\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - AUC: 0.9523 - accuracy: 0.8931 - loss: 0.3293 - val_AUC: 0.9112 - val_accuracy: 0.8529 - val_loss: 0.3915\n",
            "Epoch 7/100\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - AUC: 0.9613 - accuracy: 0.8953 - loss: 0.2995 - val_AUC: 0.9172 - val_accuracy: 0.8529 - val_loss: 0.3740\n",
            "Epoch 8/100\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - AUC: 0.9652 - accuracy: 0.9004 - loss: 0.2764 - val_AUC: 0.9182 - val_accuracy: 0.8529 - val_loss: 0.3621\n",
            "Epoch 9/100\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - AUC: 0.9737 - accuracy: 0.9032 - loss: 0.2491 - val_AUC: 0.9197 - val_accuracy: 0.8627 - val_loss: 0.3541\n",
            "Epoch 10/100\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - AUC: 0.9778 - accuracy: 0.9276 - loss: 0.2336 - val_AUC: 0.9234 - val_accuracy: 0.8627 - val_loss: 0.3495\n",
            "Epoch 11/100\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - AUC: 0.9817 - accuracy: 0.9193 - loss: 0.2182 - val_AUC: 0.9226 - val_accuracy: 0.8627 - val_loss: 0.3460\n",
            "Epoch 12/100\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - AUC: 0.9813 - accuracy: 0.9225 - loss: 0.2093 - val_AUC: 0.9248 - val_accuracy: 0.8725 - val_loss: 0.3443\n",
            "Epoch 13/100\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - AUC: 0.9868 - accuracy: 0.9133 - loss: 0.1926 - val_AUC: 0.9228 - val_accuracy: 0.8627 - val_loss: 0.3463\n",
            "Epoch 14/100\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - AUC: 0.9877 - accuracy: 0.9306 - loss: 0.1809 - val_AUC: 0.9234 - val_accuracy: 0.8529 - val_loss: 0.3463\n",
            "Epoch 15/100\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - AUC: 0.9897 - accuracy: 0.9326 - loss: 0.1679 - val_AUC: 0.9205 - val_accuracy: 0.8529 - val_loss: 0.3498\n",
            "Epoch 16/100\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - AUC: 0.9913 - accuracy: 0.9486 - loss: 0.1592 - val_AUC: 0.9209 - val_accuracy: 0.8431 - val_loss: 0.3519\n",
            "Epoch 17/100\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - AUC: 0.9910 - accuracy: 0.9451 - loss: 0.1526 - val_AUC: 0.9219 - val_accuracy: 0.8529 - val_loss: 0.3553\n",
            "Epoch 18/100\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - AUC: 0.9930 - accuracy: 0.9466 - loss: 0.1436 - val_AUC: 0.9205 - val_accuracy: 0.8431 - val_loss: 0.3564\n",
            "Epoch 19/100\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - AUC: 0.9933 - accuracy: 0.9420 - loss: 0.1371 - val_AUC: 0.9201 - val_accuracy: 0.8333 - val_loss: 0.3647\n",
            "Epoch 20/100\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - AUC: 0.9948 - accuracy: 0.9570 - loss: 0.1290 - val_AUC: 0.9178 - val_accuracy: 0.8333 - val_loss: 0.3723\n",
            "Epoch 21/100\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - AUC: 0.9935 - accuracy: 0.9493 - loss: 0.1305 - val_AUC: 0.9168 - val_accuracy: 0.8235 - val_loss: 0.3790\n",
            "Epoch 22/100\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - AUC: 0.9944 - accuracy: 0.9586 - loss: 0.1215 - val_AUC: 0.9174 - val_accuracy: 0.8235 - val_loss: 0.3826\n",
            "Epoch 23/100\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - AUC: 0.9950 - accuracy: 0.9528 - loss: 0.1173 - val_AUC: 0.9139 - val_accuracy: 0.8235 - val_loss: 0.3921\n",
            "Epoch 24/100\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - AUC: 0.9953 - accuracy: 0.9538 - loss: 0.1157 - val_AUC: 0.9151 - val_accuracy: 0.8333 - val_loss: 0.3975\n",
            "Epoch 25/100\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - AUC: 0.9968 - accuracy: 0.9654 - loss: 0.1046 - val_AUC: 0.9130 - val_accuracy: 0.8039 - val_loss: 0.4036\n",
            "Epoch 26/100\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - AUC: 0.9973 - accuracy: 0.9567 - loss: 0.0996 - val_AUC: 0.9118 - val_accuracy: 0.8137 - val_loss: 0.4124\n",
            "Epoch 27/100\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - AUC: 0.9971 - accuracy: 0.9622 - loss: 0.0962 - val_AUC: 0.9120 - val_accuracy: 0.8137 - val_loss: 0.4158\n",
            "Epoch 28/100\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - AUC: 0.9967 - accuracy: 0.9571 - loss: 0.0955 - val_AUC: 0.9108 - val_accuracy: 0.8137 - val_loss: 0.4223\n",
            "Epoch 29/100\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - AUC: 0.9971 - accuracy: 0.9565 - loss: 0.0903 - val_AUC: 0.9089 - val_accuracy: 0.8137 - val_loss: 0.4277\n",
            "Epoch 30/100\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - AUC: 0.9980 - accuracy: 0.9753 - loss: 0.0859 - val_AUC: 0.9091 - val_accuracy: 0.8137 - val_loss: 0.4372\n",
            "Epoch 31/100\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - AUC: 0.9979 - accuracy: 0.9712 - loss: 0.0845 - val_AUC: 0.9070 - val_accuracy: 0.8137 - val_loss: 0.4460\n",
            "Epoch 32/100\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - AUC: 0.9985 - accuracy: 0.9789 - loss: 0.0775 - val_AUC: 0.9062 - val_accuracy: 0.8235 - val_loss: 0.4550\n",
            "Epoch 33/100\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - AUC: 0.9980 - accuracy: 0.9663 - loss: 0.0830 - val_AUC: 0.9075 - val_accuracy: 0.8039 - val_loss: 0.4592\n",
            "Epoch 34/100\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - AUC: 0.9986 - accuracy: 0.9778 - loss: 0.0729 - val_AUC: 0.9081 - val_accuracy: 0.7941 - val_loss: 0.4637\n",
            "Epoch 35/100\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - AUC: 0.9982 - accuracy: 0.9714 - loss: 0.0806 - val_AUC: 0.9066 - val_accuracy: 0.8039 - val_loss: 0.4749\n",
            "Epoch 36/100\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - AUC: 0.9995 - accuracy: 0.9867 - loss: 0.0656 - val_AUC: 0.9072 - val_accuracy: 0.7941 - val_loss: 0.4839\n",
            "Epoch 37/100\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - AUC: 0.9983 - accuracy: 0.9743 - loss: 0.0706 - val_AUC: 0.9010 - val_accuracy: 0.7941 - val_loss: 0.4916\n",
            "Epoch 38/100\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - AUC: 0.9992 - accuracy: 0.9792 - loss: 0.0668 - val_AUC: 0.9021 - val_accuracy: 0.7941 - val_loss: 0.4975\n",
            "Epoch 39/100\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - AUC: 0.9988 - accuracy: 0.9820 - loss: 0.0668 - val_AUC: 0.9008 - val_accuracy: 0.7941 - val_loss: 0.5041\n",
            "Epoch 40/100\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - AUC: 0.9991 - accuracy: 0.9863 - loss: 0.0629 - val_AUC: 0.9012 - val_accuracy: 0.7941 - val_loss: 0.5090\n",
            "Epoch 41/100\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - AUC: 0.9994 - accuracy: 0.9761 - loss: 0.0610 - val_AUC: 0.9017 - val_accuracy: 0.7941 - val_loss: 0.5158\n",
            "Epoch 42/100\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - AUC: 0.9995 - accuracy: 0.9851 - loss: 0.0601 - val_AUC: 0.9014 - val_accuracy: 0.7843 - val_loss: 0.5225\n",
            "Epoch 43/100\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - AUC: 0.9993 - accuracy: 0.9782 - loss: 0.0611 - val_AUC: 0.9000 - val_accuracy: 0.7941 - val_loss: 0.5312\n",
            "Epoch 44/100\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - AUC: 0.9983 - accuracy: 0.9650 - loss: 0.0624 - val_AUC: 0.9010 - val_accuracy: 0.7941 - val_loss: 0.5384\n",
            "Epoch 45/100\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - AUC: 0.9996 - accuracy: 0.9894 - loss: 0.0547 - val_AUC: 0.9012 - val_accuracy: 0.7941 - val_loss: 0.5458\n",
            "Epoch 46/100\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - AUC: 0.9997 - accuracy: 0.9906 - loss: 0.0520 - val_AUC: 0.9010 - val_accuracy: 0.7941 - val_loss: 0.5537\n",
            "Epoch 47/100\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - AUC: 0.9992 - accuracy: 0.9776 - loss: 0.0582 - val_AUC: 0.8990 - val_accuracy: 0.7745 - val_loss: 0.5631\n",
            "Epoch 48/100\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - AUC: 0.9994 - accuracy: 0.9795 - loss: 0.0521 - val_AUC: 0.9004 - val_accuracy: 0.7941 - val_loss: 0.5694\n",
            "Epoch 49/100\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - AUC: 0.9998 - accuracy: 0.9876 - loss: 0.0487 - val_AUC: 0.8959 - val_accuracy: 0.7843 - val_loss: 0.5704\n",
            "Epoch 50/100\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - AUC: 0.9989 - accuracy: 0.9702 - loss: 0.0546 - val_AUC: 0.8973 - val_accuracy: 0.7843 - val_loss: 0.5730\n",
            "Epoch 51/100\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - AUC: 0.9995 - accuracy: 0.9829 - loss: 0.0504 - val_AUC: 0.8940 - val_accuracy: 0.7843 - val_loss: 0.5808\n",
            "Epoch 52/100\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - AUC: 0.9996 - accuracy: 0.9924 - loss: 0.0468 - val_AUC: 0.8944 - val_accuracy: 0.7941 - val_loss: 0.5910\n",
            "Epoch 53/100\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - AUC: 0.9995 - accuracy: 0.9812 - loss: 0.0481 - val_AUC: 0.8957 - val_accuracy: 0.7843 - val_loss: 0.5925\n",
            "Epoch 54/100\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - AUC: 0.9996 - accuracy: 0.9895 - loss: 0.0447 - val_AUC: 0.8952 - val_accuracy: 0.7745 - val_loss: 0.5998\n",
            "Epoch 55/100\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - AUC: 0.9991 - accuracy: 0.9794 - loss: 0.0508 - val_AUC: 0.8938 - val_accuracy: 0.7843 - val_loss: 0.6092\n",
            "Epoch 56/100\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - AUC: 0.9994 - accuracy: 0.9834 - loss: 0.0476 - val_AUC: 0.8932 - val_accuracy: 0.7843 - val_loss: 0.6125\n",
            "Epoch 57/100\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - AUC: 0.9998 - accuracy: 0.9837 - loss: 0.0406 - val_AUC: 0.8894 - val_accuracy: 0.7745 - val_loss: 0.6160\n",
            "Epoch 58/100\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - AUC: 0.9997 - accuracy: 0.9915 - loss: 0.0412 - val_AUC: 0.8897 - val_accuracy: 0.7843 - val_loss: 0.6225\n",
            "Epoch 59/100\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - AUC: 0.9998 - accuracy: 0.9939 - loss: 0.0390 - val_AUC: 0.8890 - val_accuracy: 0.7647 - val_loss: 0.6385\n",
            "Epoch 60/100\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - AUC: 0.9997 - accuracy: 0.9827 - loss: 0.0433 - val_AUC: 0.8901 - val_accuracy: 0.7745 - val_loss: 0.6400\n",
            "Epoch 61/100\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - AUC: 0.9998 - accuracy: 0.9887 - loss: 0.0399 - val_AUC: 0.8911 - val_accuracy: 0.7745 - val_loss: 0.6432\n",
            "Epoch 62/100\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - AUC: 0.9995 - accuracy: 0.9816 - loss: 0.0432 - val_AUC: 0.8896 - val_accuracy: 0.7745 - val_loss: 0.6511\n",
            "Epoch 63/100\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - AUC: 0.9996 - accuracy: 0.9791 - loss: 0.0408 - val_AUC: 0.8903 - val_accuracy: 0.7843 - val_loss: 0.6557\n",
            "Epoch 64/100\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - AUC: 1.0000 - accuracy: 0.9991 - loss: 0.0342 - val_AUC: 0.8925 - val_accuracy: 0.7843 - val_loss: 0.6581\n",
            "Epoch 65/100\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - AUC: 0.9999 - accuracy: 0.9955 - loss: 0.0341 - val_AUC: 0.8845 - val_accuracy: 0.7647 - val_loss: 0.6649\n",
            "Epoch 66/100\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - AUC: 0.9999 - accuracy: 0.9948 - loss: 0.0361 - val_AUC: 0.8861 - val_accuracy: 0.7843 - val_loss: 0.6704\n",
            "Epoch 67/100\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - AUC: 0.9998 - accuracy: 0.9880 - loss: 0.0374 - val_AUC: 0.8859 - val_accuracy: 0.7745 - val_loss: 0.6721\n",
            "Epoch 68/100\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - AUC: 0.9997 - accuracy: 0.9885 - loss: 0.0354 - val_AUC: 0.8868 - val_accuracy: 0.7745 - val_loss: 0.6765\n",
            "Epoch 69/100\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - AUC: 0.9997 - accuracy: 0.9878 - loss: 0.0349 - val_AUC: 0.8865 - val_accuracy: 0.7745 - val_loss: 0.6823\n",
            "Epoch 70/100\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - AUC: 0.9998 - accuracy: 0.9891 - loss: 0.0343 - val_AUC: 0.8872 - val_accuracy: 0.7843 - val_loss: 0.6871\n",
            "Epoch 71/100\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - AUC: 0.9998 - accuracy: 0.9943 - loss: 0.0339 - val_AUC: 0.8872 - val_accuracy: 0.7647 - val_loss: 0.6949\n",
            "Epoch 72/100\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - AUC: 1.0000 - accuracy: 0.9974 - loss: 0.0299 - val_AUC: 0.8868 - val_accuracy: 0.7745 - val_loss: 0.7001\n",
            "Epoch 73/100\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - AUC: 0.9997 - accuracy: 0.9894 - loss: 0.0323 - val_AUC: 0.8880 - val_accuracy: 0.7745 - val_loss: 0.7018\n",
            "Epoch 74/100\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - AUC: 0.9998 - accuracy: 0.9891 - loss: 0.0350 - val_AUC: 0.8870 - val_accuracy: 0.7745 - val_loss: 0.7066\n",
            "Epoch 75/100\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - AUC: 0.9997 - accuracy: 0.9836 - loss: 0.0354 - val_AUC: 0.8861 - val_accuracy: 0.7745 - val_loss: 0.7081\n",
            "Epoch 76/100\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - AUC: 0.9999 - accuracy: 0.9947 - loss: 0.0287 - val_AUC: 0.8867 - val_accuracy: 0.7745 - val_loss: 0.7096\n",
            "Epoch 77/100\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - AUC: 0.9998 - accuracy: 0.9876 - loss: 0.0304 - val_AUC: 0.8861 - val_accuracy: 0.7745 - val_loss: 0.7150\n",
            "Epoch 78/100\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - AUC: 0.9998 - accuracy: 0.9921 - loss: 0.0274 - val_AUC: 0.8865 - val_accuracy: 0.7745 - val_loss: 0.7224\n",
            "Epoch 79/100\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - AUC: 0.9998 - accuracy: 0.9888 - loss: 0.0311 - val_AUC: 0.8870 - val_accuracy: 0.7843 - val_loss: 0.7206\n",
            "Epoch 80/100\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - AUC: 0.9998 - accuracy: 0.9891 - loss: 0.0264 - val_AUC: 0.8876 - val_accuracy: 0.7745 - val_loss: 0.7248\n",
            "Epoch 81/100\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - AUC: 0.9999 - accuracy: 0.9874 - loss: 0.0258 - val_AUC: 0.8876 - val_accuracy: 0.7745 - val_loss: 0.7291\n",
            "Epoch 82/100\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - AUC: 0.9999 - accuracy: 0.9883 - loss: 0.0268 - val_AUC: 0.8878 - val_accuracy: 0.7745 - val_loss: 0.7385\n",
            "Epoch 83/100\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - AUC: 0.9998 - accuracy: 0.9860 - loss: 0.0278 - val_AUC: 0.8880 - val_accuracy: 0.7647 - val_loss: 0.7457\n",
            "Epoch 84/100\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - AUC: 0.9998 - accuracy: 0.9907 - loss: 0.0306 - val_AUC: 0.8876 - val_accuracy: 0.7745 - val_loss: 0.7449\n",
            "Epoch 85/100\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - AUC: 0.9998 - accuracy: 0.9953 - loss: 0.0279 - val_AUC: 0.8882 - val_accuracy: 0.7745 - val_loss: 0.7511\n",
            "Epoch 86/100\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - AUC: 0.9999 - accuracy: 0.9886 - loss: 0.0251 - val_AUC: 0.8861 - val_accuracy: 0.7745 - val_loss: 0.7594\n",
            "Epoch 87/100\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - AUC: 0.9999 - accuracy: 0.9939 - loss: 0.0252 - val_AUC: 0.8878 - val_accuracy: 0.7745 - val_loss: 0.7624\n",
            "Epoch 88/100\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - AUC: 0.9998 - accuracy: 0.9928 - loss: 0.0275 - val_AUC: 0.8878 - val_accuracy: 0.7745 - val_loss: 0.7679\n",
            "Epoch 89/100\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - AUC: 0.9999 - accuracy: 0.9902 - loss: 0.0235 - val_AUC: 0.8882 - val_accuracy: 0.7647 - val_loss: 0.7673\n",
            "Epoch 90/100\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - AUC: 0.9998 - accuracy: 0.9946 - loss: 0.0248 - val_AUC: 0.8886 - val_accuracy: 0.7647 - val_loss: 0.7719\n",
            "Epoch 91/100\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - AUC: 0.9997 - accuracy: 0.9843 - loss: 0.0285 - val_AUC: 0.8890 - val_accuracy: 0.7647 - val_loss: 0.7736\n",
            "Epoch 92/100\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - AUC: 0.9998 - accuracy: 0.9898 - loss: 0.0278 - val_AUC: 0.8890 - val_accuracy: 0.7745 - val_loss: 0.7772\n",
            "Epoch 93/100\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - AUC: 0.9998 - accuracy: 0.9941 - loss: 0.0251 - val_AUC: 0.8884 - val_accuracy: 0.7745 - val_loss: 0.7853\n",
            "Epoch 94/100\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - AUC: 0.9998 - accuracy: 0.9939 - loss: 0.0225 - val_AUC: 0.8886 - val_accuracy: 0.7745 - val_loss: 0.7871\n",
            "Epoch 95/100\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - AUC: 0.9998 - accuracy: 0.9880 - loss: 0.0249 - val_AUC: 0.8884 - val_accuracy: 0.7647 - val_loss: 0.7884\n",
            "Epoch 96/100\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - AUC: 0.9999 - accuracy: 0.9866 - loss: 0.0216 - val_AUC: 0.8888 - val_accuracy: 0.7549 - val_loss: 0.7946\n",
            "Epoch 97/100\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - AUC: 0.9999 - accuracy: 0.9971 - loss: 0.0203 - val_AUC: 0.8880 - val_accuracy: 0.7647 - val_loss: 0.8024\n",
            "Epoch 98/100\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - AUC: 0.9999 - accuracy: 0.9975 - loss: 0.0235 - val_AUC: 0.8886 - val_accuracy: 0.7647 - val_loss: 0.7970\n",
            "Epoch 99/100\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - AUC: 0.9999 - accuracy: 0.9866 - loss: 0.0247 - val_AUC: 0.8886 - val_accuracy: 0.7647 - val_loss: 0.8001\n",
            "Epoch 100/100\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - AUC: 1.0000 - accuracy: 0.9939 - loss: 0.0197 - val_AUC: 0.8888 - val_accuracy: 0.7647 - val_loss: 0.8095\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - AUC: 0.8837 - accuracy: 0.7875 - loss: 0.7355 \n",
            "Baseline 1 Test Accuracy: 0.7578, AUC: 0.8607\n"
          ]
        }
      ],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, LSTM, Dropout, Reshape # Tambah Reshape\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "tf.random.set_seed(42)\n",
        "\n",
        "# Assume nBits is the size of your fingerprint (e.g., 1024)\n",
        "nBits = 1024 # Sesuaikan dengan nBits yang lu pake di RDKit\n",
        "\n",
        "units = [32] # Ukuran hidden state LSTM\n",
        "dropout_rate = 0.2\n",
        "learning_rate = 0.001\n",
        "\n",
        "# Build the model for Fingerprint input\n",
        "model_baseline_1 = Sequential()\n",
        "\n",
        "# Layer Input: Langsung terima vektor fingerprint\n",
        "# Bentuk inputnya adalah (panjang_fingerprint,)\n",
        "model_baseline_1.add(tf.keras.Input(shape=(nBits,))) # Define input shape\n",
        "\n",
        "# Tambahkan layer Reshape untuk mengubah (nBits,) menjadi (1, nBits)\n",
        "# Agar cocok dengan input shape LSTM yang butuh 3D (samples, timesteps, features)\n",
        "model_baseline_1.add(Reshape((1, nBits))) # Ubah (features,) jadi (1, features)\n",
        "\n",
        "# Layer LSTM: Sekarang inputnya udah 3D (samples, 1, nBits)\n",
        "# Return sequences False karena kita cuma punya 1 timestep dan mau output single vector\n",
        "model_baseline_1.add(LSTM(units[0], activation='tanh', recurrent_activation='sigmoid', return_sequences=False))\n",
        "\n",
        "# Layer Dropout\n",
        "model_baseline_1.add(Dropout(dropout_rate))\n",
        "\n",
        "\n",
        "model_baseline_1.add(Dense(1, activation='sigmoid')) # Ganti kalau task-nya regresi\n",
        "\n",
        "# Compile the model\n",
        "model_baseline_1.compile(optimizer=Adam(learning_rate=learning_rate),\n",
        "                        loss='binary_crossentropy',\n",
        "                        metrics=['accuracy', 'AUC'])\n",
        "\n",
        "model_baseline_1.summary() # Penting buat ngecek arsitektur dan shape\n",
        "\n",
        "# Train the model\n",
        "history_baseline_1 = model_baseline_1.fit(\n",
        "    X_train,\n",
        "    y_train,\n",
        "    validation_split=0.2,\n",
        "    epochs=100,\n",
        "    batch_size=32\n",
        ")\n",
        "\n",
        "# Evaluate the model\n",
        "loss, accuracy, auc = model_baseline_1.evaluate(X_test, y_test)\n",
        "print(f\"Baseline 1 Test Accuracy: {accuracy:.4f}, AUC: {auc:.4f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d7cc2d39-59a3-4e4b-830a-e03a48b36616",
      "metadata": {
        "id": "d7cc2d39-59a3-4e4b-830a-e03a48b36616"
      },
      "source": [
        "## Baseline 2"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "1fc2a19b-788d-4526-b172-6b936bbf993e",
      "metadata": {
        "id": "1fc2a19b-788d-4526-b172-6b936bbf993e"
      },
      "source": [
        "| Baseline   | Layer | Units       | Act  | LR    | Rec. Act | Dropout |\n",
        "|------------|-------|-------------|------|-------|----------|---------|\n",
        "| Baseline 2 | 2     | [128,64]    | tanh | 0.001 | sigmoid  | 0.3     |"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "id": "9c6cf701-ffd6-4fd9-ba36-73843bcceaf6",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "9c6cf701-ffd6-4fd9-ba36-73843bcceaf6",
        "outputId": "79ced081-1c30-41e0-deb9-4073fd53ce1d"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_17\"</span>\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1mModel: \"sequential_17\"\u001b[0m\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ reshape_17 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Reshape</span>)            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1024</span>)        │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ lstm_31 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)         │       <span style=\"color: #00af00; text-decoration-color: #00af00\">590,336</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ lstm_32 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │        <span style=\"color: #00af00; text-decoration-color: #00af00\">49,408</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dropout_17 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_17 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)              │            <span style=\"color: #00af00; text-decoration-color: #00af00\">65</span> │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
              "</pre>\n"
            ],
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ reshape_17 (\u001b[38;5;33mReshape\u001b[0m)            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m1024\u001b[0m)        │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ lstm_31 (\u001b[38;5;33mLSTM\u001b[0m)                  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m128\u001b[0m)         │       \u001b[38;5;34m590,336\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ lstm_32 (\u001b[38;5;33mLSTM\u001b[0m)                  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │        \u001b[38;5;34m49,408\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dropout_17 (\u001b[38;5;33mDropout\u001b[0m)            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_17 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)              │            \u001b[38;5;34m65\u001b[0m │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">639,809</span> (2.44 MB)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m639,809\u001b[0m (2.44 MB)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">639,809</span> (2.44 MB)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m639,809\u001b[0m (2.44 MB)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n",
            "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 18ms/step - AUC: 0.5795 - accuracy: 0.5772 - loss: 0.7854 - val_AUC: 0.7636 - val_accuracy: 0.6667 - val_loss: 0.5781\n",
            "Epoch 2/100\n",
            "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - AUC: 0.7729 - accuracy: 0.6706 - loss: 0.5931 - val_AUC: 0.8026 - val_accuracy: 0.7124 - val_loss: 0.5520\n",
            "Epoch 3/100\n",
            "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - AUC: 0.7861 - accuracy: 0.7123 - loss: 0.5759 - val_AUC: 0.8390 - val_accuracy: 0.7320 - val_loss: 0.5786\n",
            "Epoch 4/100\n",
            "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - AUC: 0.8077 - accuracy: 0.6985 - loss: 0.5884 - val_AUC: 0.8572 - val_accuracy: 0.7778 - val_loss: 0.5090\n",
            "Epoch 5/100\n",
            "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - AUC: 0.8762 - accuracy: 0.7801 - loss: 0.4552 - val_AUC: 0.8466 - val_accuracy: 0.7712 - val_loss: 0.5309\n",
            "Epoch 6/100\n",
            "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - AUC: 0.8107 - accuracy: 0.7398 - loss: 0.6045 - val_AUC: 0.8591 - val_accuracy: 0.7582 - val_loss: 0.4913\n",
            "Epoch 7/100\n",
            "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - AUC: 0.8795 - accuracy: 0.8084 - loss: 0.4659 - val_AUC: 0.8698 - val_accuracy: 0.8039 - val_loss: 0.4634\n",
            "Epoch 8/100\n",
            "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - AUC: 0.8176 - accuracy: 0.7324 - loss: 0.5591 - val_AUC: 0.8402 - val_accuracy: 0.7516 - val_loss: 0.5465\n",
            "Epoch 9/100\n",
            "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - AUC: 0.8423 - accuracy: 0.7652 - loss: 0.5488 - val_AUC: 0.8640 - val_accuracy: 0.7843 - val_loss: 0.5493\n",
            "Epoch 10/100\n",
            "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - AUC: 0.8695 - accuracy: 0.7778 - loss: 0.5354 - val_AUC: 0.8063 - val_accuracy: 0.6797 - val_loss: 0.6733\n",
            "Epoch 11/100\n",
            "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - AUC: 0.8266 - accuracy: 0.7258 - loss: 0.5921 - val_AUC: 0.8460 - val_accuracy: 0.7647 - val_loss: 0.5690\n",
            "Epoch 12/100\n",
            "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - AUC: 0.8718 - accuracy: 0.7769 - loss: 0.4996 - val_AUC: 0.8557 - val_accuracy: 0.7778 - val_loss: 0.6119\n",
            "Epoch 13/100\n",
            "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - AUC: 0.8849 - accuracy: 0.7992 - loss: 0.4719 - val_AUC: 0.8627 - val_accuracy: 0.7843 - val_loss: 0.5378\n",
            "Epoch 14/100\n",
            "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - AUC: 0.9070 - accuracy: 0.7928 - loss: 0.3950 - val_AUC: 0.8612 - val_accuracy: 0.7712 - val_loss: 0.5518\n",
            "Epoch 15/100\n",
            "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - AUC: 0.8974 - accuracy: 0.8018 - loss: 0.4146 - val_AUC: 0.8551 - val_accuracy: 0.7647 - val_loss: 0.6289\n",
            "Epoch 16/100\n",
            "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - AUC: 0.9085 - accuracy: 0.8173 - loss: 0.4237 - val_AUC: 0.8584 - val_accuracy: 0.7974 - val_loss: 0.6037\n",
            "Epoch 17/100\n",
            "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - AUC: 0.9114 - accuracy: 0.8178 - loss: 0.4052 - val_AUC: 0.8623 - val_accuracy: 0.7908 - val_loss: 0.5814\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - AUC: 0.8997 - accuracy: 0.8177 - loss: 0.4378 \n",
            "Baseline 2 Test Accuracy: 0.8203, AUC: 0.8884\n"
          ]
        }
      ],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, LSTM, Dropout, Reshape # Tambah Reshape\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "tf.random.set_seed(42)\n",
        "# Assume nBits is the size of your fingerprint (e.g., 1024)\n",
        "# Ini harus sama dengan ukuran fingerprint yang lu bikin pake RDKit\n",
        "nBits = 1024 # Sesuaikan dengan nBits yang lu pake di RDKit\n",
        "\n",
        "# Hyperparameters (sesuai kode lu, vocab_size dan embedding_dim nggak kepake lagi)\n",
        "# vocab_size = len(tokenizer.word_index) + 1 # Not needed\n",
        "# embedding_dim = 64 # Not needed\n",
        "units = [128, 64] # Ukuran hidden state LSTM\n",
        "dropout_rate = 0.3\n",
        "learning_rate = 0.1\n",
        "\n",
        "# Build the model for Fingerprint input\n",
        "model_baseline_2 = Sequential()\n",
        "\n",
        "# Layer Input: Langsung terima vektor fingerprint\n",
        "# Bentuk inputnya adalah (panjang_fingerprint,)\n",
        "model_baseline_2.add(tf.keras.Input(shape=(nBits,))) # Define input shape\n",
        "\n",
        "# Tambahkan layer Reshape untuk mengubah (nBits,) menjadi (1, nBits)\n",
        "# Agar cocok dengan input shape LSTM yang butuh 3D (samples, timesteps, features)\n",
        "model_baseline_2.add(Reshape((1, nBits))) # Ubah (features,) jadi (1, features)\n",
        "\n",
        "# Layer LSTM: Sekarang inputnya udah 3D (samples, 1, nBits)\n",
        "# Return sequences False karena kita cuma punya 1 timestep dan mau output single vector\n",
        "model_baseline_2.add(LSTM(units[0], activation='tanh', recurrent_activation='sigmoid', return_sequences=True))\n",
        "model_baseline_2.add(LSTM(units[1], activation='tanh', recurrent_activation='sigmoid', return_sequences=False))\n",
        "\n",
        "# Layer Dropout\n",
        "model_baseline_2.add(Dropout(dropout_rate))\n",
        "\n",
        "# Layer Output: Dense dengan 1 unit dan activation sigmoid (kalau task-nya binary classification)\n",
        "# Kalau task-nya regresi, ganti activation jadi 'linear' atau jangan pakai activation\n",
        "model_baseline_2.add(Dense(1, activation='sigmoid')) # Ganti kalau task-nya regresi\n",
        "\n",
        "# Compile the model\n",
        "model_baseline_2.compile(optimizer=Adam(learning_rate=learning_rate),\n",
        "                        loss='binary_crossentropy',\n",
        "                        metrics=['accuracy', 'AUC'])\n",
        "\n",
        "model_baseline_2.summary() # Penting buat ngecek arsitektur dan shape\n",
        "\n",
        "# Train the model\n",
        "history_baseline_2 = model_baseline_2.fit(\n",
        "    X_train,\n",
        "    y_train,\n",
        "    validation_split=0.3,\n",
        "    epochs=100,\n",
        "    batch_size=8,\n",
        "    callbacks=[tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)]\n",
        ")\n",
        "\n",
        "# Evaluate the model\n",
        "loss, accuracy, auc = model_baseline_2.evaluate(X_test, y_test)\n",
        "print(f\"Baseline 2 Test Accuracy: {accuracy:.4f}, AUC: {auc:.4f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "166c20f7-86d4-498b-85f0-6716d6d1b84a",
      "metadata": {
        "id": "166c20f7-86d4-498b-85f0-6716d6d1b84a"
      },
      "source": [
        "## Baseline 3"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a82e6327-fe59-4a53-acfd-85fa1eea471d",
      "metadata": {
        "id": "a82e6327-fe59-4a53-acfd-85fa1eea471d"
      },
      "source": [
        "| Baseline   | Layer | Units       | Act  | LR    | Rec. Act | Dropout |\n",
        "|------------|-------|-------------|------|-------|----------|---------|\n",
        "| Baseline 3 | 3     | [128,64,32] | tanh | 0.001 | sigmoid  | 0.4     |"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "id": "8d7bbd90-48cf-425f-83f1-a33db960b286",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "8d7bbd90-48cf-425f-83f1-a33db960b286",
        "outputId": "b4189fc7-32f8-45ab-87de-754517ff1e56"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_2\"</span>\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1mModel: \"sequential_2\"\u001b[0m\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ reshape_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Reshape</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1024</span>)        │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ lstm_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)         │       <span style=\"color: #00af00; text-decoration-color: #00af00\">590,336</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ lstm_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)          │        <span style=\"color: #00af00; text-decoration-color: #00af00\">49,408</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ lstm_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)             │        <span style=\"color: #00af00; text-decoration-color: #00af00\">12,416</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dropout_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)             │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)              │            <span style=\"color: #00af00; text-decoration-color: #00af00\">33</span> │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
              "</pre>\n"
            ],
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ reshape_2 (\u001b[38;5;33mReshape\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m1024\u001b[0m)        │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ lstm_3 (\u001b[38;5;33mLSTM\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m128\u001b[0m)         │       \u001b[38;5;34m590,336\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ lstm_4 (\u001b[38;5;33mLSTM\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m64\u001b[0m)          │        \u001b[38;5;34m49,408\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ lstm_5 (\u001b[38;5;33mLSTM\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)             │        \u001b[38;5;34m12,416\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dropout_2 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)             │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_2 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)              │            \u001b[38;5;34m33\u001b[0m │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">652,193</span> (2.49 MB)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m652,193\u001b[0m (2.49 MB)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">652,193</span> (2.49 MB)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m652,193\u001b[0m (2.49 MB)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 67ms/step - AUC: 0.6324 - accuracy: 0.5840 - loss: 0.6905 - val_AUC: 0.7852 - val_accuracy: 0.6176 - val_loss: 0.6811\n",
            "Epoch 2/100\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - AUC: 0.8867 - accuracy: 0.7549 - loss: 0.6559 - val_AUC: 0.7942 - val_accuracy: 0.7157 - val_loss: 0.6276\n",
            "Epoch 3/100\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - AUC: 0.8983 - accuracy: 0.8381 - loss: 0.5427 - val_AUC: 0.8056 - val_accuracy: 0.7451 - val_loss: 0.5499\n",
            "Epoch 4/100\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - AUC: 0.9109 - accuracy: 0.8568 - loss: 0.4106 - val_AUC: 0.8271 - val_accuracy: 0.7451 - val_loss: 0.5410\n",
            "Epoch 5/100\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - AUC: 0.9326 - accuracy: 0.8688 - loss: 0.3412 - val_AUC: 0.8552 - val_accuracy: 0.7451 - val_loss: 0.5071\n",
            "Epoch 6/100\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - AUC: 0.9547 - accuracy: 0.8775 - loss: 0.2845 - val_AUC: 0.8606 - val_accuracy: 0.7745 - val_loss: 0.5184\n",
            "Epoch 7/100\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - AUC: 0.9662 - accuracy: 0.9063 - loss: 0.2454 - val_AUC: 0.8537 - val_accuracy: 0.7647 - val_loss: 0.5678\n",
            "Epoch 8/100\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - AUC: 0.9702 - accuracy: 0.9067 - loss: 0.2202 - val_AUC: 0.8565 - val_accuracy: 0.7549 - val_loss: 0.7000\n",
            "Epoch 9/100\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - AUC: 0.9793 - accuracy: 0.9052 - loss: 0.2150 - val_AUC: 0.8556 - val_accuracy: 0.7745 - val_loss: 0.6685\n",
            "Epoch 10/100\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - AUC: 0.9805 - accuracy: 0.9409 - loss: 0.1685 - val_AUC: 0.8540 - val_accuracy: 0.7549 - val_loss: 0.6812\n",
            "Epoch 11/100\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - AUC: 0.9897 - accuracy: 0.9537 - loss: 0.1257 - val_AUC: 0.8517 - val_accuracy: 0.7255 - val_loss: 0.8604\n",
            "Epoch 12/100\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - AUC: 0.9879 - accuracy: 0.9462 - loss: 0.1452 - val_AUC: 0.8512 - val_accuracy: 0.7451 - val_loss: 0.8368\n",
            "Epoch 13/100\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - AUC: 0.9907 - accuracy: 0.9680 - loss: 0.1053 - val_AUC: 0.8419 - val_accuracy: 0.7451 - val_loss: 0.8683\n",
            "Epoch 14/100\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - AUC: 0.9946 - accuracy: 0.9616 - loss: 0.0910 - val_AUC: 0.8367 - val_accuracy: 0.7255 - val_loss: 0.9769\n",
            "Epoch 15/100\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - AUC: 0.9938 - accuracy: 0.9614 - loss: 0.1058 - val_AUC: 0.8346 - val_accuracy: 0.7647 - val_loss: 0.9160\n",
            "Epoch 16/100\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - AUC: 0.9968 - accuracy: 0.9568 - loss: 0.0772 - val_AUC: 0.8338 - val_accuracy: 0.7549 - val_loss: 0.9926\n",
            "Epoch 17/100\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - AUC: 0.9974 - accuracy: 0.9668 - loss: 0.0712 - val_AUC: 0.8238 - val_accuracy: 0.7451 - val_loss: 1.0933\n",
            "Epoch 18/100\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - AUC: 0.9972 - accuracy: 0.9620 - loss: 0.0799 - val_AUC: 0.8285 - val_accuracy: 0.7647 - val_loss: 1.0573\n",
            "Epoch 19/100\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - AUC: 0.9963 - accuracy: 0.9760 - loss: 0.0672 - val_AUC: 0.8335 - val_accuracy: 0.7549 - val_loss: 1.1060\n",
            "Epoch 20/100\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - AUC: 0.9978 - accuracy: 0.9709 - loss: 0.0564 - val_AUC: 0.8160 - val_accuracy: 0.7549 - val_loss: 1.1712\n",
            "Epoch 21/100\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - AUC: 0.9980 - accuracy: 0.9672 - loss: 0.0601 - val_AUC: 0.8156 - val_accuracy: 0.7549 - val_loss: 1.1733\n",
            "Epoch 22/100\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - AUC: 0.9989 - accuracy: 0.9719 - loss: 0.0503 - val_AUC: 0.8208 - val_accuracy: 0.7647 - val_loss: 1.1491\n",
            "Epoch 23/100\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - AUC: 0.9990 - accuracy: 0.9799 - loss: 0.0428 - val_AUC: 0.8113 - val_accuracy: 0.7451 - val_loss: 1.3401\n",
            "Epoch 24/100\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - AUC: 0.9986 - accuracy: 0.9643 - loss: 0.0588 - val_AUC: 0.8140 - val_accuracy: 0.7549 - val_loss: 1.2787\n",
            "Epoch 25/100\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - AUC: 0.9967 - accuracy: 0.9733 - loss: 0.0824 - val_AUC: 0.8167 - val_accuracy: 0.7549 - val_loss: 1.1199\n",
            "Epoch 26/100\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - AUC: 0.9965 - accuracy: 0.9682 - loss: 0.0738 - val_AUC: 0.8142 - val_accuracy: 0.7353 - val_loss: 1.2979\n",
            "Epoch 27/100\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - AUC: 0.9992 - accuracy: 0.9661 - loss: 0.0531 - val_AUC: 0.8100 - val_accuracy: 0.7353 - val_loss: 1.2343\n",
            "Epoch 28/100\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - AUC: 0.9993 - accuracy: 0.9806 - loss: 0.0414 - val_AUC: 0.7927 - val_accuracy: 0.7451 - val_loss: 1.4183\n",
            "Epoch 29/100\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - AUC: 0.9988 - accuracy: 0.9719 - loss: 0.0562 - val_AUC: 0.7969 - val_accuracy: 0.7451 - val_loss: 1.2618\n",
            "Epoch 30/100\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - AUC: 0.9990 - accuracy: 0.9845 - loss: 0.0451 - val_AUC: 0.8094 - val_accuracy: 0.7353 - val_loss: 1.3100\n",
            "Epoch 31/100\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - AUC: 0.9874 - accuracy: 0.9683 - loss: 0.1138 - val_AUC: 0.7950 - val_accuracy: 0.7353 - val_loss: 1.3680\n",
            "Epoch 32/100\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - AUC: 0.9864 - accuracy: 0.9446 - loss: 0.1501 - val_AUC: 0.8015 - val_accuracy: 0.7647 - val_loss: 1.1133\n",
            "Epoch 33/100\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - AUC: 0.9905 - accuracy: 0.9675 - loss: 0.1311 - val_AUC: 0.8273 - val_accuracy: 0.7549 - val_loss: 1.0917\n",
            "Epoch 34/100\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - AUC: 0.9939 - accuracy: 0.9421 - loss: 0.1167 - val_AUC: 0.8310 - val_accuracy: 0.7549 - val_loss: 1.0029\n",
            "Epoch 35/100\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - AUC: 0.9973 - accuracy: 0.9737 - loss: 0.0664 - val_AUC: 0.8387 - val_accuracy: 0.7451 - val_loss: 1.0510\n",
            "Epoch 36/100\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - AUC: 0.9997 - accuracy: 0.9780 - loss: 0.0388 - val_AUC: 0.8477 - val_accuracy: 0.7549 - val_loss: 1.0000\n",
            "Epoch 37/100\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - AUC: 0.9996 - accuracy: 0.9799 - loss: 0.0360 - val_AUC: 0.8490 - val_accuracy: 0.7647 - val_loss: 1.0921\n",
            "Epoch 38/100\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - AUC: 0.9996 - accuracy: 0.9799 - loss: 0.0334 - val_AUC: 0.8415 - val_accuracy: 0.7647 - val_loss: 1.1238\n",
            "Epoch 39/100\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - AUC: 0.9997 - accuracy: 0.9759 - loss: 0.0292 - val_AUC: 0.8363 - val_accuracy: 0.7451 - val_loss: 1.2040\n",
            "Epoch 40/100\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - AUC: 0.9997 - accuracy: 0.9832 - loss: 0.0278 - val_AUC: 0.8362 - val_accuracy: 0.7647 - val_loss: 1.2054\n",
            "Epoch 41/100\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - AUC: 0.9997 - accuracy: 0.9759 - loss: 0.0250 - val_AUC: 0.8240 - val_accuracy: 0.7451 - val_loss: 1.2471\n",
            "Epoch 42/100\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - AUC: 0.9997 - accuracy: 0.9759 - loss: 0.0240 - val_AUC: 0.8171 - val_accuracy: 0.7451 - val_loss: 1.2806\n",
            "Epoch 43/100\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - AUC: 0.9997 - accuracy: 0.9799 - loss: 0.0263 - val_AUC: 0.8188 - val_accuracy: 0.7549 - val_loss: 1.2924\n",
            "Epoch 44/100\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - AUC: 0.9997 - accuracy: 0.9759 - loss: 0.0246 - val_AUC: 0.8185 - val_accuracy: 0.7451 - val_loss: 1.3226\n",
            "Epoch 45/100\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - AUC: 0.9997 - accuracy: 0.9799 - loss: 0.0238 - val_AUC: 0.8117 - val_accuracy: 0.7451 - val_loss: 1.3353\n",
            "Epoch 46/100\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - AUC: 0.9997 - accuracy: 0.9752 - loss: 0.0253 - val_AUC: 0.8113 - val_accuracy: 0.7451 - val_loss: 1.3386\n",
            "Epoch 47/100\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - AUC: 0.9997 - accuracy: 0.9832 - loss: 0.0223 - val_AUC: 0.8048 - val_accuracy: 0.7549 - val_loss: 1.3531\n",
            "Epoch 48/100\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - AUC: 0.9997 - accuracy: 0.9791 - loss: 0.0235 - val_AUC: 0.7987 - val_accuracy: 0.7647 - val_loss: 1.3640\n",
            "Epoch 49/100\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - AUC: 0.9997 - accuracy: 0.9752 - loss: 0.0230 - val_AUC: 0.7987 - val_accuracy: 0.7549 - val_loss: 1.3814\n",
            "Epoch 50/100\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - AUC: 0.9997 - accuracy: 0.9897 - loss: 0.0229 - val_AUC: 0.7983 - val_accuracy: 0.7451 - val_loss: 1.4103\n",
            "Epoch 51/100\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - AUC: 0.9997 - accuracy: 0.9897 - loss: 0.0209 - val_AUC: 0.7913 - val_accuracy: 0.7451 - val_loss: 1.4255\n",
            "Epoch 52/100\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - AUC: 0.9997 - accuracy: 0.9759 - loss: 0.0213 - val_AUC: 0.7912 - val_accuracy: 0.7549 - val_loss: 1.4323\n",
            "Epoch 53/100\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - AUC: 0.9997 - accuracy: 0.9799 - loss: 0.0210 - val_AUC: 0.7910 - val_accuracy: 0.7451 - val_loss: 1.4459\n",
            "Epoch 54/100\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - AUC: 0.9997 - accuracy: 0.9799 - loss: 0.0222 - val_AUC: 0.7860 - val_accuracy: 0.7451 - val_loss: 1.4607\n",
            "Epoch 55/100\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - AUC: 0.9997 - accuracy: 0.9799 - loss: 0.0217 - val_AUC: 0.7933 - val_accuracy: 0.7451 - val_loss: 1.4669\n",
            "Epoch 56/100\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - AUC: 0.9997 - accuracy: 0.9752 - loss: 0.0210 - val_AUC: 0.7933 - val_accuracy: 0.7451 - val_loss: 1.4757\n",
            "Epoch 57/100\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - AUC: 0.9997 - accuracy: 0.9752 - loss: 0.0207 - val_AUC: 0.7860 - val_accuracy: 0.7451 - val_loss: 1.4865\n",
            "Epoch 58/100\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - AUC: 0.9997 - accuracy: 0.9832 - loss: 0.0203 - val_AUC: 0.7883 - val_accuracy: 0.7549 - val_loss: 1.4977\n",
            "Epoch 59/100\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - AUC: 0.9997 - accuracy: 0.9759 - loss: 0.0210 - val_AUC: 0.7883 - val_accuracy: 0.7549 - val_loss: 1.5047\n",
            "Epoch 60/100\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - AUC: 0.9997 - accuracy: 0.9759 - loss: 0.0199 - val_AUC: 0.7883 - val_accuracy: 0.7549 - val_loss: 1.5115\n",
            "Epoch 61/100\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - AUC: 0.9997 - accuracy: 0.9759 - loss: 0.0201 - val_AUC: 0.7883 - val_accuracy: 0.7451 - val_loss: 1.5271\n",
            "Epoch 62/100\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - AUC: 0.9997 - accuracy: 0.9799 - loss: 0.0202 - val_AUC: 0.7883 - val_accuracy: 0.7451 - val_loss: 1.5391\n",
            "Epoch 63/100\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - AUC: 0.9997 - accuracy: 0.9799 - loss: 0.0203 - val_AUC: 0.7883 - val_accuracy: 0.7549 - val_loss: 1.5437\n",
            "Epoch 64/100\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - AUC: 0.9997 - accuracy: 0.9799 - loss: 0.0200 - val_AUC: 0.7883 - val_accuracy: 0.7549 - val_loss: 1.5474\n",
            "Epoch 65/100\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - AUC: 0.9997 - accuracy: 0.9799 - loss: 0.0196 - val_AUC: 0.7883 - val_accuracy: 0.7451 - val_loss: 1.5642\n",
            "Epoch 66/100\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - AUC: 0.9997 - accuracy: 0.9759 - loss: 0.0197 - val_AUC: 0.7883 - val_accuracy: 0.7451 - val_loss: 1.5704\n",
            "Epoch 67/100\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - AUC: 0.9997 - accuracy: 0.9759 - loss: 0.0194 - val_AUC: 0.7883 - val_accuracy: 0.7549 - val_loss: 1.5747\n",
            "Epoch 68/100\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - AUC: 0.9997 - accuracy: 0.9825 - loss: 0.0195 - val_AUC: 0.7883 - val_accuracy: 0.7549 - val_loss: 1.5734\n",
            "Epoch 69/100\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - AUC: 0.9997 - accuracy: 0.9897 - loss: 0.0189 - val_AUC: 0.7883 - val_accuracy: 0.7549 - val_loss: 1.5798\n",
            "Epoch 70/100\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - AUC: 0.9997 - accuracy: 0.9897 - loss: 0.0187 - val_AUC: 0.7883 - val_accuracy: 0.7549 - val_loss: 1.5923\n",
            "Epoch 71/100\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - AUC: 0.9997 - accuracy: 0.9897 - loss: 0.0189 - val_AUC: 0.7879 - val_accuracy: 0.7451 - val_loss: 1.6036\n",
            "Epoch 72/100\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - AUC: 0.9998 - accuracy: 0.9897 - loss: 0.0191 - val_AUC: 0.7883 - val_accuracy: 0.7549 - val_loss: 1.6045\n",
            "Epoch 73/100\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - AUC: 0.9997 - accuracy: 0.9897 - loss: 0.0186 - val_AUC: 0.7883 - val_accuracy: 0.7549 - val_loss: 1.6120\n",
            "Epoch 74/100\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - AUC: 0.9997 - accuracy: 0.9897 - loss: 0.0183 - val_AUC: 0.7883 - val_accuracy: 0.7549 - val_loss: 1.6221\n",
            "Epoch 75/100\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - AUC: 0.9997 - accuracy: 0.9897 - loss: 0.0184 - val_AUC: 0.7896 - val_accuracy: 0.7549 - val_loss: 1.6282\n",
            "Epoch 76/100\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - AUC: 0.9997 - accuracy: 0.9897 - loss: 0.0184 - val_AUC: 0.7896 - val_accuracy: 0.7549 - val_loss: 1.6338\n",
            "Epoch 77/100\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - AUC: 0.9998 - accuracy: 0.9897 - loss: 0.0180 - val_AUC: 0.7896 - val_accuracy: 0.7451 - val_loss: 1.6368\n",
            "Epoch 78/100\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - AUC: 0.9997 - accuracy: 0.9897 - loss: 0.0181 - val_AUC: 0.7896 - val_accuracy: 0.7451 - val_loss: 1.6481\n",
            "Epoch 79/100\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - AUC: 0.9997 - accuracy: 0.9897 - loss: 0.0180 - val_AUC: 0.7896 - val_accuracy: 0.7451 - val_loss: 1.6557\n",
            "Epoch 80/100\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - AUC: 0.9998 - accuracy: 0.9948 - loss: 0.0178 - val_AUC: 0.7896 - val_accuracy: 0.7451 - val_loss: 1.6544\n",
            "Epoch 81/100\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - AUC: 0.9998 - accuracy: 0.9948 - loss: 0.0171 - val_AUC: 0.7896 - val_accuracy: 0.7451 - val_loss: 1.6657\n",
            "Epoch 82/100\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - AUC: 0.9998 - accuracy: 0.9948 - loss: 0.0157 - val_AUC: 0.7896 - val_accuracy: 0.7451 - val_loss: 1.6630\n",
            "Epoch 83/100\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - AUC: 0.9998 - accuracy: 0.9948 - loss: 0.0151 - val_AUC: 0.7896 - val_accuracy: 0.7451 - val_loss: 1.6923\n",
            "Epoch 84/100\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - AUC: 0.9999 - accuracy: 0.9944 - loss: 0.0146 - val_AUC: 0.7892 - val_accuracy: 0.7451 - val_loss: 1.7051\n",
            "Epoch 85/100\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - AUC: 0.9999 - accuracy: 0.9883 - loss: 0.0148 - val_AUC: 0.7894 - val_accuracy: 0.7451 - val_loss: 1.7106\n",
            "Epoch 86/100\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - AUC: 0.9998 - accuracy: 0.9872 - loss: 0.0149 - val_AUC: 0.7896 - val_accuracy: 0.7451 - val_loss: 1.7020\n",
            "Epoch 87/100\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - AUC: 0.9998 - accuracy: 0.9948 - loss: 0.0148 - val_AUC: 0.7896 - val_accuracy: 0.7451 - val_loss: 1.7181\n",
            "Epoch 88/100\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - AUC: 0.9998 - accuracy: 0.9875 - loss: 0.0146 - val_AUC: 0.7894 - val_accuracy: 0.7451 - val_loss: 1.7183\n",
            "Epoch 89/100\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - AUC: 0.9998 - accuracy: 0.9875 - loss: 0.0149 - val_AUC: 0.7896 - val_accuracy: 0.7451 - val_loss: 1.7174\n",
            "Epoch 90/100\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - AUC: 0.9998 - accuracy: 0.9948 - loss: 0.0148 - val_AUC: 0.7896 - val_accuracy: 0.7451 - val_loss: 1.7355\n",
            "Epoch 91/100\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - AUC: 0.9999 - accuracy: 0.9842 - loss: 0.0149 - val_AUC: 0.7894 - val_accuracy: 0.7451 - val_loss: 1.7328\n",
            "Epoch 92/100\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - AUC: 0.9998 - accuracy: 0.9802 - loss: 0.0148 - val_AUC: 0.7894 - val_accuracy: 0.7451 - val_loss: 1.7256\n",
            "Epoch 93/100\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - AUC: 0.9998 - accuracy: 0.9875 - loss: 0.0145 - val_AUC: 0.7894 - val_accuracy: 0.7451 - val_loss: 1.7396\n",
            "Epoch 94/100\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - AUC: 0.9998 - accuracy: 0.9802 - loss: 0.0146 - val_AUC: 0.7894 - val_accuracy: 0.7549 - val_loss: 1.7485\n",
            "Epoch 95/100\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - AUC: 0.9998 - accuracy: 0.9810 - loss: 0.0146 - val_AUC: 0.7894 - val_accuracy: 0.7451 - val_loss: 1.7494\n",
            "Epoch 96/100\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - AUC: 0.9998 - accuracy: 0.9842 - loss: 0.0146 - val_AUC: 0.7894 - val_accuracy: 0.7451 - val_loss: 1.7501\n",
            "Epoch 97/100\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - AUC: 0.9998 - accuracy: 0.9842 - loss: 0.0146 - val_AUC: 0.7894 - val_accuracy: 0.7451 - val_loss: 1.7514\n",
            "Epoch 98/100\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - AUC: 0.9998 - accuracy: 0.9875 - loss: 0.0145 - val_AUC: 0.7894 - val_accuracy: 0.7451 - val_loss: 1.7572\n",
            "Epoch 99/100\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - AUC: 0.9998 - accuracy: 0.9948 - loss: 0.0143 - val_AUC: 0.7894 - val_accuracy: 0.7549 - val_loss: 1.7611\n",
            "Epoch 100/100\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - AUC: 0.9999 - accuracy: 0.9948 - loss: 0.0143 - val_AUC: 0.7894 - val_accuracy: 0.7549 - val_loss: 1.7685\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - AUC: 0.7695 - accuracy: 0.7521 - loss: 1.7830 \n",
            "Baseline 2 Test Accuracy: 0.7422, AUC: 0.7754\n"
          ]
        }
      ],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, LSTM, Dropout, Reshape # Tambah Reshape\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "tf.random.set_seed(42)\n",
        "# Assume nBits is the size of your fingerprint (e.g., 1024)\n",
        "# Ini harus sama dengan ukuran fingerprint yang lu bikin pake RDKit\n",
        "nBits = 1024 # Sesuaikan dengan nBits yang lu pake di RDKit\n",
        "\n",
        "# Hyperparameters (sesuai kode lu, vocab_size dan embedding_dim nggak kepake lagi)\n",
        "# vocab_size = len(tokenizer.word_index) + 1 # Not needed\n",
        "# embedding_dim = 64 # Not needed\n",
        "units = [128, 64, 32] # Ukuran hidden state LSTM\n",
        "dropout_rate = 0.4\n",
        "learning_rate = 0.001\n",
        "\n",
        "# Build the model for Fingerprint input\n",
        "model_baseline_3 = Sequential()\n",
        "\n",
        "# Layer Input: Langsung terima vektor fingerprint\n",
        "# Bentuk inputnya adalah (panjang_fingerprint,)\n",
        "model_baseline_3.add(tf.keras.Input(shape=(nBits,))) # Define input shape\n",
        "\n",
        "# Tambahkan layer Reshape untuk mengubah (nBits,) menjadi (1, nBits)\n",
        "# Agar cocok dengan input shape LSTM yang butuh 3D (samples, timesteps, features)\n",
        "model_baseline_3.add(Reshape((1, nBits))) # Ubah (features,) jadi (1, features)\n",
        "\n",
        "# Layer LSTM: Sekarang inputnya udah 3D (samples, 1, nBits)\n",
        "# Return sequences False karena kita cuma punya 1 timestep dan mau output single vector\n",
        "model_baseline_3.add(LSTM(units[0], activation='tanh', recurrent_activation='sigmoid', return_sequences=True))\n",
        "model_baseline_3.add(LSTM(units[1], activation='tanh', recurrent_activation='sigmoid', return_sequences=True))\n",
        "model_baseline_3.add(LSTM(units[2], activation='tanh', recurrent_activation='sigmoid', return_sequences=False))\n",
        "\n",
        "# Layer Dropout\n",
        "model_baseline_3.add(Dropout(dropout_rate))\n",
        "\n",
        "# Layer Output: Dense dengan 1 unit dan activation sigmoid (kalau task-nya binary classification)\n",
        "# Kalau task-nya regresi, ganti activation jadi 'linear' atau jangan pakai activation\n",
        "model_baseline_3.add(Dense(1, activation='sigmoid')) # Ganti kalau task-nya regresi\n",
        "\n",
        "# Compile the model\n",
        "model_baseline_3.compile(optimizer=Adam(learning_rate=learning_rate),\n",
        "                        loss='binary_crossentropy',\n",
        "                        metrics=['accuracy', 'AUC'])\n",
        "\n",
        "model_baseline_3.summary() # Penting buat ngecek arsitektur dan shape\n",
        "\n",
        "# Train the model\n",
        "history_baseline_3 = model_baseline_3.fit(\n",
        "    X_train,\n",
        "    y_train,\n",
        "    validation_split=0.2,\n",
        "    epochs=100,\n",
        "    batch_size=32\n",
        ")\n",
        "\n",
        "# Evaluate the model\n",
        "loss, accuracy, auc = model_baseline_3.evaluate(X_test, y_test)\n",
        "print(f\"Baseline 2 Test Accuracy: {accuracy:.4f}, AUC: {auc:.4f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "66377758-4598-4026-ba8a-b1f96a73df7d",
      "metadata": {
        "id": "66377758-4598-4026-ba8a-b1f96a73df7d"
      },
      "source": [
        "## Evaluate"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "id": "56d67aa0-a242-4a91-a361-6d0c2e348557",
      "metadata": {
        "id": "56d67aa0-a242-4a91-a361-6d0c2e348557",
        "outputId": "b3c03cd5-4d78-41ff-ef91-d3c0cb21cac3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step  \n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step  \n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step  \n",
            "Baseline 1 Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.67      0.83      0.74        60\n",
            "           1       0.81      0.63      0.71        68\n",
            "\n",
            "    accuracy                           0.73       128\n",
            "   macro avg       0.74      0.73      0.73       128\n",
            "weighted avg       0.74      0.73      0.72       128\n",
            "\n",
            "\n",
            "Baseline 2 Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.71      0.85      0.77        60\n",
            "           1       0.84      0.69      0.76        68\n",
            "\n",
            "    accuracy                           0.77       128\n",
            "   macro avg       0.77      0.77      0.77       128\n",
            "weighted avg       0.78      0.77      0.76       128\n",
            "\n",
            "\n",
            "Baseline 3 Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.68      0.83      0.75        60\n",
            "           1       0.82      0.66      0.73        68\n",
            "\n",
            "    accuracy                           0.74       128\n",
            "   macro avg       0.75      0.75      0.74       128\n",
            "weighted avg       0.76      0.74      0.74       128\n",
            "\n"
          ]
        }
      ],
      "source": [
        "from sklearn.metrics import classification_report\n",
        "\n",
        "# Generate predictions\n",
        "y_pred_1 = (model_baseline_1.predict(X_test) > 0.5).astype(\"int32\")\n",
        "y_pred_2 = (model_baseline_2.predict(X_test) > 0.5).astype(\"int32\")\n",
        "y_pred_3 = (model_baseline_3.predict(X_test) > 0.5).astype(\"int32\")\n",
        "\n",
        "# Classification reports\n",
        "print(\"Baseline 1 Classification Report:\")\n",
        "print(classification_report(y_test, y_pred_1))\n",
        "\n",
        "print(\"\\nBaseline 2 Classification Report:\")\n",
        "print(classification_report(y_test, y_pred_2))\n",
        "\n",
        "print(\"\\nBaseline 3 Classification Report:\")\n",
        "print(classification_report(y_test, y_pred_3))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "400b3fac-e4fb-447d-9d7a-80886f03a10b",
      "metadata": {
        "id": "400b3fac-e4fb-447d-9d7a-80886f03a10b"
      },
      "source": [
        "# Optimised Model"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e4c5b6eb-e715-4abc-b66d-722d685de9ae",
      "metadata": {
        "id": "e4c5b6eb-e715-4abc-b66d-722d685de9ae"
      },
      "source": [
        "Skema eksperimen akan dibagi menjadi 3, yaitu:\n",
        "\n",
        "| Skema | Population Size |\n",
        "|-------|:---------------:|\n",
        "| Model 1 |     10        |\n",
        "| Model 2 |     15        |\n",
        "| Model 3 |     20        |\n",
        "\n",
        "Dengan hyperparameter LSTM yang dioptimasi\n",
        "| Hyperparameter | Rentang Nilai |\n",
        "|:---:|:--------:|\n",
        "|Learning Rate | [0.0001, ... , 0.01] |\n",
        "| Unit | [32, 33, ..., 127, 128] |\n",
        "| Layer | [1, 2, ..., 9, 10] |\n",
        "|Dropout Rate | [0.1, 0.2, ..., 0.4, 0.5] |\n",
        "|Batch Size | [32, 64, 128] |\n",
        "\n",
        "Dan parameter yang ditetapkan\n",
        "| Hyperparameter | Rentang Nilai |\n",
        "|:---:|:--------:|\n",
        "|Epoch | 100 |\n",
        "| Activation | tanh|\n",
        "| Rec Activation | sigmoid |\n",
        "|Output Activation | sigmoid |\n",
        "|Callbacks | Early Stopping [monitor = val_loss, patience=7, restore_best_weights = true] |"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e546dc74-b222-42d8-bc7a-be0aa19363d0",
      "metadata": {
        "id": "e546dc74-b222-42d8-bc7a-be0aa19363d0"
      },
      "source": [
        "## Importing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "id": "QKTAuqU-jQMj",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QKTAuqU-jQMj",
        "outputId": "e8e73132-a5cc-48c9-b645-105fd97f8ec1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting niapy\n",
            "  Downloading niapy-2.5.2-py3-none-any.whl (187 kB)\n",
            "     -------------------------------------- 188.0/188.0 kB 1.9 MB/s eta 0:00:00\n",
            "Requirement already satisfied: matplotlib<4.0.0,>=3.8.0 in c:\\users\\dito adistya\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from niapy) (3.10.0)\n",
            "Requirement already satisfied: numpy<2.0.0,>=1.26.1 in c:\\users\\dito adistya\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from niapy) (1.26.4)\n",
            "Collecting openpyxl<4.0.0,>=3.1.2\n",
            "  Downloading openpyxl-3.1.5-py2.py3-none-any.whl (250 kB)\n",
            "     -------------------------------------- 250.9/250.9 kB 1.5 MB/s eta 0:00:00\n",
            "Requirement already satisfied: pandas<3.0.0,>=2.1.1 in c:\\users\\dito adistya\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from niapy) (2.1.4)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in c:\\users\\dito adistya\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from matplotlib<4.0.0,>=3.8.0->niapy) (1.3.2)\n",
            "Requirement already satisfied: cycler>=0.10 in c:\\users\\dito adistya\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from matplotlib<4.0.0,>=3.8.0->niapy) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in c:\\users\\dito adistya\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from matplotlib<4.0.0,>=3.8.0->niapy) (4.58.4)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in c:\\users\\dito adistya\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from matplotlib<4.0.0,>=3.8.0->niapy) (1.4.8)\n",
            "Requirement already satisfied: packaging>=20.0 in c:\\users\\dito adistya\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from matplotlib<4.0.0,>=3.8.0->niapy) (25.0)\n",
            "Requirement already satisfied: pillow>=8 in c:\\users\\dito adistya\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from matplotlib<4.0.0,>=3.8.0->niapy) (11.2.1)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in c:\\users\\dito adistya\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from matplotlib<4.0.0,>=3.8.0->niapy) (3.2.3)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in c:\\users\\dito adistya\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from matplotlib<4.0.0,>=3.8.0->niapy) (2.9.0.post0)\n",
            "Collecting et-xmlfile\n",
            "  Downloading et_xmlfile-2.0.0-py3-none-any.whl (18 kB)\n",
            "Requirement already satisfied: pytz>=2020.1 in c:\\users\\dito adistya\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from pandas<3.0.0,>=2.1.1->niapy) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.1 in c:\\users\\dito adistya\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from pandas<3.0.0,>=2.1.1->niapy) (2025.2)\n",
            "Requirement already satisfied: six>=1.5 in c:\\users\\dito adistya\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from python-dateutil>=2.7->matplotlib<4.0.0,>=3.8.0->niapy) (1.17.0)\n",
            "Installing collected packages: et-xmlfile, openpyxl, niapy\n",
            "Successfully installed et-xmlfile-2.0.0 niapy-2.5.2 openpyxl-3.1.5\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n",
            "[notice] A new release of pip available: 22.3 -> 25.2\n",
            "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
          ]
        }
      ],
      "source": [
        "!pip install niapy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "32d5bdf9-2735-4d06-9444-b762cc432e51",
      "metadata": {
        "id": "32d5bdf9-2735-4d06-9444-b762cc432e51"
      },
      "outputs": [],
      "source": [
        "# LSTM MODEL BUILDER UNTUK FINGERPRINT\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import LSTM, Dense, Dropout, Reshape\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "from sklearn.metrics import roc_auc_score\n",
        "import numpy as np\n",
        "from niapy.algorithms.basic import MonarchButterflyOptimization\n",
        "from niapy.task import Task\n",
        "from niapy.problems import Problem"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2e2c17ec-2064-4083-a75d-0a2af9f0b786",
      "metadata": {
        "id": "2e2c17ec-2064-4083-a75d-0a2af9f0b786"
      },
      "source": [
        "## LSTM Model Builder"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "id": "2945d18e-ebb8-4cd6-8733-d5d95e6f788b",
      "metadata": {
        "id": "2945d18e-ebb8-4cd6-8733-d5d95e6f788b"
      },
      "outputs": [],
      "source": [
        "def build_evaluate_lstm_fingerprint(params):\n",
        "    learning_rate, units, layers, dropout_rate, batch_size = params\n",
        "\n",
        "    units = int(units)\n",
        "    layers = max(1, int(layers))\n",
        "    batch_size = max(1, int(batch_size))\n",
        "\n",
        "    model = Sequential()\n",
        "    model.add(tf.keras.Input(shape=(nBits,))) # Input shape (nBits,)\n",
        "    model.add(Reshape((1, nBits)))          # Reshape ke (1, nBits)\n",
        "\n",
        "    # Tambahkan layer LSTM INTERMEDIATE (kalau ada > 1 layer)\n",
        "    for i in range(layers - 1):\n",
        "        # Layer intermediate harus return_sequences=True\n",
        "        model.add(LSTM(units, activation='tanh', recurrent_activation='sigmoid', return_sequences=True))\n",
        "        model.add(Dropout(dropout_rate))\n",
        "\n",
        "    model.add(LSTM(units, activation='tanh', recurrent_activation='sigmoid', return_sequences=False))\n",
        "    model.add(Dropout(dropout_rate))\n",
        "\n",
        "    model.add(Dense(1, activation='sigmoid'))\n",
        "\n",
        "    model.compile(optimizer=Adam(learning_rate=learning_rate),\n",
        "                  loss='binary_crossentropy',\n",
        "                  metrics=['accuracy', 'AUC'])\n",
        "\n",
        "    # ... (rest of the fit, evaluate, return part) ...\n",
        "    early_stop = EarlyStopping(patience=7, restore_best_weights=True)\n",
        "    history = model.fit(X_train,\n",
        "                        y_train,\n",
        "                        validation_split=0.2,\n",
        "                        epochs=100,\n",
        "                        batch_size=batch_size,\n",
        "                        callbacks=[early_stop],\n",
        "                        verbose=0)\n",
        "\n",
        "    val_preds = model.predict(X_test).flatten()\n",
        "    val_auc = roc_auc_score(y_test, val_preds)\n",
        "\n",
        "    print(f\"Evaluated params: {params} → Val AUC: {val_auc:.4f}\")\n",
        "\n",
        "    return 1 - val_auc\n",
        "\n",
        "        # --- LANGKAH PEMBERSIHAN MEMORI ---\n",
        "    # Penting banget buat dijalankan setelah selesai pake model\n",
        "    del model # Hapus objek model dari memori Python\n",
        "    tf.keras.backend.clear_session() # Clear session Keras, ini ngebantu rilis resource TensorFlow/GPU\n",
        "    gc.collect() # Jalankan garbage collector Python (opsional, tapi bisa ngebantu)\n",
        "    # --- AKHIR LANGKAH PEMBERSIHAN MEMORI ---"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "id": "27d5b7ab-fa61-4b2b-8f3b-9c2a1c823067",
      "metadata": {
        "id": "27d5b7ab-fa61-4b2b-8f3b-9c2a1c823067"
      },
      "outputs": [],
      "source": [
        "class LSTMOptimizationProblem(Problem):\n",
        "    def __init__(self, param_bounds, nBits): # Tambahin nBits sebagai parameter kalau perlu\n",
        "        dimension = len(param_bounds)\n",
        "        lower = [0.0] * dimension # Asumsi rentang niapy [0, 1]\n",
        "        upper = [1.0] * dimension # Asumsi rentang niapy [0, 1]\n",
        "\n",
        "        super().__init__(dimension=dimension, lower=lower, upper=upper)\n",
        "        self.param_bounds = param_bounds\n",
        "        # Simpan nBits kalau fungsi build_evaluate_lstm_fingerprint butuh akses\n",
        "        self.nBits = nBits\n",
        "\n",
        "    # Metode utama yang dipanggil MBA untuk evaluasi solusi 'x'\n",
        "    def _evaluate(self, x):\n",
        "        decoded_params_values = []\n",
        "        for i in range(self.dimension):\n",
        "            bounds_list = self.param_bounds[i]\n",
        "            # Hitung index berdasarkan nilai x[i] (dalam rentang [0, 1])\n",
        "            # dan jumlah pilihan di list param_bounds[i]\n",
        "            index = min(int(x[i] * len(bounds_list)), len(bounds_list) - 1) # Pastikan index valid\n",
        "            decoded_value = bounds_list[index]\n",
        "            decoded_params_values.append(decoded_value)\n",
        "        try:\n",
        "            # Panggil fungsi model yang udah dimodifikasi\n",
        "            fitness_value = build_evaluate_lstm_fingerprint(decoded_params_values)\n",
        "        except Exception as e:\n",
        "            # Handle kalau training atau evaluasi model error\n",
        "            print(f\"Error evaluating params {decoded_params_values}: {e}\")\n",
        "            fitness_value = 1.0 # Kasih fitness terburuk kalau error\n",
        "\n",
        "        return fitness_value # Ini 1 - AUC dari fungsi model lu\n",
        "\n",
        "# --- Bagian setup MBA di luar class ---"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "27de9397-8ac5-4710-93bc-bee38d7a77ed",
      "metadata": {
        "id": "27de9397-8ac5-4710-93bc-bee38d7a77ed"
      },
      "source": [
        "## Define Search Space"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "id": "e341544e-fddc-4c37-b55d-8d7a3c18326a",
      "metadata": {
        "id": "e341544e-fddc-4c37-b55d-8d7a3c18326a"
      },
      "outputs": [],
      "source": [
        "# Define parameter bounds (ini tetap sama)\n",
        "# Pastikan urutan ini sama persis dengan urutan parameter di fungsi build_evaluate_lstm_fingerprint\n",
        "param_bounds = [\n",
        "    [0.0001, 0.001, 0.01],\n",
        "    list(range(32, 129)),\n",
        "    list(range(1, 4)),\n",
        "    [0.1, 0.2, 0.3, 0.4, 0.5],\n",
        "    [32, 64, 128]\n",
        "]\n",
        "\n",
        "# Pastikan nBits lu udah didefinisikan, sama dengan yang dipake di fingerprint\n",
        "nBits = 1024 # Contoh, sesuaikan\n",
        "\n",
        "# Buat instance Problem class yang udah diperbaiki\n",
        "problem = LSTMOptimizationProblem(param_bounds, nBits)\n",
        "\n",
        "# Run MBO (bagian ini sebagian besar sama)\n",
        "population_sizes = [10, 15, 20]\n",
        "results = {}"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "11bd277e-9c66-4f8d-89e0-60c1d023b4ed",
      "metadata": {
        "id": "11bd277e-9c66-4f8d-89e0-60c1d023b4ed"
      },
      "source": [
        "## Define Object Function"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "id": "def75eee-50c3-416d-818c-19b45bfe5b0c",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "def75eee-50c3-416d-818c-19b45bfe5b0c",
        "outputId": "92ff0b4b-859c-4e85-c67f-78f1193ba2e4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Running MBO with population size = 10\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step  \n",
            "Evaluated params: [0.01, 113, 2, 0.3, 64] → Val AUC: 0.8873\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step  \n",
            "Evaluated params: [0.01, 109, 3, 0.2, 32] → Val AUC: 0.8466\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step  \n",
            "Evaluated params: [0.001, 67, 2, 0.5, 64] → Val AUC: 0.8485\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step  \n",
            "Evaluated params: [0.01, 48, 2, 0.4, 128] → Val AUC: 0.8368\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step  \n",
            "Evaluated params: [0.0001, 60, 3, 0.3, 64] → Val AUC: 0.8404\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step  \n",
            "Evaluated params: [0.001, 44, 1, 0.2, 64] → Val AUC: 0.8853\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step  \n",
            "Evaluated params: [0.001, 113, 1, 0.2, 128] → Val AUC: 0.8574\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step  \n",
            "Evaluated params: [0.0001, 123, 3, 0.3, 32] → Val AUC: 0.8806\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step  \n",
            "Evaluated params: [0.0001, 97, 2, 0.5, 128] → Val AUC: 0.8708\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step \n",
            "Evaluated params: [0.0001, 128, 1, 0.2, 64] → Val AUC: 0.8826\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step  \n",
            "Evaluated params: [0.01, 113, 3, 0.3, 64] → Val AUC: 0.8770\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step  \n",
            "Evaluated params: [0.0001, 60, 3, 0.2, 64] → Val AUC: 0.8673\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step \n",
            "Evaluated params: [0.001, 128, 3, 0.5, 64] → Val AUC: 0.8895\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step  \n",
            "Evaluated params: [0.0001, 60, 3, 0.3, 32] → Val AUC: 0.8819\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step \n",
            "Evaluated params: [0.001, 109, 2, 0.2, 64] → Val AUC: 0.8471\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step \n",
            "Evaluated params: [0.01, 32, 3, 0.5, 64] → Val AUC: 0.8436\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step  \n",
            "Evaluated params: [0.01, 113, 3, 0.3, 64] → Val AUC: 0.8904\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step  \n",
            "Evaluated params: [0.0001, 128, 3, 0.3, 64] → Val AUC: 0.8733\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step  \n",
            "Evaluated params: [0.01, 32, 3, 0.3, 128] → Val AUC: 0.8218\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step\n",
            "Evaluated params: [0.001, 113, 3, 0.3, 64] → Val AUC: 0.8365\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step  \n",
            "Evaluated params: [0.01, 113, 3, 0.3, 64] → Val AUC: 0.8824\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step  \n",
            "Evaluated params: [0.001, 128, 3, 0.5, 64] → Val AUC: 0.8838\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step \n",
            "Evaluated params: [0.0001, 60, 3, 0.3, 32] → Val AUC: 0.8799\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step  \n",
            "Evaluated params: [0.01, 113, 3, 0.3, 64] → Val AUC: 0.8841\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step  \n",
            "Evaluated params: [0.0001, 128, 3, 0.3, 64] → Val AUC: 0.8630\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step \n",
            "Evaluated params: [0.0001, 60, 3, 0.2, 64] → Val AUC: 0.8480\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step  \n",
            "Evaluated params: [0.001, 109, 2, 0.2, 64] → Val AUC: 0.8711\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step  \n",
            "Evaluated params: [0.01, 32, 3, 0.5, 64] → Val AUC: 0.8735\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step  \n",
            "Evaluated params: [0.01, 113, 2, 0.3, 64] → Val AUC: 0.8875\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step  \n",
            "Evaluated params: [0.001, 44, 1, 0.2, 64] → Val AUC: 0.8804\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step  \n",
            "Evaluated params: [0.01, 128, 3, 0.3, 64] → Val AUC: 0.8833\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step  \n",
            "Evaluated params: [0.01, 32, 2, 0.2, 64] → Val AUC: 0.8272\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step  \n",
            "Evaluated params: [0.0001, 60, 3, 0.5, 64] → Val AUC: 0.8574\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step  \n",
            "Evaluated params: [0.0001, 60, 2, 0.2, 64] → Val AUC: 0.8743\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step  \n",
            "Evaluated params: [0.01, 113, 3, 0.5, 64] → Val AUC: 0.8895\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step  \n",
            "Evaluated params: [0.01, 113, 3, 0.3, 64] → Val AUC: 0.8850\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step  \n",
            "Evaluated params: [0.0001, 113, 3, 0.5, 64] → Val AUC: 0.8512\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step  \n",
            "Evaluated params: [0.01, 113, 3, 0.5, 128] → Val AUC: 0.8843\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step  \n",
            "Evaluated params: [0.01, 128, 3, 0.5, 64] → Val AUC: 0.8841\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step \n",
            "Evaluated params: [0.01, 113, 3, 0.3, 128] → Val AUC: 0.8914\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step  \n",
            "Evaluated params: [0.01, 113, 3, 0.3, 128] → Val AUC: 0.8784\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step  \n",
            "Evaluated params: [0.01, 113, 3, 0.5, 64] → Val AUC: 0.8873\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step  \n",
            "Evaluated params: [0.01, 113, 3, 0.3, 64] → Val AUC: 0.8733\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step  \n",
            "Evaluated params: [0.01, 113, 3, 0.5, 128] → Val AUC: 0.8828\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step  \n",
            "Evaluated params: [0.01, 128, 3, 0.5, 64] → Val AUC: 0.8816\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step  \n",
            "Evaluated params: [0.01, 128, 3, 0.3, 64] → Val AUC: 0.8801\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step  \n",
            "Evaluated params: [0.0001, 60, 2, 0.2, 64] → Val AUC: 0.8725\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step  \n",
            "Evaluated params: [0.0001, 60, 3, 0.5, 64] → Val AUC: 0.8676\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step  \n",
            "Evaluated params: [0.01, 113, 2, 0.3, 64] → Val AUC: 0.8755\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step  \n",
            "Evaluated params: [0.01, 113, 3, 0.3, 64] → Val AUC: 0.8738\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step  \n",
            "Evaluated params: [0.01, 128, 3, 0.3, 64] → Val AUC: 0.8789\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step  \n",
            "Evaluated params: [0.01, 60, 3, 0.3, 64] → Val AUC: 0.8841\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step  \n",
            "Evaluated params: [0.01, 113, 2, 0.3, 64] → Val AUC: 0.8831\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step  \n",
            "Evaluated params: [0.01, 60, 3, 0.5, 64] → Val AUC: 0.8686\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step  \n",
            "Evaluated params: [0.01, 113, 3, 0.5, 64] → Val AUC: 0.8748\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step  \n",
            "Evaluated params: [0.01, 113, 3, 0.3, 128] → Val AUC: 0.8882\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step  \n",
            "Evaluated params: [0.01, 60, 1, 0.3, 128] → Val AUC: 0.8434\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step  \n",
            "Evaluated params: [0.01, 128, 3, 0.5, 32] → Val AUC: 0.8882\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step  \n",
            "Evaluated params: [0.01, 113, 3, 0.3, 128] → Val AUC: 0.8748\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step  \n",
            "Evaluated params: [0.0001, 128, 3, 0.3, 128] → Val AUC: 0.8392\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step \n",
            "Evaluated params: [0.01, 128, 3, 0.5, 32] → Val AUC: 0.9039\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 11ms/step\n",
            "Evaluated params: [0.01, 113, 3, 0.3, 128] → Val AUC: 0.8846\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step \n",
            "Evaluated params: [0.01, 60, 3, 0.3, 64] → Val AUC: 0.8897\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step  \n",
            "Evaluated params: [0.01, 113, 2, 0.3, 64] → Val AUC: 0.8907\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step  \n",
            "Evaluated params: [0.01, 128, 3, 0.3, 64] → Val AUC: 0.8865\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step  \n",
            "Evaluated params: [0.01, 113, 3, 0.5, 64] → Val AUC: 0.8958\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step \n",
            "Evaluated params: [0.01, 113, 3, 0.3, 128] → Val AUC: 0.8169\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step  \n",
            "Evaluated params: [0.01, 60, 3, 0.5, 64] → Val AUC: 0.8814\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step  \n",
            "Evaluated params: [0.01, 113, 3, 0.5, 64] → Val AUC: 0.8294\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step  \n",
            "Evaluated params: [0.01, 113, 3, 0.5, 128] → Val AUC: 0.8843\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step  \n",
            "Evaluated params: [0.01, 60, 3, 0.5, 64] → Val AUC: 0.8725\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step  \n",
            "Evaluated params: [0.01, 113, 3, 0.3, 64] → Val AUC: 0.8733\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step \n",
            "Evaluated params: [0.01, 113, 3, 0.5, 64] → Val AUC: 0.8738\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step  \n",
            "Evaluated params: [0.01, 60, 2, 0.5, 128] → Val AUC: 0.8377\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step  \n",
            "Evaluated params: [0.01, 60, 3, 0.5, 64] → Val AUC: 0.9010\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step  \n",
            "Evaluated params: [0.01, 128, 3, 0.5, 32] → Val AUC: 0.8966\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step  \n",
            "Evaluated params: [0.01, 128, 3, 0.5, 32] → Val AUC: 0.8983\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step  \n",
            "Evaluated params: [0.01, 128, 3, 0.5, 32] → Val AUC: 0.8873\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step  \n",
            "Evaluated params: [0.01, 128, 3, 0.5, 32] → Val AUC: 0.9069\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step  \n",
            "Evaluated params: [0.01, 128, 3, 0.5, 128] → Val AUC: 0.8985\n"
          ]
        },
        {
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
            "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
            "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[19]\u001b[39m\u001b[32m, line 10\u001b[39m\n\u001b[32m      7\u001b[39m task = Task(problem=problem, max_iters=\u001b[32m20\u001b[39m)\n\u001b[32m      9\u001b[39m \u001b[38;5;66;03m# Jalankan optimasi\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m10\u001b[39m best = \u001b[43malgorithm\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtask\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     11\u001b[39m best_params_continuous = best[\u001b[32m0\u001b[39m] \u001b[38;5;66;03m# Hasil terbaik dalam rentang kontinyu [0, 1] atau bounds\u001b[39;00m\n\u001b[32m     12\u001b[39m best_fitness = best[\u001b[32m1\u001b[39m] \u001b[38;5;66;03m# Nilai fitness terbaik (1 - AUC terendah)\u001b[39;00m\n",
            "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Dito Adistya\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\niapy\\algorithms\\algorithm.py:321\u001b[39m, in \u001b[36mAlgorithm.run\u001b[39m\u001b[34m(self, task)\u001b[39m\n\u001b[32m    319\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m    320\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m threading.current_thread() \u001b[38;5;129;01mis\u001b[39;00m threading.main_thread() \u001b[38;5;129;01mand\u001b[39;00m multiprocessing.current_process().name == \u001b[33m'\u001b[39m\u001b[33mMainProcess\u001b[39m\u001b[33m'\u001b[39m:\n\u001b[32m--> \u001b[39m\u001b[32m321\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m e\n\u001b[32m    322\u001b[39m     \u001b[38;5;28mself\u001b[39m.exception = e\n\u001b[32m    323\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;28;01mNone\u001b[39;00m\n",
            "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Dito Adistya\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\niapy\\algorithms\\algorithm.py:314\u001b[39m, in \u001b[36mAlgorithm.run\u001b[39m\u001b[34m(self, task)\u001b[39m\n\u001b[32m    312\u001b[39m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m task.stopping_condition():\n\u001b[32m    313\u001b[39m     \u001b[38;5;28mself\u001b[39m.callbacks.before_iteration(pop, fpop, xb, fxb, **params)\n\u001b[32m--> \u001b[39m\u001b[32m314\u001b[39m     pop, fpop, xb, fxb, params = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mrun_iteration\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtask\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpop\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfpop\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mxb\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfxb\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mparams\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    315\u001b[39m     \u001b[38;5;28mself\u001b[39m.callbacks.after_iteration(pop, fpop, xb, fxb, **params)\n\u001b[32m    316\u001b[39m     task.next_iter()\n",
            "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Dito Adistya\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\niapy\\algorithms\\basic\\mbo.py:268\u001b[39m, in \u001b[36mMonarchButterflyOptimization.run_iteration\u001b[39m\u001b[34m(self, task, population, population_fitness, best_x, best_fitness, **params)\u001b[39m\n\u001b[32m    266\u001b[39m current_best = population[\u001b[32m0\u001b[39m]\n\u001b[32m    267\u001b[39m population[-\u001b[38;5;28mself\u001b[39m.keep:] = elite\n\u001b[32m--> \u001b[39m\u001b[32m268\u001b[39m population_fitness, population = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mevaluate_and_sort\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtask\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpopulation\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    269\u001b[39m best_x, best_fitness = \u001b[38;5;28mself\u001b[39m.get_best(population, population_fitness, best_x, best_fitness)\n\u001b[32m    270\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m population, population_fitness, best_x, best_fitness, {\u001b[33m'\u001b[39m\u001b[33mcurrent_best\u001b[39m\u001b[33m'\u001b[39m: current_best}\n",
            "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Dito Adistya\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\niapy\\algorithms\\basic\\mbo.py:205\u001b[39m, in \u001b[36mMonarchButterflyOptimization.evaluate_and_sort\u001b[39m\u001b[34m(task, butterflies)\u001b[39m\n\u001b[32m    190\u001b[39m \u001b[38;5;129m@staticmethod\u001b[39m\n\u001b[32m    191\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mevaluate_and_sort\u001b[39m(task, butterflies):\n\u001b[32m    192\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33mr\u001b[39m\u001b[33;03m\"\"\"Evaluate and sort the butterfly population.\u001b[39;00m\n\u001b[32m    193\u001b[39m \n\u001b[32m    194\u001b[39m \u001b[33;03m    Args:\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m    203\u001b[39m \n\u001b[32m    204\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m205\u001b[39m     fitness = \u001b[43mnp\u001b[49m\u001b[43m.\u001b[49m\u001b[43mapply_along_axis\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtask\u001b[49m\u001b[43m.\u001b[49m\u001b[43meval\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbutterflies\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    206\u001b[39m     indices = np.argsort(fitness)\n\u001b[32m    207\u001b[39m     butterflies = butterflies[indices]\n",
            "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Dito Adistya\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\numpy\\lib\\shape_base.py:379\u001b[39m, in \u001b[36mapply_along_axis\u001b[39m\u001b[34m(func1d, axis, arr, *args, **kwargs)\u001b[39m\n\u001b[32m    375\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mStopIteration\u001b[39;00m:\n\u001b[32m    376\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[32m    377\u001b[39m         \u001b[33m'\u001b[39m\u001b[33mCannot apply_along_axis when any iteration dimensions are 0\u001b[39m\u001b[33m'\u001b[39m\n\u001b[32m    378\u001b[39m     ) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m379\u001b[39m res = asanyarray(\u001b[43mfunc1d\u001b[49m\u001b[43m(\u001b[49m\u001b[43minarr_view\u001b[49m\u001b[43m[\u001b[49m\u001b[43mind0\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[32m    381\u001b[39m \u001b[38;5;66;03m# build a buffer for storing evaluations of func1d.\u001b[39;00m\n\u001b[32m    382\u001b[39m \u001b[38;5;66;03m# remove the requested axis, and add the new ones on the end.\u001b[39;00m\n\u001b[32m    383\u001b[39m \u001b[38;5;66;03m# laid out so that each write is contiguous.\u001b[39;00m\n\u001b[32m    384\u001b[39m \u001b[38;5;66;03m# for a tuple index inds, buff[inds] = func1d(inarr_view[inds])\u001b[39;00m\n\u001b[32m    385\u001b[39m buff = zeros(inarr_view.shape[:-\u001b[32m1\u001b[39m] + res.shape, res.dtype)\n",
            "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Dito Adistya\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\niapy\\task.py:145\u001b[39m, in \u001b[36mTask.eval\u001b[39m\u001b[34m(self, x)\u001b[39m\n\u001b[32m    142\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m np.inf\n\u001b[32m    144\u001b[39m \u001b[38;5;28mself\u001b[39m.evals += \u001b[32m1\u001b[39m\n\u001b[32m--> \u001b[39m\u001b[32m145\u001b[39m x_f = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mproblem\u001b[49m\u001b[43m.\u001b[49m\u001b[43mevaluate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m * \u001b[38;5;28mself\u001b[39m.optimization_type.value\n\u001b[32m    147\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m x_f < \u001b[38;5;28mself\u001b[39m.x_f * \u001b[38;5;28mself\u001b[39m.optimization_type.value:\n\u001b[32m    148\u001b[39m     \u001b[38;5;28mself\u001b[39m.x_f = x_f * \u001b[38;5;28mself\u001b[39m.optimization_type.value\n",
            "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Dito Adistya\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\niapy\\problems\\problem.py:57\u001b[39m, in \u001b[36mProblem.evaluate\u001b[39m\u001b[34m(self, x)\u001b[39m\n\u001b[32m     54\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m x.shape[\u001b[32m0\u001b[39m] != \u001b[38;5;28mself\u001b[39m.dimension:\n\u001b[32m     55\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[33m'\u001b[39m\u001b[33mDimensions do not match. \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[33m != \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[33m'\u001b[39m.format(x.shape[\u001b[32m0\u001b[39m], \u001b[38;5;28mself\u001b[39m.dimension))\n\u001b[32m---> \u001b[39m\u001b[32m57\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_evaluate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n",
            "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[17]\u001b[39m\u001b[32m, line 24\u001b[39m, in \u001b[36mLSTMOptimizationProblem._evaluate\u001b[39m\u001b[34m(self, x)\u001b[39m\n\u001b[32m     21\u001b[39m     decoded_params_values.append(decoded_value)\n\u001b[32m     22\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m     23\u001b[39m     \u001b[38;5;66;03m# Panggil fungsi model yang udah dimodifikasi\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m24\u001b[39m     fitness_value = \u001b[43mbuild_evaluate_lstm_fingerprint\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdecoded_params_values\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     25\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m     26\u001b[39m     \u001b[38;5;66;03m# Handle kalau training atau evaluasi model error\u001b[39;00m\n\u001b[32m     27\u001b[39m     \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mError evaluating params \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdecoded_params_values\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00me\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n",
            "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[16]\u001b[39m\u001b[32m, line 29\u001b[39m, in \u001b[36mbuild_evaluate_lstm_fingerprint\u001b[39m\u001b[34m(params)\u001b[39m\n\u001b[32m     27\u001b[39m \u001b[38;5;66;03m# ... (rest of the fit, evaluate, return part) ...\u001b[39;00m\n\u001b[32m     28\u001b[39m early_stop = EarlyStopping(patience=\u001b[32m7\u001b[39m, restore_best_weights=\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[32m---> \u001b[39m\u001b[32m29\u001b[39m history = \u001b[43mmodel\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     30\u001b[39m \u001b[43m                    \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     31\u001b[39m \u001b[43m                    \u001b[49m\u001b[43mvalidation_split\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m0.2\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m     32\u001b[39m \u001b[43m                    \u001b[49m\u001b[43mepochs\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m100\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m     33\u001b[39m \u001b[43m                    \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[43m=\u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     34\u001b[39m \u001b[43m                    \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m=\u001b[49m\u001b[43m[\u001b[49m\u001b[43mearly_stop\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     35\u001b[39m \u001b[43m                    \u001b[49m\u001b[43mverbose\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m0\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m     37\u001b[39m val_preds = model.predict(X_test).flatten()\n\u001b[32m     38\u001b[39m val_auc = roc_auc_score(y_test, val_preds)\n",
            "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Dito Adistya\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\utils\\traceback_utils.py:117\u001b[39m, in \u001b[36mfilter_traceback.<locals>.error_handler\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    115\u001b[39m filtered_tb = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    116\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m117\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    118\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m    119\u001b[39m     filtered_tb = _process_traceback_frames(e.__traceback__)\n",
            "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Dito Adistya\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\backend\\tensorflow\\trainer.py:377\u001b[39m, in \u001b[36mTensorFlowTrainer.fit\u001b[39m\u001b[34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq)\u001b[39m\n\u001b[32m    375\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m step, iterator \u001b[38;5;129;01min\u001b[39;00m epoch_iterator:\n\u001b[32m    376\u001b[39m     callbacks.on_train_batch_begin(step)\n\u001b[32m--> \u001b[39m\u001b[32m377\u001b[39m     logs = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mtrain_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    378\u001b[39m     callbacks.on_train_batch_end(step, logs)\n\u001b[32m    379\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.stop_training:\n",
            "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Dito Adistya\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\backend\\tensorflow\\trainer.py:220\u001b[39m, in \u001b[36mTensorFlowTrainer._make_function.<locals>.function\u001b[39m\u001b[34m(iterator)\u001b[39m\n\u001b[32m    216\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mfunction\u001b[39m(iterator):\n\u001b[32m    217\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\n\u001b[32m    218\u001b[39m         iterator, (tf.data.Iterator, tf.distribute.DistributedIterator)\n\u001b[32m    219\u001b[39m     ):\n\u001b[32m--> \u001b[39m\u001b[32m220\u001b[39m         opt_outputs = \u001b[43mmulti_step_on_iterator\u001b[49m\u001b[43m(\u001b[49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    221\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m opt_outputs.has_value():\n\u001b[32m    222\u001b[39m             \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mStopIteration\u001b[39;00m\n",
            "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Dito Adistya\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\tensorflow\\python\\util\\traceback_utils.py:150\u001b[39m, in \u001b[36mfilter_traceback.<locals>.error_handler\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    148\u001b[39m filtered_tb = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    149\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m150\u001b[39m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    151\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m    152\u001b[39m   filtered_tb = _process_traceback_frames(e.__traceback__)\n",
            "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Dito Adistya\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\polymorphic_function.py:833\u001b[39m, in \u001b[36mFunction.__call__\u001b[39m\u001b[34m(self, *args, **kwds)\u001b[39m\n\u001b[32m    830\u001b[39m compiler = \u001b[33m\"\u001b[39m\u001b[33mxla\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._jit_compile \u001b[38;5;28;01melse\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[33mnonXla\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    832\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m OptionalXlaContext(\u001b[38;5;28mself\u001b[39m._jit_compile):\n\u001b[32m--> \u001b[39m\u001b[32m833\u001b[39m   result = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    835\u001b[39m new_tracing_count = \u001b[38;5;28mself\u001b[39m.experimental_get_tracing_count()\n\u001b[32m    836\u001b[39m without_tracing = (tracing_count == new_tracing_count)\n",
            "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Dito Adistya\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\polymorphic_function.py:919\u001b[39m, in \u001b[36mFunction._call\u001b[39m\u001b[34m(self, *args, **kwds)\u001b[39m\n\u001b[32m    913\u001b[39m   \u001b[38;5;66;03m# If we did not create any variables the trace we have is good enough.\u001b[39;00m\n\u001b[32m    914\u001b[39m   filtered_flat_args = (\n\u001b[32m    915\u001b[39m       \u001b[38;5;28mself\u001b[39m._concrete_variable_creation_fn.function_type.unpack_inputs(\n\u001b[32m    916\u001b[39m           bound_args\n\u001b[32m    917\u001b[39m       )\n\u001b[32m    918\u001b[39m   )\n\u001b[32m--> \u001b[39m\u001b[32m919\u001b[39m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_concrete_variable_creation_fn\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_call_flat\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# pylint: disable=protected-access\u001b[39;49;00m\n\u001b[32m    920\u001b[39m \u001b[43m      \u001b[49m\u001b[43mfiltered_flat_args\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    921\u001b[39m \u001b[43m      \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_concrete_variable_creation_fn\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcaptured_inputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    922\u001b[39m \u001b[43m  \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    924\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mfn_with_cond\u001b[39m(inner_args, inner_kwds):\n\u001b[32m    925\u001b[39m \u001b[38;5;250m  \u001b[39m\u001b[33;03m\"\"\"Conditionally runs initialization if it's needed.\"\"\"\u001b[39;00m\n",
            "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Dito Adistya\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\concrete_function.py:1322\u001b[39m, in \u001b[36mConcreteFunction._call_flat\u001b[39m\u001b[34m(self, tensor_inputs, captured_inputs)\u001b[39m\n\u001b[32m   1318\u001b[39m possible_gradient_type = gradients_util.PossibleTapeGradientTypes(args)\n\u001b[32m   1319\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m (possible_gradient_type == gradients_util.POSSIBLE_GRADIENT_TYPES_NONE\n\u001b[32m   1320\u001b[39m     \u001b[38;5;129;01mand\u001b[39;00m executing_eagerly):\n\u001b[32m   1321\u001b[39m   \u001b[38;5;66;03m# No tape is watching; skip to running the function.\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1322\u001b[39m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_inference_function\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcall_preflattened\u001b[49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1323\u001b[39m forward_backward = \u001b[38;5;28mself\u001b[39m._select_forward_and_backward_functions(\n\u001b[32m   1324\u001b[39m     args,\n\u001b[32m   1325\u001b[39m     possible_gradient_type,\n\u001b[32m   1326\u001b[39m     executing_eagerly)\n\u001b[32m   1327\u001b[39m forward_function, args_with_tangents = forward_backward.forward()\n",
            "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Dito Adistya\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\atomic_function.py:216\u001b[39m, in \u001b[36mAtomicFunction.call_preflattened\u001b[39m\u001b[34m(self, args)\u001b[39m\n\u001b[32m    214\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mcall_preflattened\u001b[39m(\u001b[38;5;28mself\u001b[39m, args: Sequence[core.Tensor]) -> Any:\n\u001b[32m    215\u001b[39m \u001b[38;5;250m  \u001b[39m\u001b[33;03m\"\"\"Calls with flattened tensor inputs and returns the structured output.\"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m216\u001b[39m   flat_outputs = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mcall_flat\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    217\u001b[39m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m.function_type.pack_output(flat_outputs)\n",
            "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Dito Adistya\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\atomic_function.py:251\u001b[39m, in \u001b[36mAtomicFunction.call_flat\u001b[39m\u001b[34m(self, *args)\u001b[39m\n\u001b[32m    249\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m record.stop_recording():\n\u001b[32m    250\u001b[39m   \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._bound_context.executing_eagerly():\n\u001b[32m--> \u001b[39m\u001b[32m251\u001b[39m     outputs = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_bound_context\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcall_function\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    252\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    253\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    254\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mfunction_type\u001b[49m\u001b[43m.\u001b[49m\u001b[43mflat_outputs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    255\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    256\u001b[39m   \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    257\u001b[39m     outputs = make_call_op_in_graph(\n\u001b[32m    258\u001b[39m         \u001b[38;5;28mself\u001b[39m,\n\u001b[32m    259\u001b[39m         \u001b[38;5;28mlist\u001b[39m(args),\n\u001b[32m    260\u001b[39m         \u001b[38;5;28mself\u001b[39m._bound_context.function_call_options.as_attrs(),\n\u001b[32m    261\u001b[39m     )\n",
            "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Dito Adistya\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\tensorflow\\python\\eager\\context.py:1688\u001b[39m, in \u001b[36mContext.call_function\u001b[39m\u001b[34m(self, name, tensor_inputs, num_outputs)\u001b[39m\n\u001b[32m   1686\u001b[39m cancellation_context = cancellation.context()\n\u001b[32m   1687\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m cancellation_context \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1688\u001b[39m   outputs = \u001b[43mexecute\u001b[49m\u001b[43m.\u001b[49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1689\u001b[39m \u001b[43m      \u001b[49m\u001b[43mname\u001b[49m\u001b[43m.\u001b[49m\u001b[43mdecode\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mutf-8\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1690\u001b[39m \u001b[43m      \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[43m=\u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1691\u001b[39m \u001b[43m      \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtensor_inputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1692\u001b[39m \u001b[43m      \u001b[49m\u001b[43mattrs\u001b[49m\u001b[43m=\u001b[49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1693\u001b[39m \u001b[43m      \u001b[49m\u001b[43mctx\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m   1694\u001b[39m \u001b[43m  \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1695\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   1696\u001b[39m   outputs = execute.execute_with_cancellation(\n\u001b[32m   1697\u001b[39m       name.decode(\u001b[33m\"\u001b[39m\u001b[33mutf-8\u001b[39m\u001b[33m\"\u001b[39m),\n\u001b[32m   1698\u001b[39m       num_outputs=num_outputs,\n\u001b[32m   (...)\u001b[39m\u001b[32m   1702\u001b[39m       cancellation_manager=cancellation_context,\n\u001b[32m   1703\u001b[39m   )\n",
            "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Dito Adistya\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\tensorflow\\python\\eager\\execute.py:53\u001b[39m, in \u001b[36mquick_execute\u001b[39m\u001b[34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[39m\n\u001b[32m     51\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m     52\u001b[39m   ctx.ensure_initialized()\n\u001b[32m---> \u001b[39m\u001b[32m53\u001b[39m   tensors = \u001b[43mpywrap_tfe\u001b[49m\u001b[43m.\u001b[49m\u001b[43mTFE_Py_Execute\u001b[49m\u001b[43m(\u001b[49m\u001b[43mctx\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_handle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mop_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     54\u001b[39m \u001b[43m                                      \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     55\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m core._NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m     56\u001b[39m   \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
            "\u001b[31mKeyboardInterrupt\u001b[39m: "
          ]
        }
      ],
      "source": [
        "for pop_size in population_sizes:\n",
        "    print(f\"\\nRunning MBO with population size = {pop_size}\")\n",
        "\n",
        "    # Inisialisasi algoritma MBA\n",
        "    algorithm = MonarchButterflyOptimization(population_size=pop_size, limit=1.2, butterfly_population=pop_size)\n",
        "    # Set Task\n",
        "    task = Task(problem=problem, max_iters=20)\n",
        "\n",
        "    # Jalankan optimasi\n",
        "    best = algorithm.run(task)\n",
        "    best_params_continuous = best[0] # Hasil terbaik dalam rentang kontinyu [0, 1] atau bounds\n",
        "    best_fitness = best[1] # Nilai fitness terbaik (1 - AUC terendah)\n",
        "\n",
        "    # --- Menerjemahkan hasil terbaik kontinyu kembali ke hyperparameter diskrit ---\n",
        "    # Logic ini mirip dengan yang di _evaluate, tapi cuma untuk hasil terbaik (best_params_continuous)\n",
        "    decoded_best_params = {}\n",
        "    # Pastikan urutannya sama dengan param_bounds\n",
        "    param_names = ['learning_rate', 'units', 'layers', 'dropout_rate', 'batch_size']\n",
        "\n",
        "    for i in range(len(param_bounds)):\n",
        "        bounds_list = param_bounds[i]\n",
        "        # Petakan nilai kontinyu best_params_continuous[i] ke index di bounds_list\n",
        "        index = min(int(best_params_continuous[i] * len(bounds_list)), len(bounds_list) - 1)\n",
        "        decoded_best_params[param_names[i]] = bounds_list[index]\n",
        "\n",
        "\n",
        "    results[pop_size] = {\n",
        "        'best_fitness': best_fitness,\n",
        "        'best_params': decoded_best_params\n",
        "    }\n",
        "    print(f\"Best params for pop={pop_size}: {decoded_best_params}, Fitness: {best_fitness:.4f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6EqyNBVVMDO0",
      "metadata": {
        "id": "6EqyNBVVMDO0"
      },
      "source": [
        "Eksperimen"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "d4e27684",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Import library\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import LSTM, Dense, Dropout, Reshape\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "from sklearn.metrics import roc_auc_score\n",
        "from niapy.algorithms.basic import MonarchButterflyOptimization\n",
        "from niapy.task import Task\n",
        "from niapy.problems import Problem\n",
        "import gc\n",
        "from tqdm import tqdm\n",
        "\n",
        "# Set random seed untuk reproduktibilitas\n",
        "tf.random.set_seed(42)\n",
        "np.random.seed(42)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "6130e1c4",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting niapy\n",
            "  Downloading niapy-2.5.2-py3-none-any.whl.metadata (23 kB)\n",
            "Requirement already satisfied: matplotlib<4.0.0,>=3.8.0 in /home/dito-adistya/miniconda3/envs/py311/lib/python3.11/site-packages (from niapy) (3.10.6)\n",
            "Collecting numpy<2.0.0,>=1.26.1 (from niapy)\n",
            "  Downloading numpy-1.26.4-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (61 kB)\n",
            "Collecting openpyxl<4.0.0,>=3.1.2 (from niapy)\n",
            "  Downloading openpyxl-3.1.5-py2.py3-none-any.whl.metadata (2.5 kB)\n",
            "Requirement already satisfied: pandas<3.0.0,>=2.1.1 in /home/dito-adistya/miniconda3/envs/py311/lib/python3.11/site-packages (from niapy) (2.3.2)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /home/dito-adistya/miniconda3/envs/py311/lib/python3.11/site-packages (from matplotlib<4.0.0,>=3.8.0->niapy) (1.3.3)\n",
            "Requirement already satisfied: cycler>=0.10 in /home/dito-adistya/miniconda3/envs/py311/lib/python3.11/site-packages (from matplotlib<4.0.0,>=3.8.0->niapy) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /home/dito-adistya/miniconda3/envs/py311/lib/python3.11/site-packages (from matplotlib<4.0.0,>=3.8.0->niapy) (4.60.0)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /home/dito-adistya/miniconda3/envs/py311/lib/python3.11/site-packages (from matplotlib<4.0.0,>=3.8.0->niapy) (1.4.9)\n",
            "Requirement already satisfied: packaging>=20.0 in /home/dito-adistya/miniconda3/envs/py311/lib/python3.11/site-packages (from matplotlib<4.0.0,>=3.8.0->niapy) (25.0)\n",
            "Requirement already satisfied: pillow>=8 in /home/dito-adistya/miniconda3/envs/py311/lib/python3.11/site-packages (from matplotlib<4.0.0,>=3.8.0->niapy) (11.3.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /home/dito-adistya/miniconda3/envs/py311/lib/python3.11/site-packages (from matplotlib<4.0.0,>=3.8.0->niapy) (3.2.5)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /home/dito-adistya/miniconda3/envs/py311/lib/python3.11/site-packages (from matplotlib<4.0.0,>=3.8.0->niapy) (2.9.0.post0)\n",
            "Collecting et-xmlfile (from openpyxl<4.0.0,>=3.1.2->niapy)\n",
            "  Downloading et_xmlfile-2.0.0-py3-none-any.whl.metadata (2.7 kB)\n",
            "Requirement already satisfied: pytz>=2020.1 in /home/dito-adistya/miniconda3/envs/py311/lib/python3.11/site-packages (from pandas<3.0.0,>=2.1.1->niapy) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /home/dito-adistya/miniconda3/envs/py311/lib/python3.11/site-packages (from pandas<3.0.0,>=2.1.1->niapy) (2025.2)\n",
            "Requirement already satisfied: six>=1.5 in /home/dito-adistya/miniconda3/envs/py311/lib/python3.11/site-packages (from python-dateutil>=2.7->matplotlib<4.0.0,>=3.8.0->niapy) (1.17.0)\n",
            "Downloading niapy-2.5.2-py3-none-any.whl (187 kB)\n",
            "Downloading numpy-1.26.4-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (18.3 MB)\n",
            "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m18.3/18.3 MB\u001b[0m \u001b[31m1.8 MB/s\u001b[0m  \u001b[33m0:00:10\u001b[0m\u001b[0m eta \u001b[36m0:00:01\u001b[0m[36m0:00:01\u001b[0m\n",
            "\u001b[?25hDownloading openpyxl-3.1.5-py2.py3-none-any.whl (250 kB)\n",
            "Downloading et_xmlfile-2.0.0-py3-none-any.whl (18 kB)\n",
            "Installing collected packages: numpy, et-xmlfile, openpyxl, niapy\n",
            "\u001b[2K  Attempting uninstall: numpy\n",
            "\u001b[2K    Found existing installation: numpy 2.3.3\n",
            "\u001b[2K    Uninstalling numpy-2.3.3:━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0/4\u001b[0m [numpy]\n",
            "\u001b[2K      Successfully uninstalled numpy-2.3.3━━━━━━━━\u001b[0m \u001b[32m0/4\u001b[0m [numpy]\n",
            "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4/4\u001b[0m [niapy]━━━━━\u001b[0m \u001b[32m3/4\u001b[0m [niapy]xl]\n",
            "\u001b[1A\u001b[2KSuccessfully installed et-xmlfile-2.0.0 niapy-2.5.2 numpy-1.26.4 openpyxl-3.1.5\n",
            "Note: you may need to restart the kernel to use updated packages.\n"
          ]
        }
      ],
      "source": [
        "pip install niapy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "id": "b3bd6ea6",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Fungsi untuk membangun dan mengevaluasi model LSTM\n",
        "def build_evaluate_lstm_fingerprint(params):\n",
        "    learning_rate, units, layers, dropout_rate, batch_size = params\n",
        "\n",
        "    units = int(units)\n",
        "    layers = max(1, int(layers))\n",
        "    batch_size = max(1, int(batch_size))\n",
        "\n",
        "    model = Sequential()\n",
        "    model.add(tf.keras.Input(shape=(nBits,)))\n",
        "    model.add(Reshape((1, nBits)))\n",
        "\n",
        "    for i in range(layers - 1):\n",
        "        model.add(LSTM(units, activation='tanh', recurrent_activation='sigmoid', return_sequences=True))\n",
        "        model.add(Dropout(dropout_rate))\n",
        "\n",
        "    model.add(LSTM(units, activation='tanh', recurrent_activation='sigmoid', return_sequences=False))\n",
        "    model.add(Dropout(dropout_rate))\n",
        "\n",
        "    model.add(Dense(1, activation='sigmoid'))\n",
        "\n",
        "    model.compile(optimizer=Adam(learning_rate=learning_rate),\n",
        "                  loss='binary_crossentropy',\n",
        "                  metrics=['accuracy', 'AUC'])\n",
        "\n",
        "    early_stop = EarlyStopping(monitor='val_loss', patience=7, restore_best_weights=True)\n",
        "    \n",
        "    # verbose=0 agar output tidak terlalu panjang\n",
        "    history = model.fit(X_train,\n",
        "                        y_train,\n",
        "                        validation_split=0.2,\n",
        "                        epochs=100,\n",
        "                        batch_size=batch_size,\n",
        "                        callbacks=[early_stop],\n",
        "                        verbose=0)\n",
        "\n",
        "    val_preds = model.predict(X_test, verbose=0).flatten()\n",
        "    val_auc = roc_auc_score(y_test, val_preds)\n",
        "\n",
        "    del model\n",
        "    tf.keras.backend.clear_session()\n",
        "    gc.collect()\n",
        "\n",
        "    return 1 - val_auc"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "id": "c3fffd3e",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Kelas untuk MBO\n",
        "class LSTMOptimizationProblem(Problem):\n",
        "    def __init__(self, param_bounds):\n",
        "        dimension = len(param_bounds)\n",
        "        super().__init__(dimension=dimension, lower=[0.0] * dimension, upper=[1.0] * dimension)\n",
        "        self.param_bounds = param_bounds\n",
        "\n",
        "    def _evaluate(self, x):\n",
        "        decoded_params_values = []\n",
        "        for i in range(self.dimension):\n",
        "            bounds_list = self.param_bounds[i]\n",
        "            index = min(int(x[i] * len(bounds_list)), len(bounds_list) - 1)\n",
        "            decoded_value = bounds_list[index]\n",
        "            decoded_params_values.append(decoded_value)\n",
        "        \n",
        "        try:\n",
        "            fitness_value = build_evaluate_lstm_fingerprint(decoded_params_values)\n",
        "        except Exception as e:\n",
        "            print(f\"Error evaluating params {decoded_params_values}: {e}\")\n",
        "            fitness_value = 1.0\n",
        "\n",
        "        return fitness_value"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a3b0bf75",
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "MBO Pop Size Progress:   0%|          | 0/3 [00:00<?, ?it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From c:\\Users\\Dito Adistya\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\backend\\common\\global_state.py:82: The name tf.reset_default_graph is deprecated. Please use tf.compat.v1.reset_default_graph instead.\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From c:\\Users\\Dito Adistya\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\backend\\common\\global_state.py:82: The name tf.reset_default_graph is deprecated. Please use tf.compat.v1.reset_default_graph instead.\n",
            "\n",
            "Exception ignored in: <function WeakKeyDictionary.__init__.<locals>.remove at 0x000001F507961EE0>\n",
            "Traceback (most recent call last):\n",
            "  File \"c:\\Users\\Dito Adistya\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\weakref.py\", line 370, in remove\n",
            "    self = selfref()\n",
            "           ^^^^^^^^^\n",
            "KeyboardInterrupt: \n"
          ]
        }
      ],
      "source": [
        "# Definisi ruang pencarian (search space)\n",
        "param_bounds = [\n",
        "    [0.0001, 0.001, 0.01],\n",
        "    list(range(32, 129)),\n",
        "    list(range(1, 4)),\n",
        "    [0.1, 0.2, 0.3, 0.4, 0.5],\n",
        "    [32, 64, 128]\n",
        "]\n",
        "\n",
        "problem = LSTMOptimizationProblem(param_bounds)\n",
        "\n",
        "population_sizes = [10, 15, 20]\n",
        "results = {}\n",
        "\n",
        "# Gunakan tqdm untuk memantau progress per population size\n",
        "for pop_size in tqdm(population_sizes, desc=\"MBO Pop Size Progress\"):\n",
        "    algorithm = MonarchButterflyOptimization(population_size=pop_size, limit=1.2, butterfly_population=pop_size)\n",
        "    task = Task(problem=problem, max_iters=20)\n",
        "    \n",
        "    best = algorithm.run(task)\n",
        "    best_params_continuous = best[0]\n",
        "    best_fitness = best[1]\n",
        "\n",
        "    decoded_best_params = {}\n",
        "    param_names = ['learning_rate', 'units', 'layers', 'dropout_rate', 'batch_size']\n",
        "\n",
        "    for i in range(len(param_bounds)):\n",
        "        bounds_list = param_bounds[i]\n",
        "        index = min(int(best_params_continuous[i] * len(bounds_list)), len(bounds_list) - 1)\n",
        "        decoded_best_params[param_names[i]] = bounds_list[index]\n",
        "\n",
        "    results[pop_size] = {\n",
        "        'best_fitness': best_fitness,\n",
        "        'best_params': decoded_best_params\n",
        "    }\n",
        "\n",
        "print(\"\\n\\n=============== MBO Results Summary ===============\")\n",
        "for pop_size, res in results.items():\n",
        "    print(f\"Population Size = {pop_size}\")\n",
        "    print(f\"  Best Parameters: {res['best_params']}\")\n",
        "    print(f\"  Best AUC: {1 - res['best_fitness']:.4f}\")\n",
        "    print(\"-\" * 40)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "80af6256",
      "metadata": {},
      "source": [
        "# EXP 1\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "id": "02599af9",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Fungsi untuk membangun dan mengevaluasi model LSTM\n",
        "def build_evaluate_lstm_fingerprint(params):\n",
        "    learning_rate, units, layers, dropout_rate, batch_size = params\n",
        "\n",
        "    units = int(units)\n",
        "    layers = max(1, int(layers))\n",
        "    batch_size = max(1, int(batch_size))\n",
        "\n",
        "    model = Sequential()\n",
        "    model.add(tf.keras.Input(shape=(nBits,)))\n",
        "    model.add(Reshape((1, nBits)))\n",
        "\n",
        "    for i in range(layers - 1):\n",
        "        model.add(LSTM(units, activation='tanh', recurrent_activation='sigmoid', return_sequences=True))\n",
        "        model.add(Dropout(dropout_rate))\n",
        "\n",
        "    model.add(LSTM(units, activation='tanh', recurrent_activation='sigmoid', return_sequences=False))\n",
        "    model.add(Dropout(dropout_rate))\n",
        "\n",
        "    model.add(Dense(1, activation='sigmoid'))\n",
        "\n",
        "    model.compile(optimizer=Adam(learning_rate=learning_rate),\n",
        "                  loss='binary_crossentropy',\n",
        "                  metrics=['accuracy', 'AUC'])\n",
        "\n",
        "    early_stop = EarlyStopping(monitor='val_loss', patience=7, restore_best_weights=True)\n",
        "    \n",
        "    history = model.fit(X_train,\n",
        "                        y_train,\n",
        "                        validation_split=0.2,\n",
        "                        epochs=100,\n",
        "                        batch_size=batch_size,\n",
        "                        callbacks=[early_stop],\n",
        "                        verbose=0)\n",
        "\n",
        "    val_preds = model.predict(X_test, verbose=0).flatten()\n",
        "    val_auc = roc_auc_score(y_test, val_preds)\n",
        "\n",
        "    del model\n",
        "    tf.keras.backend.clear_session()\n",
        "    gc.collect()\n",
        "\n",
        "    return 1 - val_auc"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "id": "a0e68faf",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Kelas untuk MBO\n",
        "class LSTMOptimizationProblem(Problem):\n",
        "    def __init__(self, param_bounds):\n",
        "        dimension = len(param_bounds)\n",
        "        super().__init__(dimension=dimension, lower=[0.0] * dimension, upper=[1.0] * dimension)\n",
        "        self.param_bounds = param_bounds\n",
        "\n",
        "    def _evaluate(self, x):\n",
        "        decoded_params_values = []\n",
        "        for i in range(self.dimension):\n",
        "            bounds_list = self.param_bounds[i]\n",
        "            index = min(int(x[i] * len(bounds_list)), len(bounds_list) - 1)\n",
        "            decoded_value = bounds_list[index]\n",
        "            decoded_params_values.append(decoded_value)\n",
        "        \n",
        "        try:\n",
        "            fitness_value = build_evaluate_lstm_fingerprint(decoded_params_values)\n",
        "            # Ditambahkan print manual supaya lu tahu setiap kali satu model selesai di-evaluate\n",
        "            print(f\"Evaluated params: {decoded_params_values} -> Val AUC: {1 - fitness_value:.4f}\")\n",
        "        except Exception as e:\n",
        "            print(f\"Error evaluating params {decoded_params_values}: {e}\")\n",
        "            fitness_value = 1.0\n",
        "\n",
        "        return fitness_value"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "id": "f2424746",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Running MBO with population size = 10\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "MBO Optimization:   0%|          | 0/20 [00:00<?, ?it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Evaluated params: [0.0001, 34, 3, 0.2, 32] -> Val AUC: 0.8899\n",
            "Evaluated params: [0.001, 74, 3, 0.5, 128] -> Val AUC: 0.8742\n",
            "Evaluated params: [0.0001, 58, 2, 0.5, 32] -> Val AUC: 0.8952\n",
            "Evaluated params: [0.01, 43, 3, 0.4, 32] -> Val AUC: 0.9087\n",
            "Evaluated params: [0.0001, 47, 1, 0.1, 128] -> Val AUC: 0.8808\n",
            "Evaluated params: [0.0001, 87, 2, 0.5, 128] -> Val AUC: 0.8835\n",
            "Evaluated params: [0.001, 91, 1, 0.1, 32] -> Val AUC: 0.8969\n",
            "Evaluated params: [0.0001, 51, 3, 0.1, 64] -> Val AUC: 0.8874\n",
            "Evaluated params: [0.0001, 86, 3, 0.5, 64] -> Val AUC: 0.8828\n",
            "Evaluated params: [0.01, 53, 2, 0.5, 64] -> Val AUC: 0.8872\n",
            "Evaluated params: [0.0001, 87, 3, 0.5, 32] -> Val AUC: 0.9023\n",
            "Evaluated params: [0.001, 86, 3, 0.5, 32] -> Val AUC: 0.9004\n",
            "Evaluated params: [0.01, 53, 1, 0.1, 64] -> Val AUC: 0.8952\n",
            "Evaluated params: [0.0001, 87, 1, 0.5, 64] -> Val AUC: 0.8955\n",
            "Evaluated params: [0.0001, 53, 3, 0.5, 32] -> Val AUC: 0.8974\n",
            "Evaluated params: [0.0001, 87, 3, 0.1, 128] -> Val AUC: 0.8803\n",
            "Evaluated params: [0.0001, 87, 3, 0.5, 64] -> Val AUC: 0.8911\n",
            "Evaluated params: [0.001, 87, 1, 0.5, 32] -> Val AUC: 0.8960\n",
            "Evaluated params: [0.0001, 87, 3, 0.5, 32] -> Val AUC: 0.9011\n",
            "Evaluated params: [0.0001, 128, 3, 0.5, 32] -> Val AUC: 0.9028\n",
            "Evaluated params: [0.0001, 128, 3, 0.5, 32] -> Val AUC: 0.8950\n",
            "Evaluated params: [0.0001, 87, 3, 0.5, 32] -> Val AUC: 0.9004\n",
            "Evaluated params: [0.0001, 87, 3, 0.5, 32] -> Val AUC: 0.8962\n",
            "Evaluated params: [0.001, 86, 3, 0.5, 32] -> Val AUC: 0.9062\n",
            "Evaluated params: [0.0001, 53, 3, 0.5, 32] -> Val AUC: 0.8852\n",
            "Evaluated params: [0.001, 87, 1, 0.5, 32] -> Val AUC: 0.8994\n",
            "Evaluated params: [0.0001, 87, 1, 0.5, 64] -> Val AUC: 0.8967\n",
            "Evaluated params: [0.01, 53, 1, 0.1, 64] -> Val AUC: 0.8952\n",
            "Evaluated params: [0.01, 43, 3, 0.4, 32] -> Val AUC: 0.9101\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "MBO Optimization:   5%|▌         | 1/20 [08:01<2:32:32, 481.74s/it, Best AUC=0.9101]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Evaluated params: [0.001, 91, 1, 0.1, 32] -> Val AUC: 0.9011\n",
            "Evaluated params: [0.0001, 61, 3, 0.1, 128] -> Val AUC: 0.8767\n",
            "Evaluated params: [0.001, 35, 3, 0.5, 32] -> Val AUC: 0.8926\n",
            "Evaluated params: [0.01, 121, 1, 0.4, 64] -> Val AUC: 0.8979\n",
            "Evaluated params: [0.01, 42, 1, 0.4, 128] -> Val AUC: 0.8801\n",
            "Evaluated params: [0.01, 116, 3, 0.1, 32] -> Val AUC: 0.8833\n",
            "Evaluated params: [0.01, 42, 1, 0.3, 128] -> Val AUC: 0.8847\n",
            "Evaluated params: [0.001, 79, 3, 0.3, 32] -> Val AUC: 0.8926\n",
            "Evaluated params: [0.01, 47, 1, 0.4, 32] -> Val AUC: 0.9094\n",
            "Evaluated params: [0.01, 99, 1, 0.3, 128] -> Val AUC: 0.8838\n",
            "Evaluated params: [0.0001, 124, 2, 0.4, 32] -> Val AUC: 0.8940\n",
            "Evaluated params: [0.0001, 42, 1, 0.3, 32] -> Val AUC: 0.8984\n",
            "Evaluated params: [0.01, 116, 3, 0.4, 32] -> Val AUC: 0.8930\n",
            "Evaluated params: [0.01, 116, 3, 0.4, 32] -> Val AUC: 0.8877\n",
            "Evaluated params: [0.01, 47, 2, 0.3, 128] -> Val AUC: 0.8684\n",
            "Evaluated params: [0.01, 42, 1, 0.4, 32] -> Val AUC: 0.9048\n",
            "Evaluated params: [0.0001, 42, 3, 0.3, 32] -> Val AUC: 0.8994\n",
            "Evaluated params: [0.0001, 42, 1, 0.3, 128] -> Val AUC: 0.8777\n",
            "Evaluated params: [0.0001, 128, 1, 0.3, 32] -> Val AUC: 0.9028\n",
            "Evaluated params: [0.0001, 42, 1, 0.3, 32] -> Val AUC: 0.8996\n",
            "Evaluated params: [0.01, 42, 3, 0.3, 32] -> Val AUC: 0.8916\n",
            "Evaluated params: [0.01, 42, 1, 0.4, 32] -> Val AUC: 0.8952\n",
            "Evaluated params: [0.0001, 128, 1, 0.3, 32] -> Val AUC: 0.9021\n",
            "Evaluated params: [0.0001, 42, 1, 0.3, 32] -> Val AUC: 0.9053\n",
            "Evaluated params: [0.0001, 42, 3, 0.3, 32] -> Val AUC: 0.8952\n",
            "Evaluated params: [0.0001, 42, 1, 0.3, 32] -> Val AUC: 0.9038\n",
            "Evaluated params: [0.01, 116, 3, 0.4, 32] -> Val AUC: 0.8950\n",
            "Evaluated params: [0.01, 42, 3, 0.3, 32] -> Val AUC: 0.8955\n",
            "Evaluated params: [0.01, 116, 3, 0.4, 32] -> Val AUC: 0.9092\n",
            "Evaluated params: [0.01, 47, 1, 0.4, 32] -> Val AUC: 0.8987\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "MBO Optimization:  10%|█         | 2/20 [15:07<2:14:37, 448.77s/it, Best AUC=0.9094]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Evaluated params: [0.01, 121, 1, 0.4, 64] -> Val AUC: 0.8906\n",
            "Evaluated params: [0.0001, 63, 3, 0.4, 128] -> Val AUC: 0.8806\n",
            "Evaluated params: [0.001, 125, 2, 0.5, 32] -> Val AUC: 0.8994\n",
            "Evaluated params: [0.001, 124, 3, 0.3, 128] -> Val AUC: 0.8816\n",
            "Evaluated params: [0.0001, 71, 3, 0.2, 32] -> Val AUC: 0.9004\n",
            "Evaluated params: [0.001, 57, 2, 0.1, 64] -> Val AUC: 0.8872\n",
            "Evaluated params: [0.001, 91, 2, 0.1, 128] -> Val AUC: 0.8784\n",
            "Evaluated params: [0.01, 87, 3, 0.5, 32] -> Val AUC: 0.8996\n",
            "Evaluated params: [0.01, 80, 1, 0.4, 32] -> Val AUC: 0.9001\n",
            "Evaluated params: [0.001, 125, 3, 0.2, 128] -> Val AUC: 0.8759\n",
            "Evaluated params: [0.001, 43, 2, 0.4, 32] -> Val AUC: 0.9006\n",
            "Evaluated params: [0.001, 71, 2, 0.5, 32] -> Val AUC: 0.9004\n",
            "Evaluated params: [0.001, 87, 3, 0.4, 128] -> Val AUC: 0.8794\n",
            "Evaluated params: [0.01, 91, 3, 0.3, 128] -> Val AUC: 0.8703\n",
            "Evaluated params: [0.001, 80, 3, 0.4, 64] -> Val AUC: 0.8852\n",
            "Evaluated params: [0.01, 63, 3, 0.1, 32] -> Val AUC: 0.8899\n",
            "Evaluated params: [0.0001, 71, 2, 0.5, 32] -> Val AUC: 0.9038\n",
            "Evaluated params: [0.001, 71, 2, 0.5, 32] -> Val AUC: 0.8987\n",
            "Evaluated params: [0.001, 32, 1, 0.5, 32] -> Val AUC: 0.9031\n",
            "Evaluated params: [0.01, 57, 3, 0.5, 32] -> Val AUC: 0.9053\n",
            "Evaluated params: [0.001, 71, 2, 0.5, 32] -> Val AUC: 0.8918\n",
            "Evaluated params: [0.01, 57, 3, 0.5, 32] -> Val AUC: 0.8967\n",
            "Evaluated params: [0.0001, 71, 2, 0.5, 32] -> Val AUC: 0.9001\n",
            "Evaluated params: [0.001, 32, 1, 0.5, 32] -> Val AUC: 0.8987\n",
            "Evaluated params: [0.001, 71, 2, 0.5, 32] -> Val AUC: 0.8830\n",
            "Evaluated params: [0.001, 71, 2, 0.5, 32] -> Val AUC: 0.8911\n",
            "Evaluated params: [0.001, 71, 2, 0.5, 32] -> Val AUC: 0.8999\n",
            "Evaluated params: [0.01, 63, 3, 0.1, 32] -> Val AUC: 0.8945\n",
            "Evaluated params: [0.001, 80, 3, 0.4, 64] -> Val AUC: 0.8857\n",
            "Evaluated params: [0.001, 43, 2, 0.4, 32] -> Val AUC: 0.8906\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "MBO Optimization:  15%|█▌        | 3/20 [21:33<1:59:05, 420.35s/it, Best AUC=0.9006]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Evaluated params: [0.0001, 71, 3, 0.2, 32] -> Val AUC: 0.8813\n",
            "Evaluated params: [0.001, 32, 1, 0.4, 64] -> Val AUC: 0.8940\n",
            "Evaluated params: [0.001, 86, 3, 0.5, 128] -> Val AUC: 0.8733\n",
            "Evaluated params: [0.01, 53, 1, 0.2, 128] -> Val AUC: 0.8742\n",
            "Evaluated params: [0.0001, 79, 2, 0.2, 64] -> Val AUC: 0.8918\n",
            "Evaluated params: [0.01, 67, 2, 0.3, 128] -> Val AUC: 0.8830\n",
            "Evaluated params: [0.001, 80, 3, 0.4, 64] -> Val AUC: 0.8933\n",
            "Evaluated params: [0.001, 99, 1, 0.2, 64] -> Val AUC: 0.8933\n",
            "Evaluated params: [0.001, 32, 1, 0.1, 64] -> Val AUC: 0.8930\n",
            "Evaluated params: [0.0001, 117, 1, 0.4, 128] -> Val AUC: 0.8855\n",
            "Evaluated params: [0.0001, 36, 2, 0.4, 32] -> Val AUC: 0.8833\n",
            "Evaluated params: [0.0001, 32, 2, 0.4, 64] -> Val AUC: 0.8996\n",
            "Evaluated params: [0.01, 32, 1, 0.3, 32] -> Val AUC: 0.8974\n",
            "Evaluated params: [0.01, 80, 1, 0.1, 128] -> Val AUC: 0.8823\n",
            "Evaluated params: [0.0001, 32, 1, 0.3, 128] -> Val AUC: 0.8737\n",
            "Evaluated params: [0.001, 32, 2, 0.4, 128] -> Val AUC: 0.8757\n",
            "Evaluated params: [0.0001, 32, 3, 0.4, 32] -> Val AUC: 0.8957\n",
            "Evaluated params: [0.0001, 32, 1, 0.4, 128] -> Val AUC: 0.8779\n",
            "Evaluated params: [0.0001, 128, 1, 0.5, 32] -> Val AUC: 0.9033\n",
            "Evaluated params: [0.0001, 32, 2, 0.1, 64] -> Val AUC: 0.8972\n",
            "Evaluated params: [0.0001, 32, 1, 0.1, 64] -> Val AUC: 0.8957\n",
            "Evaluated params: [0.0001, 128, 1, 0.5, 32] -> Val AUC: 0.9043\n",
            "Evaluated params: [0.0001, 32, 2, 0.4, 64] -> Val AUC: 0.8911\n",
            "Evaluated params: [0.01, 32, 1, 0.3, 32] -> Val AUC: 0.9043\n",
            "Evaluated params: [0.0001, 32, 2, 0.1, 64] -> Val AUC: 0.8979\n",
            "Evaluated params: [0.0001, 32, 3, 0.4, 32] -> Val AUC: 0.8935\n",
            "Evaluated params: [0.0001, 32, 1, 0.1, 64] -> Val AUC: 0.8940\n",
            "Evaluated params: [0.01, 80, 1, 0.1, 128] -> Val AUC: 0.8701\n",
            "Evaluated params: [0.0001, 32, 1, 0.4, 128] -> Val AUC: 0.8811\n",
            "Evaluated params: [0.001, 32, 1, 0.4, 64] -> Val AUC: 0.8906\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "MBO Optimization:  20%|██        | 4/20 [30:09<2:02:04, 457.77s/it, Best AUC=0.9043]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Evaluated params: [0.001, 99, 1, 0.2, 64] -> Val AUC: 0.8945\n",
            "Evaluated params: [0.001, 94, 2, 0.5, 64] -> Val AUC: 0.8877\n",
            "Evaluated params: [0.001, 126, 2, 0.4, 32] -> Val AUC: 0.8904\n",
            "Evaluated params: [0.001, 48, 2, 0.5, 128] -> Val AUC: 0.8791\n",
            "Evaluated params: [0.0001, 78, 1, 0.3, 128] -> Val AUC: 0.8828\n",
            "Evaluated params: [0.01, 50, 3, 0.4, 128] -> Val AUC: 0.8818\n",
            "Evaluated params: [0.0001, 66, 3, 0.4, 64] -> Val AUC: 0.8904\n",
            "Evaluated params: [0.001, 117, 1, 0.4, 32] -> Val AUC: 0.9016\n",
            "Evaluated params: [0.0001, 115, 2, 0.2, 128] -> Val AUC: 0.8862\n",
            "Evaluated params: [0.0001, 35, 1, 0.5, 64] -> Val AUC: 0.8945\n",
            "Evaluated params: [0.0001, 107, 2, 0.1, 64] -> Val AUC: 0.8904\n",
            "Evaluated params: [0.001, 117, 3, 0.4, 64] -> Val AUC: 0.8806\n",
            "Evaluated params: [0.0001, 117, 3, 0.4, 128] -> Val AUC: 0.8789\n",
            "Evaluated params: [0.01, 115, 2, 0.5, 32] -> Val AUC: 0.8923\n",
            "Evaluated params: [0.0001, 115, 1, 0.5, 64] -> Val AUC: 0.8974\n",
            "Evaluated params: [0.001, 115, 2, 0.4, 64] -> Val AUC: 0.8908\n",
            "Evaluated params: [0.01, 128, 3, 0.5, 32] -> Val AUC: 0.9175\n",
            "Evaluated params: [0.001, 117, 2, 0.1, 32] -> Val AUC: 0.8911\n",
            "Evaluated params: [0.01, 117, 1, 0.5, 128] -> Val AUC: 0.8806\n",
            "Evaluated params: [0.0001, 32, 3, 0.5, 128] -> Val AUC: 0.8664\n",
            "Evaluated params: [0.01, 117, 3, 0.4, 64] -> Val AUC: 0.8947\n",
            "Evaluated params: [0.01, 128, 3, 0.5, 32] -> Val AUC: 0.9021\n",
            "Evaluated params: [0.0001, 115, 1, 0.5, 64] -> Val AUC: 0.8933\n",
            "Evaluated params: [0.01, 117, 3, 0.4, 64] -> Val AUC: 0.8955\n",
            "Evaluated params: [0.01, 115, 2, 0.5, 32] -> Val AUC: 0.9087\n",
            "Evaluated params: [0.001, 117, 2, 0.1, 32] -> Val AUC: 0.8918\n",
            "Evaluated params: [0.001, 115, 2, 0.4, 64] -> Val AUC: 0.8855\n",
            "Evaluated params: [0.01, 117, 1, 0.5, 128] -> Val AUC: 0.8904\n",
            "Evaluated params: [0.001, 117, 3, 0.4, 64] -> Val AUC: 0.8901\n",
            "Evaluated params: [0.001, 117, 1, 0.4, 32] -> Val AUC: 0.9018\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "MBO Optimization:  25%|██▌       | 5/20 [38:00<1:55:40, 462.69s/it, Best AUC=0.9087]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Evaluated params: [0.0001, 35, 1, 0.5, 64] -> Val AUC: 0.8930\n",
            "Evaluated params: [0.01, 118, 1, 0.5, 64] -> Val AUC: 0.8908\n",
            "Evaluated params: [0.01, 50, 2, 0.2, 32] -> Val AUC: 0.9033\n",
            "Evaluated params: [0.001, 50, 1, 0.4, 32] -> Val AUC: 0.9006\n",
            "Evaluated params: [0.001, 85, 1, 0.5, 32] -> Val AUC: 0.8982\n",
            "Evaluated params: [0.0001, 33, 1, 0.1, 32] -> Val AUC: 0.8979\n",
            "Evaluated params: [0.001, 49, 3, 0.2, 32] -> Val AUC: 0.8945\n",
            "Evaluated params: [0.01, 37, 1, 0.1, 128] -> Val AUC: 0.8791\n",
            "Evaluated params: [0.01, 101, 1, 0.3, 32] -> Val AUC: 0.9053\n",
            "Evaluated params: [0.0001, 55, 2, 0.5, 64] -> Val AUC: 0.8901\n",
            "Evaluated params: [0.0001, 40, 2, 0.5, 64] -> Val AUC: 0.8891\n",
            "Evaluated params: [0.001, 40, 1, 0.4, 32] -> Val AUC: 0.9033\n",
            "Evaluated params: [0.001, 50, 3, 0.4, 64] -> Val AUC: 0.8860\n",
            "Evaluated params: [0.01, 85, 2, 0.5, 32] -> Val AUC: 0.8842\n",
            "Evaluated params: [0.001, 49, 3, 0.5, 64] -> Val AUC: 0.8808\n",
            "Evaluated params: [0.0001, 55, 2, 0.5, 64] -> Val AUC: 0.8952\n",
            "Evaluated params: [0.001, 40, 1, 0.4, 32] -> Val AUC: 0.8987\n",
            "Evaluated params: [0.001, 40, 3, 0.4, 32] -> Val AUC: 0.8884\n",
            "Evaluated params: [0.001, 40, 1, 0.4, 128] -> Val AUC: 0.8816\n",
            "Evaluated params: [0.001, 40, 1, 0.4, 32] -> Val AUC: 0.8926\n",
            "Evaluated params: [0.001, 32, 1, 0.5, 32] -> Val AUC: 0.9053\n",
            "Evaluated params: [0.001, 32, 1, 0.5, 32] -> Val AUC: 0.9065\n",
            "Evaluated params: [0.001, 40, 1, 0.4, 32] -> Val AUC: 0.9031\n",
            "Evaluated params: [0.001, 40, 1, 0.4, 32] -> Val AUC: 0.9011\n",
            "Evaluated params: [0.0001, 55, 2, 0.5, 64] -> Val AUC: 0.8911\n",
            "Evaluated params: [0.001, 40, 1, 0.4, 32] -> Val AUC: 0.8938\n",
            "Evaluated params: [0.001, 40, 3, 0.4, 32] -> Val AUC: 0.8901\n",
            "Evaluated params: [0.001, 50, 3, 0.4, 64] -> Val AUC: 0.8882\n",
            "Evaluated params: [0.01, 85, 2, 0.5, 32] -> Val AUC: 0.9065\n",
            "Evaluated params: [0.01, 101, 1, 0.3, 32] -> Val AUC: 0.9038\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "MBO Optimization:  30%|███       | 6/20 [45:05<1:44:58, 449.90s/it, Best AUC=0.9065]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Evaluated params: [0.01, 50, 2, 0.2, 32] -> Val AUC: 0.8994\n",
            "Evaluated params: [0.001, 32, 3, 0.5, 128] -> Val AUC: 0.8801\n",
            "Evaluated params: [0.0001, 116, 1, 0.2, 32] -> Val AUC: 0.9038\n",
            "Evaluated params: [0.001, 101, 1, 0.2, 32] -> Val AUC: 0.9038\n",
            "Evaluated params: [0.001, 57, 1, 0.5, 64] -> Val AUC: 0.8857\n",
            "Evaluated params: [0.0001, 51, 2, 0.3, 64] -> Val AUC: 0.8935\n",
            "Evaluated params: [0.001, 54, 3, 0.5, 64] -> Val AUC: 0.8796\n",
            "Evaluated params: [0.001, 110, 1, 0.3, 128] -> Val AUC: 0.8847\n",
            "Evaluated params: [0.0001, 43, 1, 0.2, 32] -> Val AUC: 0.8962\n",
            "Evaluated params: [0.0001, 46, 1, 0.5, 64] -> Val AUC: 0.8930\n",
            "Evaluated params: [0.001, 52, 1, 0.4, 32] -> Val AUC: 0.8945\n",
            "Evaluated params: [0.0001, 57, 1, 0.5, 128] -> Val AUC: 0.8701\n",
            "Evaluated params: [0.001, 57, 1, 0.4, 128] -> Val AUC: 0.8906\n",
            "Evaluated params: [0.001, 110, 1, 0.5, 64] -> Val AUC: 0.8933\n",
            "Evaluated params: [0.001, 57, 1, 0.5, 128] -> Val AUC: 0.8867\n",
            "Evaluated params: [0.001, 32, 1, 0.2, 32] -> Val AUC: 0.9023\n",
            "Evaluated params: [0.0001, 32, 1, 0.5, 128] -> Val AUC: 0.8764\n",
            "Evaluated params: [0.0001, 32, 1, 0.5, 128] -> Val AUC: 0.8779\n",
            "Evaluated params: [0.0001, 32, 3, 0.5, 32] -> Val AUC: 0.9028\n",
            "Evaluated params: [0.0001, 57, 1, 0.5, 32] -> Val AUC: 0.9013\n",
            "Evaluated params: [0.0001, 57, 3, 0.1, 128] -> Val AUC: 0.8847\n",
            "Evaluated params: [0.0001, 32, 3, 0.5, 32] -> Val AUC: 0.8935\n",
            "Evaluated params: [0.001, 32, 1, 0.2, 32] -> Val AUC: 0.8955\n",
            "Evaluated params: [0.0001, 57, 1, 0.5, 32] -> Val AUC: 0.9035\n",
            "Evaluated params: [0.001, 110, 1, 0.5, 64] -> Val AUC: 0.8911\n",
            "Evaluated params: [0.001, 57, 1, 0.4, 128] -> Val AUC: 0.8869\n",
            "Evaluated params: [0.001, 57, 1, 0.5, 128] -> Val AUC: 0.8904\n",
            "Evaluated params: [0.0001, 57, 3, 0.1, 128] -> Val AUC: 0.8838\n",
            "Evaluated params: [0.0001, 32, 1, 0.5, 128] -> Val AUC: 0.8774\n",
            "Evaluated params: [0.0001, 116, 1, 0.2, 32] -> Val AUC: 0.9045\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "MBO Optimization:  35%|███▌      | 7/20 [54:23<1:45:08, 485.26s/it, Best AUC=0.9045]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Evaluated params: [0.001, 101, 1, 0.2, 32] -> Val AUC: 0.8969\n",
            "Evaluated params: [0.01, 62, 1, 0.4, 64] -> Val AUC: 0.8918\n",
            "Evaluated params: [0.01, 112, 1, 0.2, 128] -> Val AUC: 0.8801\n",
            "Evaluated params: [0.0001, 119, 2, 0.2, 32] -> Val AUC: 0.8967\n",
            "Evaluated params: [0.001, 58, 1, 0.2, 32] -> Val AUC: 0.9028\n",
            "Evaluated params: [0.01, 40, 2, 0.4, 128] -> Val AUC: 0.8811\n",
            "Evaluated params: [0.01, 36, 1, 0.4, 32] -> Val AUC: 0.9104\n",
            "Evaluated params: [0.01, 67, 2, 0.5, 64] -> Val AUC: 0.8906\n",
            "Evaluated params: [0.0001, 72, 1, 0.5, 128] -> Val AUC: 0.8830\n",
            "Evaluated params: [0.001, 95, 2, 0.5, 128] -> Val AUC: 0.8784\n",
            "Evaluated params: [0.0001, 52, 1, 0.4, 64] -> Val AUC: 0.8918\n",
            "Evaluated params: [0.01, 36, 2, 0.5, 128] -> Val AUC: 0.8745\n",
            "Evaluated params: [0.0001, 72, 1, 0.2, 128] -> Val AUC: 0.8862\n",
            "Evaluated params: [0.01, 62, 1, 0.4, 128] -> Val AUC: 0.8813\n",
            "Evaluated params: [0.01, 62, 1, 0.5, 64] -> Val AUC: 0.8874\n",
            "Evaluated params: [0.01, 58, 1, 0.5, 128] -> Val AUC: 0.8908\n",
            "Evaluated params: [0.0001, 36, 2, 0.5, 64] -> Val AUC: 0.8918\n",
            "Evaluated params: [0.01, 36, 2, 0.5, 128] -> Val AUC: 0.8713\n",
            "Evaluated params: [0.01, 36, 3, 0.5, 128] -> Val AUC: 0.8789\n",
            "Evaluated params: [0.01, 36, 2, 0.1, 128] -> Val AUC: 0.8767\n",
            "Evaluated params: [0.01, 36, 3, 0.5, 64] -> Val AUC: 0.8896\n",
            "Evaluated params: [0.0001, 36, 2, 0.5, 64] -> Val AUC: 0.8926\n",
            "Evaluated params: [0.01, 58, 1, 0.5, 128] -> Val AUC: 0.8767\n",
            "Evaluated params: [0.01, 36, 3, 0.5, 64] -> Val AUC: 0.8752\n",
            "Evaluated params: [0.01, 62, 1, 0.5, 64] -> Val AUC: 0.9006\n",
            "Evaluated params: [0.0001, 72, 1, 0.2, 128] -> Val AUC: 0.8852\n",
            "Evaluated params: [0.01, 62, 1, 0.4, 128] -> Val AUC: 0.8779\n",
            "Evaluated params: [0.01, 36, 3, 0.5, 128] -> Val AUC: 0.8855\n",
            "Evaluated params: [0.01, 36, 2, 0.1, 128] -> Val AUC: 0.8755\n",
            "Evaluated params: [0.01, 36, 1, 0.4, 32] -> Val AUC: 0.9001\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "MBO Optimization:  40%|████      | 8/20 [1:02:10<1:35:52, 479.37s/it, Best AUC=0.9104]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Evaluated params: [0.001, 58, 1, 0.2, 32] -> Val AUC: 0.9062\n",
            "Evaluated params: [0.01, 33, 1, 0.5, 32] -> Val AUC: 0.9011\n",
            "Evaluated params: [0.0001, 121, 3, 0.3, 64] -> Val AUC: 0.8894\n",
            "Evaluated params: [0.001, 121, 2, 0.2, 32] -> Val AUC: 0.8960\n",
            "Evaluated params: [0.001, 51, 1, 0.4, 32] -> Val AUC: 0.8977\n",
            "Evaluated params: [0.0001, 83, 1, 0.4, 32] -> Val AUC: 0.8999\n",
            "Evaluated params: [0.001, 114, 1, 0.3, 64] -> Val AUC: 0.8938\n",
            "Evaluated params: [0.01, 35, 1, 0.5, 32] -> Val AUC: 0.8977\n",
            "Evaluated params: [0.0001, 54, 2, 0.1, 128] -> Val AUC: 0.8823\n",
            "Evaluated params: [0.001, 85, 1, 0.4, 128] -> Val AUC: 0.8916\n",
            "Evaluated params: [0.001, 86, 1, 0.3, 64] -> Val AUC: 0.8913\n",
            "Evaluated params: [0.01, 51, 1, 0.4, 32] -> Val AUC: 0.9055\n",
            "Evaluated params: [0.001, 114, 1, 0.4, 32] -> Val AUC: 0.9055\n",
            "Evaluated params: [0.0001, 83, 1, 0.4, 64] -> Val AUC: 0.8901\n",
            "Evaluated params: [0.01, 85, 1, 0.3, 64] -> Val AUC: 0.8945\n",
            "Evaluated params: [0.001, 51, 1, 0.3, 128] -> Val AUC: 0.8882\n",
            "Evaluated params: [0.01, 128, 3, 0.3, 128] -> Val AUC: 0.8755\n",
            "Evaluated params: [0.01, 86, 1, 0.3, 128] -> Val AUC: 0.8779\n",
            "Evaluated params: [0.01, 51, 1, 0.5, 32] -> Val AUC: 0.9084\n",
            "Evaluated params: [0.01, 51, 1, 0.4, 32] -> Val AUC: 0.9016\n",
            "Evaluated params: [0.01, 51, 1, 0.5, 128] -> Val AUC: 0.8745\n",
            "Evaluated params: [0.01, 51, 1, 0.5, 32] -> Val AUC: 0.9094\n",
            "Evaluated params: [0.01, 51, 1, 0.4, 32] -> Val AUC: 0.9033\n",
            "Evaluated params: [0.001, 114, 1, 0.4, 32] -> Val AUC: 0.8908\n",
            "Evaluated params: [0.01, 51, 1, 0.4, 32] -> Val AUC: 0.9040\n",
            "Evaluated params: [0.01, 85, 1, 0.3, 64] -> Val AUC: 0.8913\n",
            "Evaluated params: [0.0001, 83, 1, 0.4, 64] -> Val AUC: 0.8911\n",
            "Evaluated params: [0.001, 51, 1, 0.3, 128] -> Val AUC: 0.8879\n",
            "Evaluated params: [0.01, 86, 1, 0.3, 128] -> Val AUC: 0.8796\n",
            "Evaluated params: [0.01, 33, 1, 0.5, 32] -> Val AUC: 0.8855\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "MBO Optimization:  45%|████▌     | 9/20 [1:10:10<1:27:55, 479.63s/it, Best AUC=0.9094]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Evaluated params: [0.0001, 83, 1, 0.4, 32] -> Val AUC: 0.9013\n",
            "Evaluated params: [0.01, 99, 3, 0.1, 128] -> Val AUC: 0.8742\n",
            "Evaluated params: [0.001, 108, 3, 0.4, 64] -> Val AUC: 0.8784\n",
            "Evaluated params: [0.001, 99, 1, 0.1, 128] -> Val AUC: 0.8842\n",
            "Evaluated params: [0.01, 52, 3, 0.4, 128] -> Val AUC: 0.8789\n",
            "Evaluated params: [0.0001, 94, 1, 0.4, 128] -> Val AUC: 0.8869\n",
            "Evaluated params: [0.01, 50, 3, 0.4, 64] -> Val AUC: 0.9021\n",
            "Evaluated params: [0.01, 99, 2, 0.4, 128] -> Val AUC: 0.8733\n",
            "Evaluated params: [0.001, 87, 1, 0.5, 128] -> Val AUC: 0.8913\n",
            "Evaluated params: [0.01, 67, 1, 0.3, 128] -> Val AUC: 0.8823\n",
            "Evaluated params: [0.01, 84, 1, 0.3, 32] -> Val AUC: 0.8994\n",
            "Evaluated params: [0.01, 94, 1, 0.3, 64] -> Val AUC: 0.8891\n",
            "Evaluated params: [0.01, 108, 1, 0.3, 64] -> Val AUC: 0.8923\n",
            "Evaluated params: [0.01, 84, 3, 0.3, 128] -> Val AUC: 0.8706\n",
            "Evaluated params: [0.01, 52, 3, 0.3, 64] -> Val AUC: 0.8821\n",
            "Evaluated params: [0.001, 99, 3, 0.1, 64] -> Val AUC: 0.8821\n",
            "Evaluated params: [0.01, 94, 1, 0.4, 64] -> Val AUC: 0.8952\n",
            "Evaluated params: [0.001, 99, 1, 0.3, 128] -> Val AUC: 0.8825\n",
            "Evaluated params: [0.001, 94, 1, 0.3, 64] -> Val AUC: 0.8950\n",
            "Evaluated params: [0.0001, 128, 1, 0.3, 32] -> Val AUC: 0.9018\n",
            "Evaluated params: [0.01, 94, 2, 0.3, 32] -> Val AUC: 0.9101\n",
            "Evaluated params: [0.01, 94, 2, 0.3, 32] -> Val AUC: 0.9040\n",
            "Evaluated params: [0.0001, 128, 1, 0.3, 32] -> Val AUC: 0.8952\n",
            "Evaluated params: [0.01, 94, 1, 0.4, 64] -> Val AUC: 0.8965\n",
            "Evaluated params: [0.001, 94, 1, 0.3, 64] -> Val AUC: 0.8982\n",
            "Evaluated params: [0.01, 108, 1, 0.3, 64] -> Val AUC: 0.8991\n",
            "Evaluated params: [0.01, 94, 1, 0.3, 64] -> Val AUC: 0.8928\n",
            "Evaluated params: [0.001, 99, 1, 0.3, 128] -> Val AUC: 0.8842\n",
            "Evaluated params: [0.01, 52, 3, 0.3, 64] -> Val AUC: 0.8879\n",
            "Evaluated params: [0.01, 50, 3, 0.4, 64] -> Val AUC: 0.8979\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "MBO Optimization:  50%|█████     | 10/20 [1:18:17<1:20:20, 482.01s/it, Best AUC=0.9082]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Evaluated params: [0.01, 84, 1, 0.3, 32] -> Val AUC: 0.9082\n",
            "Evaluated params: [0.0001, 93, 2, 0.4, 32] -> Val AUC: 0.8940\n",
            "Evaluated params: [0.01, 94, 1, 0.1, 128] -> Val AUC: 0.8825\n",
            "Evaluated params: [0.01, 121, 1, 0.2, 64] -> Val AUC: 0.8952\n",
            "Evaluated params: [0.0001, 127, 3, 0.3, 128] -> Val AUC: 0.8840\n",
            "Evaluated params: [0.01, 82, 1, 0.2, 128] -> Val AUC: 0.8803\n",
            "Evaluated params: [0.001, 52, 1, 0.5, 64] -> Val AUC: 0.8984\n",
            "Evaluated params: [0.001, 122, 3, 0.4, 128] -> Val AUC: 0.8742\n",
            "Evaluated params: [0.0001, 37, 1, 0.5, 64] -> Val AUC: 0.8967\n",
            "Evaluated params: [0.01, 61, 1, 0.2, 64] -> Val AUC: 0.8928\n",
            "Evaluated params: [0.001, 52, 2, 0.1, 128] -> Val AUC: 0.8825\n",
            "Evaluated params: [0.001, 52, 1, 0.2, 128] -> Val AUC: 0.8891\n",
            "Evaluated params: [0.001, 127, 1, 0.1, 128] -> Val AUC: 0.8926\n",
            "Evaluated params: [0.01, 37, 2, 0.2, 128] -> Val AUC: 0.8742\n",
            "Evaluated params: [0.0001, 93, 2, 0.1, 128] -> Val AUC: 0.8855\n",
            "Evaluated params: [0.001, 94, 1, 0.1, 32] -> Val AUC: 0.8996\n",
            "Evaluated params: [0.001, 52, 3, 0.2, 64] -> Val AUC: 0.8830\n",
            "Evaluated params: [0.01, 128, 1, 0.5, 128] -> Val AUC: 0.8801\n",
            "Evaluated params: [0.001, 52, 1, 0.2, 128] -> Val AUC: 0.8840\n",
            "Evaluated params: [0.001, 127, 1, 0.2, 128] -> Val AUC: 0.8869\n",
            "Evaluated params: [0.0001, 52, 1, 0.3, 128] -> Val AUC: 0.8847\n",
            "Evaluated params: [0.001, 94, 1, 0.1, 32] -> Val AUC: 0.9035\n",
            "Evaluated params: [0.001, 127, 1, 0.1, 128] -> Val AUC: 0.8901\n",
            "Evaluated params: [0.001, 52, 1, 0.2, 128] -> Val AUC: 0.8940\n",
            "Evaluated params: [0.001, 127, 1, 0.2, 128] -> Val AUC: 0.8921\n",
            "Evaluated params: [0.0001, 93, 2, 0.1, 128] -> Val AUC: 0.8811\n",
            "Evaluated params: [0.0001, 52, 1, 0.3, 128] -> Val AUC: 0.8796\n",
            "Evaluated params: [0.001, 52, 1, 0.2, 128] -> Val AUC: 0.8830\n",
            "Evaluated params: [0.001, 52, 3, 0.2, 64] -> Val AUC: 0.8901\n",
            "Evaluated params: [0.001, 52, 1, 0.5, 64] -> Val AUC: 0.8918\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "MBO Optimization:  55%|█████▌    | 11/20 [1:27:39<1:15:56, 506.31s/it, Best AUC=0.9035]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Evaluated params: [0.0001, 37, 1, 0.5, 64] -> Val AUC: 0.8945\n",
            "Evaluated params: [0.001, 80, 3, 0.3, 128] -> Val AUC: 0.8750\n",
            "Evaluated params: [0.01, 66, 2, 0.4, 128] -> Val AUC: 0.8735\n",
            "Evaluated params: [0.01, 34, 3, 0.5, 128] -> Val AUC: 0.8750\n",
            "Evaluated params: [0.001, 44, 3, 0.2, 128] -> Val AUC: 0.8784\n",
            "Evaluated params: [0.001, 33, 3, 0.1, 64] -> Val AUC: 0.8796\n",
            "Evaluated params: [0.001, 36, 3, 0.3, 128] -> Val AUC: 0.8789\n",
            "Evaluated params: [0.001, 105, 2, 0.2, 128] -> Val AUC: 0.8745\n",
            "Evaluated params: [0.0001, 127, 3, 0.1, 64] -> Val AUC: 0.8852\n",
            "Evaluated params: [0.0001, 80, 1, 0.1, 32] -> Val AUC: 0.9043\n",
            "Evaluated params: [0.0001, 35, 1, 0.2, 32] -> Val AUC: 0.9089\n",
            "Evaluated params: [0.001, 44, 3, 0.3, 64] -> Val AUC: 0.8947\n",
            "Evaluated params: [0.0001, 105, 3, 0.1, 128] -> Val AUC: 0.8840\n",
            "Evaluated params: [0.001, 105, 3, 0.2, 64] -> Val AUC: 0.8894\n",
            "Evaluated params: [0.01, 80, 3, 0.5, 128] -> Val AUC: 0.8967\n",
            "Evaluated params: [0.0001, 127, 3, 0.2, 128] -> Val AUC: 0.8842\n",
            "Evaluated params: [0.01, 44, 3, 0.3, 64] -> Val AUC: 0.8911\n",
            "Evaluated params: [0.01, 44, 1, 0.3, 32] -> Val AUC: 0.9040\n",
            "Evaluated params: [0.001, 44, 3, 0.5, 64] -> Val AUC: 0.8825\n",
            "Evaluated params: [0.001, 128, 3, 0.3, 64] -> Val AUC: 0.8967\n",
            "Evaluated params: [0.0001, 44, 3, 0.1, 128] -> Val AUC: 0.8784\n",
            "Evaluated params: [0.01, 44, 1, 0.3, 32] -> Val AUC: 0.9035\n",
            "Evaluated params: [0.01, 80, 3, 0.5, 128] -> Val AUC: 0.8750\n",
            "Evaluated params: [0.001, 128, 3, 0.3, 64] -> Val AUC: 0.8896\n",
            "Evaluated params: [0.001, 44, 3, 0.3, 64] -> Val AUC: 0.8943\n",
            "Evaluated params: [0.01, 44, 3, 0.3, 64] -> Val AUC: 0.8733\n",
            "Evaluated params: [0.001, 105, 3, 0.2, 64] -> Val AUC: 0.8852\n",
            "Evaluated params: [0.0001, 127, 3, 0.2, 128] -> Val AUC: 0.8833\n",
            "Evaluated params: [0.0001, 105, 3, 0.1, 128] -> Val AUC: 0.8840\n",
            "Evaluated params: [0.0001, 35, 1, 0.2, 32] -> Val AUC: 0.9062\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "MBO Optimization:  60%|██████    | 12/20 [1:38:06<1:12:25, 543.17s/it, Best AUC=0.9089]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Evaluated params: [0.0001, 80, 1, 0.1, 32] -> Val AUC: 0.9023\n",
            "Evaluated params: [0.0001, 100, 2, 0.2, 32] -> Val AUC: 0.8933\n",
            "Evaluated params: [0.01, 81, 3, 0.2, 128] -> Val AUC: 0.8691\n",
            "Evaluated params: [0.01, 114, 3, 0.4, 128] -> Val AUC: 0.8716\n",
            "Evaluated params: [0.001, 122, 1, 0.5, 64] -> Val AUC: 0.8950\n",
            "Evaluated params: [0.01, 32, 1, 0.4, 64] -> Val AUC: 0.8874\n",
            "Evaluated params: [0.001, 36, 1, 0.3, 64] -> Val AUC: 0.8911\n",
            "Evaluated params: [0.001, 86, 3, 0.4, 128] -> Val AUC: 0.8764\n",
            "Evaluated params: [0.0001, 45, 1, 0.1, 64] -> Val AUC: 0.8894\n",
            "Evaluated params: [0.001, 91, 3, 0.2, 128] -> Val AUC: 0.8725\n",
            "Evaluated params: [0.01, 81, 2, 0.1, 64] -> Val AUC: 0.8957\n",
            "Evaluated params: [0.01, 91, 3, 0.4, 128] -> Val AUC: 0.8965\n",
            "Evaluated params: [0.01, 114, 1, 0.4, 64] -> Val AUC: 0.8904\n",
            "Evaluated params: [0.01, 32, 3, 0.4, 32] -> Val AUC: 0.8894\n",
            "Evaluated params: [0.01, 86, 2, 0.1, 128] -> Val AUC: 0.8745\n",
            "Evaluated params: [0.01, 86, 1, 0.2, 64] -> Val AUC: 0.8889\n",
            "Evaluated params: [0.01, 32, 3, 0.4, 128] -> Val AUC: 0.8691\n",
            "Evaluated params: [0.01, 91, 3, 0.4, 128] -> Val AUC: 0.8947\n",
            "Evaluated params: [0.01, 91, 3, 0.3, 64] -> Val AUC: 0.8940\n",
            "Evaluated params: [0.01, 86, 3, 0.4, 32] -> Val AUC: 0.8957\n",
            "Evaluated params: [0.01, 91, 3, 0.4, 128] -> Val AUC: 0.8735\n",
            "Evaluated params: [0.01, 91, 3, 0.4, 128] -> Val AUC: 0.8769\n",
            "Evaluated params: [0.01, 86, 3, 0.4, 32] -> Val AUC: 0.9040\n",
            "Evaluated params: [0.01, 91, 3, 0.4, 128] -> Val AUC: 0.8816\n",
            "Evaluated params: [0.01, 91, 3, 0.3, 64] -> Val AUC: 0.9011\n",
            "Evaluated params: [0.01, 114, 1, 0.4, 64] -> Val AUC: 0.8926\n",
            "Evaluated params: [0.01, 32, 3, 0.4, 32] -> Val AUC: 0.9101\n",
            "Evaluated params: [0.01, 86, 1, 0.2, 64] -> Val AUC: 0.8891\n",
            "Evaluated params: [0.01, 86, 2, 0.1, 128] -> Val AUC: 0.8779\n",
            "Evaluated params: [0.01, 81, 2, 0.1, 64] -> Val AUC: 0.8835\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "MBO Optimization:  65%|██████▌   | 13/20 [1:47:12<1:03:27, 543.94s/it, Best AUC=0.9101]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Evaluated params: [0.001, 122, 1, 0.5, 64] -> Val AUC: 0.8911\n",
            "Evaluated params: [0.0001, 48, 3, 0.1, 128] -> Val AUC: 0.8796\n",
            "Evaluated params: [0.001, 47, 2, 0.2, 64] -> Val AUC: 0.8889\n",
            "Evaluated params: [0.01, 82, 1, 0.3, 64] -> Val AUC: 0.8921\n",
            "Evaluated params: [0.0001, 72, 1, 0.4, 32] -> Val AUC: 0.8984\n",
            "Evaluated params: [0.001, 115, 2, 0.1, 32] -> Val AUC: 0.8891\n",
            "Evaluated params: [0.01, 117, 1, 0.4, 128] -> Val AUC: 0.8784\n",
            "Evaluated params: [0.01, 95, 1, 0.4, 128] -> Val AUC: 0.8801\n",
            "Evaluated params: [0.001, 106, 2, 0.4, 64] -> Val AUC: 0.8965\n",
            "Evaluated params: [0.01, 44, 2, 0.2, 64] -> Val AUC: 0.8830\n",
            "Evaluated params: [0.01, 50, 1, 0.4, 64] -> Val AUC: 0.8994\n",
            "Evaluated params: [0.01, 95, 2, 0.4, 32] -> Val AUC: 0.9016\n",
            "Evaluated params: [0.0001, 72, 1, 0.4, 128] -> Val AUC: 0.8828\n",
            "Evaluated params: [0.01, 48, 1, 0.4, 128] -> Val AUC: 0.8813\n",
            "Evaluated params: [0.0001, 106, 1, 0.2, 64] -> Val AUC: 0.8921\n",
            "Evaluated params: [0.01, 82, 1, 0.4, 64] -> Val AUC: 0.8965\n",
            "Evaluated params: [0.001, 95, 2, 0.4, 32] -> Val AUC: 0.8977\n",
            "Evaluated params: [0.01, 95, 2, 0.4, 32] -> Val AUC: 0.9070\n",
            "Evaluated params: [0.01, 44, 2, 0.5, 128] -> Val AUC: 0.8784\n",
            "Evaluated params: [0.01, 44, 2, 0.5, 32] -> Val AUC: 0.8926\n",
            "Evaluated params: [0.01, 95, 2, 0.1, 32] -> Val AUC: 0.8947\n",
            "Evaluated params: [0.01, 95, 2, 0.4, 32] -> Val AUC: 0.8904\n",
            "Evaluated params: [0.01, 95, 2, 0.4, 32] -> Val AUC: 0.9023\n",
            "Evaluated params: [0.001, 95, 2, 0.4, 32] -> Val AUC: 0.8965\n",
            "Evaluated params: [0.01, 82, 1, 0.4, 64] -> Val AUC: 0.8906\n",
            "Evaluated params: [0.01, 95, 2, 0.1, 32] -> Val AUC: 0.8950\n",
            "Evaluated params: [0.01, 44, 2, 0.5, 32] -> Val AUC: 0.8945\n",
            "Evaluated params: [0.0001, 106, 1, 0.2, 64] -> Val AUC: 0.8921\n",
            "Evaluated params: [0.0001, 72, 1, 0.4, 128] -> Val AUC: 0.8799\n",
            "Evaluated params: [0.01, 50, 1, 0.4, 64] -> Val AUC: 0.8921\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "MBO Optimization:  70%|███████   | 14/20 [1:57:39<56:54, 569.06s/it, Best AUC=0.9023]  "
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Evaluated params: [0.0001, 72, 1, 0.4, 32] -> Val AUC: 0.8996\n",
            "Evaluated params: [0.01, 46, 2, 0.5, 64] -> Val AUC: 0.8867\n",
            "Evaluated params: [0.01, 98, 2, 0.4, 128] -> Val AUC: 0.8786\n",
            "Evaluated params: [0.01, 41, 2, 0.5, 32] -> Val AUC: 0.9111\n",
            "Evaluated params: [0.01, 97, 3, 0.1, 128] -> Val AUC: 0.8825\n",
            "Evaluated params: [0.001, 119, 1, 0.5, 128] -> Val AUC: 0.8877\n",
            "Evaluated params: [0.001, 67, 2, 0.5, 128] -> Val AUC: 0.8799\n",
            "Evaluated params: [0.001, 103, 2, 0.2, 64] -> Val AUC: 0.8899\n",
            "Evaluated params: [0.0001, 125, 2, 0.1, 64] -> Val AUC: 0.8879\n",
            "Evaluated params: [0.0001, 113, 1, 0.4, 64] -> Val AUC: 0.8989\n",
            "Evaluated params: [0.01, 88, 3, 0.1, 32] -> Val AUC: 0.9094\n",
            "Evaluated params: [0.0001, 113, 1, 0.4, 32] -> Val AUC: 0.9016\n",
            "Evaluated params: [0.01, 41, 2, 0.1, 128] -> Val AUC: 0.8689\n",
            "Evaluated params: [0.01, 103, 3, 0.4, 128] -> Val AUC: 0.8825\n",
            "Evaluated params: [0.01, 67, 3, 0.1, 64] -> Val AUC: 0.8825\n",
            "Evaluated params: [0.01, 67, 2, 0.5, 64] -> Val AUC: 0.8977\n",
            "Evaluated params: [0.0001, 113, 1, 0.1, 32] -> Val AUC: 0.9013\n",
            "Evaluated params: [0.0001, 113, 1, 0.4, 128] -> Val AUC: 0.8877\n",
            "Evaluated params: [0.0001, 113, 1, 0.5, 32] -> Val AUC: 0.8987\n",
            "Evaluated params: [0.0001, 46, 1, 0.1, 32] -> Val AUC: 0.8940\n",
            "Evaluated params: [0.0001, 128, 1, 0.4, 32] -> Val AUC: 0.9026\n",
            "Evaluated params: [0.0001, 128, 1, 0.4, 32] -> Val AUC: 0.9009\n",
            "Evaluated params: [0.0001, 113, 1, 0.4, 32] -> Val AUC: 0.8991\n",
            "Evaluated params: [0.0001, 113, 1, 0.1, 32] -> Val AUC: 0.9028\n",
            "Evaluated params: [0.0001, 113, 1, 0.5, 32] -> Val AUC: 0.9021\n",
            "Evaluated params: [0.01, 67, 2, 0.5, 64] -> Val AUC: 0.8984\n",
            "Evaluated params: [0.0001, 46, 1, 0.1, 32] -> Val AUC: 0.9006\n",
            "Evaluated params: [0.0001, 113, 1, 0.4, 128] -> Val AUC: 0.8806\n",
            "Evaluated params: [0.01, 103, 3, 0.4, 128] -> Val AUC: 0.8794\n",
            "Evaluated params: [0.01, 41, 2, 0.5, 32] -> Val AUC: 0.9013\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "MBO Optimization:  75%|███████▌  | 15/20 [2:11:01<53:15, 639.14s/it, Best AUC=0.9111]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Evaluated params: [0.01, 88, 3, 0.1, 32] -> Val AUC: 0.9094\n",
            "Evaluated params: [0.001, 50, 1, 0.3, 128] -> Val AUC: 0.8867\n",
            "Evaluated params: [0.0001, 43, 1, 0.4, 32] -> Val AUC: 0.8955\n",
            "Evaluated params: [0.0001, 72, 1, 0.5, 32] -> Val AUC: 0.9013\n",
            "Evaluated params: [0.01, 73, 3, 0.5, 64] -> Val AUC: 0.9023\n",
            "Evaluated params: [0.01, 55, 3, 0.3, 32] -> Val AUC: 0.8764\n",
            "Evaluated params: [0.001, 55, 3, 0.3, 64] -> Val AUC: 0.8901\n",
            "Evaluated params: [0.01, 85, 3, 0.1, 64] -> Val AUC: 0.8803\n",
            "Evaluated params: [0.001, 111, 3, 0.5, 64] -> Val AUC: 0.8882\n",
            "Evaluated params: [0.0001, 68, 3, 0.2, 128] -> Val AUC: 0.8833\n",
            "Evaluated params: [0.01, 100, 3, 0.1, 128] -> Val AUC: 0.8718\n",
            "Evaluated params: [0.0001, 43, 3, 0.3, 32] -> Val AUC: 0.8984\n",
            "Evaluated params: [0.001, 72, 3, 0.1, 64] -> Val AUC: 0.8842\n",
            "Evaluated params: [0.001, 55, 1, 0.3, 128] -> Val AUC: 0.8894\n",
            "Evaluated params: [0.01, 68, 3, 0.2, 128] -> Val AUC: 0.8625\n",
            "Evaluated params: [0.001, 73, 3, 0.5, 64] -> Val AUC: 0.8840\n",
            "Evaluated params: [0.0001, 43, 3, 0.3, 32] -> Val AUC: 0.8916\n",
            "Evaluated params: [0.0001, 55, 3, 0.3, 128] -> Val AUC: 0.8784\n",
            "Evaluated params: [0.0001, 43, 2, 0.3, 64] -> Val AUC: 0.8908\n",
            "Evaluated params: [0.001, 128, 3, 0.3, 32] -> Val AUC: 0.8928\n",
            "Evaluated params: [0.0001, 43, 3, 0.3, 32] -> Val AUC: 0.8969\n",
            "Evaluated params: [0.0001, 43, 3, 0.3, 32] -> Val AUC: 0.9018\n",
            "Evaluated params: [0.0001, 43, 3, 0.3, 32] -> Val AUC: 0.8935\n",
            "Evaluated params: [0.001, 128, 3, 0.3, 32] -> Val AUC: 0.8913\n",
            "Evaluated params: [0.0001, 43, 3, 0.3, 32] -> Val AUC: 0.8943\n",
            "Evaluated params: [0.0001, 43, 2, 0.3, 64] -> Val AUC: 0.8901\n",
            "Evaluated params: [0.001, 55, 1, 0.3, 128] -> Val AUC: 0.8886\n",
            "Evaluated params: [0.001, 72, 3, 0.1, 64] -> Val AUC: 0.8918\n",
            "Evaluated params: [0.001, 73, 3, 0.5, 64] -> Val AUC: 0.8886\n",
            "Evaluated params: [0.01, 73, 3, 0.5, 64] -> Val AUC: 0.8982\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "MBO Optimization:  80%|████████  | 16/20 [2:24:32<46:03, 690.98s/it, Best AUC=0.9026]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Evaluated params: [0.0001, 72, 1, 0.5, 32] -> Val AUC: 0.9026\n",
            "Evaluated params: [0.01, 54, 3, 0.3, 32] -> Val AUC: 0.8940\n",
            "Evaluated params: [0.0001, 36, 3, 0.3, 64] -> Val AUC: 0.8906\n",
            "Evaluated params: [0.001, 56, 2, 0.1, 128] -> Val AUC: 0.8803\n",
            "Evaluated params: [0.01, 52, 3, 0.3, 128] -> Val AUC: 0.8759\n",
            "Evaluated params: [0.0001, 36, 2, 0.3, 128] -> Val AUC: 0.8808\n",
            "Evaluated params: [0.01, 67, 3, 0.3, 64] -> Val AUC: 0.8889\n",
            "Evaluated params: [0.01, 82, 3, 0.4, 128] -> Val AUC: 0.8769\n",
            "Evaluated params: [0.01, 79, 2, 0.5, 32] -> Val AUC: 0.8977\n",
            "Evaluated params: [0.01, 97, 3, 0.4, 32] -> Val AUC: 0.8982\n",
            "Evaluated params: [0.01, 99, 3, 0.5, 64] -> Val AUC: 0.8916\n",
            "Evaluated params: [0.001, 36, 3, 0.1, 128] -> Val AUC: 0.8823\n",
            "Evaluated params: [0.001, 56, 3, 0.4, 32] -> Val AUC: 0.8977\n",
            "Evaluated params: [0.01, 67, 2, 0.4, 64] -> Val AUC: 0.9004\n",
            "Evaluated params: [0.01, 82, 3, 0.3, 128] -> Val AUC: 0.8752\n",
            "Evaluated params: [0.001, 97, 3, 0.3, 64] -> Val AUC: 0.8825\n",
            "Evaluated params: [0.001, 36, 3, 0.2, 128] -> Val AUC: 0.8796\n",
            "Evaluated params: [0.0001, 36, 1, 0.1, 128] -> Val AUC: 0.8742\n",
            "Evaluated params: [0.0001, 36, 3, 0.1, 128] -> Val AUC: 0.8767\n",
            "Evaluated params: [0.001, 56, 3, 0.1, 128] -> Val AUC: 0.8796\n",
            "Evaluated params: [0.0001, 36, 3, 0.1, 128] -> Val AUC: 0.8791\n",
            "Evaluated params: [0.01, 67, 2, 0.4, 64] -> Val AUC: 0.8816\n",
            "Evaluated params: [0.001, 56, 3, 0.4, 32] -> Val AUC: 0.8813\n",
            "Evaluated params: [0.001, 97, 3, 0.3, 64] -> Val AUC: 0.8869\n",
            "Evaluated params: [0.001, 36, 3, 0.1, 128] -> Val AUC: 0.8728\n",
            "Evaluated params: [0.001, 36, 3, 0.2, 128] -> Val AUC: 0.8847\n",
            "Evaluated params: [0.001, 56, 3, 0.1, 128] -> Val AUC: 0.8755\n",
            "Evaluated params: [0.0001, 36, 3, 0.1, 128] -> Val AUC: 0.8801\n",
            "Evaluated params: [0.0001, 36, 3, 0.1, 128] -> Val AUC: 0.8806\n",
            "Evaluated params: [0.01, 97, 3, 0.4, 32] -> Val AUC: 0.9070\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "MBO Optimization:  85%|████████▌ | 17/20 [2:37:30<35:51, 717.04s/it, Best AUC=0.9070]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Evaluated params: [0.01, 79, 2, 0.5, 32] -> Val AUC: 0.8930\n",
            "Evaluated params: [0.0001, 50, 2, 0.5, 64] -> Val AUC: 0.8928\n",
            "Evaluated params: [0.001, 75, 1, 0.2, 32] -> Val AUC: 0.8969\n",
            "Evaluated params: [0.01, 74, 1, 0.2, 128] -> Val AUC: 0.8794\n",
            "Evaluated params: [0.0001, 119, 3, 0.3, 32] -> Val AUC: 0.8928\n",
            "Evaluated params: [0.0001, 118, 1, 0.3, 64] -> Val AUC: 0.8960\n",
            "Evaluated params: [0.001, 107, 3, 0.1, 128] -> Val AUC: 0.8740\n",
            "Evaluated params: [0.01, 72, 1, 0.5, 128] -> Val AUC: 0.8840\n",
            "Evaluated params: [0.001, 43, 3, 0.3, 128] -> Val AUC: 0.8850\n",
            "Evaluated params: [0.0001, 78, 3, 0.2, 64] -> Val AUC: 0.8852\n",
            "Evaluated params: [0.0001, 75, 2, 0.5, 64] -> Val AUC: 0.8894\n",
            "Evaluated params: [0.01, 78, 2, 0.2, 128] -> Val AUC: 0.8720\n",
            "Evaluated params: [0.0001, 78, 1, 0.5, 64] -> Val AUC: 0.8926\n",
            "Evaluated params: [0.0001, 78, 1, 0.2, 64] -> Val AUC: 0.8933\n",
            "Evaluated params: [0.0001, 74, 1, 0.2, 64] -> Val AUC: 0.8904\n",
            "Evaluated params: [0.0001, 119, 3, 0.5, 128] -> Val AUC: 0.8828\n",
            "Evaluated params: [0.01, 32, 2, 0.2, 128] -> Val AUC: 0.8769\n",
            "Evaluated params: [0.01, 78, 3, 0.1, 128] -> Val AUC: 0.8698\n",
            "Evaluated params: [0.01, 78, 2, 0.2, 128] -> Val AUC: 0.8811\n",
            "Evaluated params: [0.01, 78, 2, 0.2, 128] -> Val AUC: 0.8864\n",
            "Evaluated params: [0.01, 78, 3, 0.2, 64] -> Val AUC: 0.8872\n",
            "Evaluated params: [0.0001, 78, 1, 0.2, 64] -> Val AUC: 0.9001\n",
            "Evaluated params: [0.0001, 78, 1, 0.5, 64] -> Val AUC: 0.8955\n",
            "Evaluated params: [0.0001, 74, 1, 0.2, 64] -> Val AUC: 0.8889\n",
            "Evaluated params: [0.01, 78, 3, 0.2, 64] -> Val AUC: 0.8794\n",
            "Evaluated params: [0.01, 78, 2, 0.2, 128] -> Val AUC: 0.8764\n",
            "Evaluated params: [0.0001, 119, 3, 0.5, 128] -> Val AUC: 0.8811\n",
            "Evaluated params: [0.01, 78, 2, 0.2, 128] -> Val AUC: 0.8799\n",
            "Evaluated params: [0.01, 32, 2, 0.2, 128] -> Val AUC: 0.8723\n",
            "Evaluated params: [0.001, 75, 1, 0.2, 32] -> Val AUC: 0.9040\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "MBO Optimization:  90%|█████████ | 18/20 [2:51:37<25:12, 756.22s/it, Best AUC=0.9040]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Evaluated params: [0.0001, 118, 1, 0.3, 64] -> Val AUC: 0.8965\n",
            "Evaluated params: [0.01, 121, 1, 0.1, 32] -> Val AUC: 0.9072\n",
            "Evaluated params: [0.0001, 103, 2, 0.5, 32] -> Val AUC: 0.8960\n",
            "Evaluated params: [0.01, 94, 2, 0.4, 64] -> Val AUC: 0.8884\n",
            "Evaluated params: [0.01, 65, 3, 0.4, 64] -> Val AUC: 0.9031\n",
            "Evaluated params: [0.0001, 109, 2, 0.4, 128] -> Val AUC: 0.8838\n",
            "Evaluated params: [0.001, 59, 1, 0.1, 32] -> Val AUC: 0.9001\n",
            "Evaluated params: [0.0001, 81, 2, 0.4, 128] -> Val AUC: 0.8842\n",
            "Evaluated params: [0.01, 98, 3, 0.1, 64] -> Val AUC: 0.8904\n",
            "Evaluated params: [0.0001, 62, 2, 0.2, 64] -> Val AUC: 0.8891\n",
            "Evaluated params: [0.0001, 105, 3, 0.4, 128] -> Val AUC: 0.8811\n",
            "Evaluated params: [0.0001, 81, 2, 0.4, 64] -> Val AUC: 0.8899\n",
            "Evaluated params: [0.01, 65, 3, 0.4, 64] -> Val AUC: 0.8926\n",
            "Evaluated params: [0.01, 94, 2, 0.2, 128] -> Val AUC: 0.8830\n",
            "Evaluated params: [0.01, 62, 2, 0.4, 32] -> Val AUC: 0.8938\n",
            "Evaluated params: [0.0001, 59, 2, 0.4, 128] -> Val AUC: 0.8767\n",
            "Evaluated params: [0.01, 81, 2, 0.4, 32] -> Val AUC: 0.8918\n",
            "Evaluated params: [0.0001, 32, 2, 0.5, 128] -> Val AUC: 0.8657\n",
            "Evaluated params: [0.0001, 81, 3, 0.5, 64] -> Val AUC: 0.8821\n",
            "Evaluated params: [0.0001, 94, 2, 0.4, 64] -> Val AUC: 0.8967\n",
            "Evaluated params: [0.0001, 81, 2, 0.5, 64] -> Val AUC: 0.8921\n",
            "Evaluated params: [0.0001, 94, 2, 0.4, 64] -> Val AUC: 0.8938\n",
            "Evaluated params: [0.01, 62, 2, 0.4, 32] -> Val AUC: 0.8811\n",
            "Evaluated params: [0.01, 65, 3, 0.4, 64] -> Val AUC: 0.8977\n",
            "Evaluated params: [0.0001, 81, 2, 0.5, 64] -> Val AUC: 0.8842\n",
            "Evaluated params: [0.01, 81, 2, 0.4, 32] -> Val AUC: 0.9057\n",
            "Evaluated params: [0.0001, 81, 2, 0.4, 64] -> Val AUC: 0.8911\n",
            "Evaluated params: [0.01, 94, 2, 0.2, 128] -> Val AUC: 0.8740\n",
            "Evaluated params: [0.0001, 81, 3, 0.5, 64] -> Val AUC: 0.8882\n",
            "Evaluated params: [0.01, 121, 1, 0.1, 32] -> Val AUC: 0.9055\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "MBO Optimization:  95%|█████████▌| 19/20 [3:06:57<13:25, 805.23s/it, Best AUC=0.9072]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Evaluated params: [0.01, 65, 3, 0.4, 64] -> Val AUC: 0.8896\n",
            "Evaluated params: [0.0001, 105, 3, 0.3, 128] -> Val AUC: 0.8862\n",
            "Evaluated params: [0.01, 62, 3, 0.4, 32] -> Val AUC: 0.9004\n",
            "Evaluated params: [0.0001, 119, 1, 0.4, 128] -> Val AUC: 0.8845\n",
            "Evaluated params: [0.001, 80, 2, 0.3, 64] -> Val AUC: 0.8947\n",
            "Evaluated params: [0.01, 74, 3, 0.2, 128] -> Val AUC: 0.8667\n",
            "Evaluated params: [0.01, 128, 3, 0.3, 128] -> Val AUC: 0.8940\n",
            "Evaluated params: [0.001, 67, 2, 0.2, 32] -> Val AUC: 0.8918\n",
            "Evaluated params: [0.001, 126, 3, 0.5, 64] -> Val AUC: 0.8823\n",
            "Evaluated params: [0.0001, 100, 2, 0.1, 64] -> Val AUC: 0.8886\n",
            "Evaluated params: [0.0001, 91, 2, 0.1, 128] -> Val AUC: 0.8850\n",
            "Evaluated params: [0.001, 105, 2, 0.3, 128] -> Val AUC: 0.8764\n",
            "Evaluated params: [0.01, 91, 3, 0.3, 64] -> Val AUC: 0.8930\n",
            "Evaluated params: [0.0001, 126, 3, 0.4, 32] -> Val AUC: 0.8972\n",
            "Evaluated params: [0.0001, 119, 2, 0.3, 128] -> Val AUC: 0.8838\n",
            "Evaluated params: [0.0001, 67, 3, 0.4, 64] -> Val AUC: 0.8877\n",
            "Evaluated params: [0.001, 105, 1, 0.3, 128] -> Val AUC: 0.8916\n",
            "Evaluated params: [0.001, 105, 2, 0.3, 128] -> Val AUC: 0.8728\n",
            "Evaluated params: [0.001, 105, 2, 0.3, 128] -> Val AUC: 0.8801\n",
            "Evaluated params: [0.01, 105, 2, 0.5, 128] -> Val AUC: 0.8825\n",
            "Evaluated params: [0.001, 105, 2, 0.5, 128] -> Val AUC: 0.8752\n",
            "Evaluated params: [0.0001, 126, 3, 0.4, 32] -> Val AUC: 0.8987\n",
            "Evaluated params: [0.01, 91, 3, 0.3, 64] -> Val AUC: 0.8913\n",
            "Evaluated params: [0.001, 105, 1, 0.3, 128] -> Val AUC: 0.8857\n",
            "Evaluated params: [0.0001, 67, 3, 0.4, 64] -> Val AUC: 0.8830\n",
            "Evaluated params: [0.0001, 119, 2, 0.3, 128] -> Val AUC: 0.8850\n",
            "Evaluated params: [0.01, 105, 2, 0.5, 128] -> Val AUC: 0.8835\n",
            "Evaluated params: [0.001, 105, 2, 0.3, 128] -> Val AUC: 0.8767\n",
            "Evaluated params: [0.001, 105, 2, 0.3, 128] -> Val AUC: 0.8774\n",
            "Evaluated params: [0.01, 62, 3, 0.4, 32] -> Val AUC: 0.9028\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "MBO Optimization: 100%|██████████| 20/20 [3:20:35<00:00, 601.77s/it, Best AUC=0.9028]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Evaluated params: [0.001, 80, 2, 0.3, 64] -> Val AUC: 0.8911\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "ename": "AttributeError",
          "evalue": "'MonarchButterflyOptimization' object has no attribute 'best_solution'",
          "output_type": "error",
          "traceback": [
            "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
            "\u001b[31mAttributeError\u001b[39m                            Traceback (most recent call last)",
            "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[18]\u001b[39m\u001b[32m, line 31\u001b[39m\n\u001b[32m     28\u001b[39m         pbar.update(\u001b[32m1\u001b[39m)\n\u001b[32m     30\u001b[39m \u001b[38;5;66;03m# Setelah loop selesai, ambil hasil terbaik dari MBO\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m31\u001b[39m best_solution = \u001b[43malgorithm\u001b[49m\u001b[43m.\u001b[49m\u001b[43mbest_solution\u001b[49m\n\u001b[32m     32\u001b[39m best_params_continuous = best_solution[\u001b[32m0\u001b[39m]\n\u001b[32m     33\u001b[39m best_fitness = best_solution[\u001b[32m1\u001b[39m]\n",
            "\u001b[31mAttributeError\u001b[39m: 'MonarchButterflyOptimization' object has no attribute 'best_solution'"
          ]
        }
      ],
      "source": [
        "# Definisi ruang pencarian (search space)\n",
        "param_bounds = [\n",
        "    [0.0001, 0.001, 0.01],\n",
        "    list(range(32, 129)),\n",
        "    list(range(1, 4)),\n",
        "    [0.1, 0.2, 0.3, 0.4, 0.5],\n",
        "    [32, 64, 128]\n",
        "]\n",
        "\n",
        "problem = LSTMOptimizationProblem(param_bounds)\n",
        "\n",
        "# Run MBO dengan satu populasi (10)\n",
        "pop_size = 10\n",
        "results = {}\n",
        "\n",
        "print(f\"\\nRunning MBO with population size = {pop_size}\")\n",
        "\n",
        "algorithm = MonarchButterflyOptimization(population_size=pop_size, limit=1.2, butterfly_population=pop_size)\n",
        "task = Task(problem=problem, max_iters=20)\n",
        "    \n",
        "# Ganti bagian ini dengan loop tqdm\n",
        "with tqdm(total=task.max_iters, desc=\"MBO Optimization\") as pbar:\n",
        "    for i in range(task.max_iters):\n",
        "        best = algorithm.run(Task(problem=problem, max_iters=1))\n",
        "        # Ini untuk update progress bar dan display best fitness sementara\n",
        "        best_fitness = best[1]\n",
        "        pbar.set_postfix({'Best AUC': f'{1 - best_fitness:.4f}'})\n",
        "        pbar.update(1)\n",
        "\n",
        "# Setelah loop selesai, ambil hasil terbaik dari MBO\n",
        "best_solution = algorithm.best_solution\n",
        "best_params_continuous = best_solution[0]\n",
        "best_fitness = best_solution[1]\n",
        "\n",
        "decoded_best_params = {}\n",
        "param_names = ['learning_rate', 'units', 'layers', 'dropout_rate', 'batch_size']\n",
        "\n",
        "for i in range(len(param_bounds)):\n",
        "    bounds_list = param_bounds[i]\n",
        "    index = min(int(best_params_continuous[i] * len(bounds_list)), len(bounds_list) - 1)\n",
        "    decoded_best_params[param_names[i]] = bounds_list[index]\n",
        "\n",
        "results[pop_size] = {\n",
        "    'best_fitness': best_fitness,\n",
        "    'best_params': decoded_best_params\n",
        "}\n",
        "\n",
        "print(\"\\n\\n=============== MBO Results Summary ===============\")\n",
        "print(f\"Population Size = {pop_size}\")\n",
        "print(f\"  Best Parameters: {results[pop_size]['best_params']}\")\n",
        "print(f\"  Best AUC: {1 - results[pop_size]['best_fitness']:.4f}\")\n",
        "print(\"-\" * 40)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2a181d10",
      "metadata": {},
      "source": [
        "Hasil terbaik\n",
        "\n",
        "Berdasarkan log yang lo berikan, nilai \n",
        "\n",
        "Val AUC terbaik yang dicapai adalah 0.9175.\n",
        "\n",
        "Nilai ini dicapai pada iterasi ke-4, dengan set parameter berikut:\n",
        "\n",
        "learning_rate: 0.01 \n",
        "units: 128 \n",
        "layers: 3 \n",
        "dropout_rate: 0.5 \n",
        "batch_size: 32 \n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4d1f56c2",
      "metadata": {},
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "id": "a45b742d",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_1\"</span>\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1mModel: \"sequential_1\"\u001b[0m\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ reshape_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Reshape</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1024</span>)        │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ lstm_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">12</span>)          │        <span style=\"color: #00af00; text-decoration-color: #00af00\">49,776</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ lstm_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">12</span>)          │         <span style=\"color: #00af00; text-decoration-color: #00af00\">1,200</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ lstm_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">12</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">1,200</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dropout_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">12</span>)             │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)              │            <span style=\"color: #00af00; text-decoration-color: #00af00\">13</span> │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
              "</pre>\n"
            ],
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ reshape_1 (\u001b[38;5;33mReshape\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m1024\u001b[0m)        │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ lstm_3 (\u001b[38;5;33mLSTM\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m12\u001b[0m)          │        \u001b[38;5;34m49,776\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ lstm_4 (\u001b[38;5;33mLSTM\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m12\u001b[0m)          │         \u001b[38;5;34m1,200\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ lstm_5 (\u001b[38;5;33mLSTM\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m12\u001b[0m)             │         \u001b[38;5;34m1,200\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dropout_1 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m12\u001b[0m)             │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_1 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)              │            \u001b[38;5;34m13\u001b[0m │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">52,189</span> (203.86 KB)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m52,189\u001b[0m (203.86 KB)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">52,189</span> (203.86 KB)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m52,189\u001b[0m (203.86 KB)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 91ms/step - AUC: 0.6185 - accuracy: 0.5891 - loss: 0.6853 - val_AUC: 0.8882 - val_accuracy: 0.8333 - val_loss: 0.5943\n",
            "Epoch 2/100\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - AUC: 0.8909 - accuracy: 0.8439 - loss: 0.5406 - val_AUC: 0.8928 - val_accuracy: 0.8431 - val_loss: 0.4163\n",
            "Epoch 3/100\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - AUC: 0.9205 - accuracy: 0.8796 - loss: 0.3582 - val_AUC: 0.8971 - val_accuracy: 0.8137 - val_loss: 0.4343\n",
            "Epoch 4/100\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - AUC: 0.9339 - accuracy: 0.8765 - loss: 0.3336 - val_AUC: 0.8969 - val_accuracy: 0.8824 - val_loss: 0.3839\n",
            "Epoch 5/100\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - AUC: 0.9633 - accuracy: 0.9333 - loss: 0.2253 - val_AUC: 0.9201 - val_accuracy: 0.8725 - val_loss: 0.3732\n",
            "Epoch 6/100\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - AUC: 0.9608 - accuracy: 0.9376 - loss: 0.2063 - val_AUC: 0.9193 - val_accuracy: 0.8529 - val_loss: 0.3897\n",
            "Epoch 7/100\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - AUC: 0.9664 - accuracy: 0.9291 - loss: 0.2022 - val_AUC: 0.9251 - val_accuracy: 0.8725 - val_loss: 0.3594\n",
            "Epoch 8/100\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - AUC: 0.9842 - accuracy: 0.9463 - loss: 0.1460 - val_AUC: 0.9193 - val_accuracy: 0.8529 - val_loss: 0.3952\n",
            "Epoch 9/100\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - AUC: 0.9819 - accuracy: 0.9249 - loss: 0.1837 - val_AUC: 0.9172 - val_accuracy: 0.8431 - val_loss: 0.4414\n",
            "Epoch 10/100\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - AUC: 0.9845 - accuracy: 0.9544 - loss: 0.1344 - val_AUC: 0.9186 - val_accuracy: 0.8529 - val_loss: 0.4607\n",
            "Epoch 11/100\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - AUC: 0.9960 - accuracy: 0.9679 - loss: 0.0926 - val_AUC: 0.9151 - val_accuracy: 0.8431 - val_loss: 0.5224\n",
            "Epoch 12/100\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - AUC: 0.9955 - accuracy: 0.9622 - loss: 0.0867 - val_AUC: 0.9153 - val_accuracy: 0.8137 - val_loss: 0.5876\n",
            "Epoch 13/100\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - AUC: 0.9951 - accuracy: 0.9571 - loss: 0.0963 - val_AUC: 0.9122 - val_accuracy: 0.8529 - val_loss: 0.6019\n",
            "Epoch 14/100\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - AUC: 0.9983 - accuracy: 0.9734 - loss: 0.0572 - val_AUC: 0.8998 - val_accuracy: 0.8235 - val_loss: 0.6632\n",
            "Epoch 15/100\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - AUC: 0.9988 - accuracy: 0.9773 - loss: 0.0478 - val_AUC: 0.8983 - val_accuracy: 0.8431 - val_loss: 0.7032\n",
            "Epoch 16/100\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - AUC: 0.9950 - accuracy: 0.9506 - loss: 0.0808 - val_AUC: 0.8992 - val_accuracy: 0.8333 - val_loss: 0.7158\n",
            "Epoch 17/100\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - AUC: 0.9976 - accuracy: 0.9691 - loss: 0.0647 - val_AUC: 0.9068 - val_accuracy: 0.8627 - val_loss: 0.6253\n",
            "Epoch 18/100\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - AUC: 0.9972 - accuracy: 0.9637 - loss: 0.0666 - val_AUC: 0.8946 - val_accuracy: 0.8039 - val_loss: 0.7254\n",
            "Epoch 19/100\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - AUC: 0.9935 - accuracy: 0.9545 - loss: 0.1095 - val_AUC: 0.9199 - val_accuracy: 0.8627 - val_loss: 0.5344\n",
            "Epoch 20/100\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - AUC: 0.9977 - accuracy: 0.9705 - loss: 0.0687 - val_AUC: 0.9112 - val_accuracy: 0.8431 - val_loss: 0.5395\n",
            "Epoch 21/100\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - AUC: 0.9979 - accuracy: 0.9751 - loss: 0.0611 - val_AUC: 0.9155 - val_accuracy: 0.8333 - val_loss: 0.5820\n",
            "Epoch 22/100\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - AUC: 0.9993 - accuracy: 0.9840 - loss: 0.0464 - val_AUC: 0.9027 - val_accuracy: 0.8431 - val_loss: 0.6689\n",
            "Epoch 23/100\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - AUC: 0.9996 - accuracy: 0.9861 - loss: 0.0284 - val_AUC: 0.9097 - val_accuracy: 0.8431 - val_loss: 0.6412\n",
            "Epoch 24/100\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - AUC: 0.9995 - accuracy: 0.9780 - loss: 0.0409 - val_AUC: 0.9083 - val_accuracy: 0.8725 - val_loss: 0.6425\n",
            "Epoch 25/100\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - AUC: 0.9992 - accuracy: 0.9828 - loss: 0.0383 - val_AUC: 0.9023 - val_accuracy: 0.8529 - val_loss: 0.7090\n",
            "Epoch 26/100\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - AUC: 0.9997 - accuracy: 0.9874 - loss: 0.0241 - val_AUC: 0.9075 - val_accuracy: 0.8627 - val_loss: 0.6718\n",
            "Epoch 27/100\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - AUC: 0.9997 - accuracy: 0.9832 - loss: 0.0273 - val_AUC: 0.9050 - val_accuracy: 0.8627 - val_loss: 0.7145\n",
            "Epoch 28/100\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - AUC: 0.9995 - accuracy: 0.9818 - loss: 0.0270 - val_AUC: 0.8927 - val_accuracy: 0.8627 - val_loss: 0.7408\n",
            "Epoch 29/100\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - AUC: 0.9997 - accuracy: 0.9877 - loss: 0.0245 - val_AUC: 0.8919 - val_accuracy: 0.8529 - val_loss: 0.7775\n",
            "Epoch 30/100\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - AUC: 0.9996 - accuracy: 0.9830 - loss: 0.0268 - val_AUC: 0.8857 - val_accuracy: 0.8725 - val_loss: 0.7727\n",
            "Epoch 31/100\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - AUC: 0.9998 - accuracy: 0.9900 - loss: 0.0177 - val_AUC: 0.8845 - val_accuracy: 0.8627 - val_loss: 0.7846\n",
            "Epoch 32/100\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - AUC: 0.9999 - accuracy: 0.9890 - loss: 0.0209 - val_AUC: 0.8758 - val_accuracy: 0.8431 - val_loss: 0.8401\n",
            "Epoch 33/100\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - AUC: 0.9999 - accuracy: 0.9939 - loss: 0.0141 - val_AUC: 0.8805 - val_accuracy: 0.8725 - val_loss: 0.8240\n",
            "Epoch 34/100\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - AUC: 0.9989 - accuracy: 0.9862 - loss: 0.0239 - val_AUC: 0.8843 - val_accuracy: 0.8725 - val_loss: 0.8092\n",
            "Epoch 35/100\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - AUC: 0.9998 - accuracy: 0.9903 - loss: 0.0262 - val_AUC: 0.8921 - val_accuracy: 0.8431 - val_loss: 0.7885\n",
            "Epoch 36/100\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - AUC: 0.9998 - accuracy: 0.9896 - loss: 0.0166 - val_AUC: 0.8967 - val_accuracy: 0.8529 - val_loss: 0.7628\n",
            "Epoch 37/100\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - AUC: 0.9995 - accuracy: 0.9795 - loss: 0.0292 - val_AUC: 0.8899 - val_accuracy: 0.8431 - val_loss: 0.8235\n",
            "Epoch 38/100\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - AUC: 0.9993 - accuracy: 0.9749 - loss: 0.0369 - val_AUC: 0.8888 - val_accuracy: 0.8431 - val_loss: 0.7663\n",
            "Epoch 39/100\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - AUC: 0.9998 - accuracy: 0.9900 - loss: 0.0155 - val_AUC: 0.8911 - val_accuracy: 0.8529 - val_loss: 0.7730\n",
            "Epoch 40/100\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - AUC: 0.9999 - accuracy: 0.9895 - loss: 0.0165 - val_AUC: 0.8925 - val_accuracy: 0.8529 - val_loss: 0.7986\n",
            "Epoch 41/100\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - AUC: 0.9988 - accuracy: 0.9847 - loss: 0.0266 - val_AUC: 0.8865 - val_accuracy: 0.8529 - val_loss: 0.8204\n",
            "Epoch 42/100\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - AUC: 0.9999 - accuracy: 0.9944 - loss: 0.0158 - val_AUC: 0.8874 - val_accuracy: 0.8627 - val_loss: 0.8368\n",
            "Epoch 43/100\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - AUC: 0.9998 - accuracy: 0.9915 - loss: 0.0168 - val_AUC: 0.8872 - val_accuracy: 0.8627 - val_loss: 0.8397\n",
            "Epoch 44/100\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - AUC: 0.9997 - accuracy: 0.9834 - loss: 0.0188 - val_AUC: 0.8876 - val_accuracy: 0.8529 - val_loss: 0.8577\n",
            "Epoch 45/100\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - AUC: 0.9998 - accuracy: 0.9902 - loss: 0.0156 - val_AUC: 0.8890 - val_accuracy: 0.8627 - val_loss: 0.8638\n",
            "Epoch 46/100\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - AUC: 0.9999 - accuracy: 0.9887 - loss: 0.0183 - val_AUC: 0.8826 - val_accuracy: 0.8627 - val_loss: 0.8767\n",
            "Epoch 47/100\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - AUC: 0.9999 - accuracy: 0.9959 - loss: 0.0113 - val_AUC: 0.8828 - val_accuracy: 0.8627 - val_loss: 0.8907\n",
            "Epoch 48/100\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - AUC: 0.9998 - accuracy: 0.9888 - loss: 0.0171 - val_AUC: 0.8901 - val_accuracy: 0.8627 - val_loss: 0.9042\n",
            "Epoch 49/100\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - AUC: 0.9997 - accuracy: 0.9893 - loss: 0.0194 - val_AUC: 0.8754 - val_accuracy: 0.8627 - val_loss: 0.9217\n",
            "Epoch 50/100\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - AUC: 1.0000 - accuracy: 0.9974 - loss: 0.0093 - val_AUC: 0.8754 - val_accuracy: 0.8627 - val_loss: 0.9415\n",
            "Epoch 51/100\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - AUC: 0.9998 - accuracy: 0.9870 - loss: 0.0158 - val_AUC: 0.8754 - val_accuracy: 0.8627 - val_loss: 0.9575\n",
            "Epoch 52/100\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - AUC: 0.9999 - accuracy: 0.9897 - loss: 0.0124 - val_AUC: 0.8766 - val_accuracy: 0.8627 - val_loss: 0.9676\n",
            "Epoch 53/100\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - AUC: 0.9999 - accuracy: 0.9973 - loss: 0.0119 - val_AUC: 0.8754 - val_accuracy: 0.8627 - val_loss: 0.9797\n",
            "Epoch 54/100\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - AUC: 0.9999 - accuracy: 0.9954 - loss: 0.0097 - val_AUC: 0.8750 - val_accuracy: 0.8431 - val_loss: 0.9917\n",
            "Epoch 55/100\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - AUC: 1.0000 - accuracy: 0.9944 - loss: 0.0084 - val_AUC: 0.8781 - val_accuracy: 0.8627 - val_loss: 0.9811\n",
            "Epoch 56/100\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - AUC: 0.9998 - accuracy: 0.9903 - loss: 0.0158 - val_AUC: 0.8752 - val_accuracy: 0.8529 - val_loss: 0.9724\n",
            "Epoch 57/100\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - AUC: 0.9998 - accuracy: 0.9870 - loss: 0.0163 - val_AUC: 0.8766 - val_accuracy: 0.8627 - val_loss: 0.9630\n",
            "Epoch 58/100\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - AUC: 0.9999 - accuracy: 0.9903 - loss: 0.0135 - val_AUC: 0.8762 - val_accuracy: 0.8627 - val_loss: 0.9726\n",
            "Epoch 59/100\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - AUC: 0.9995 - accuracy: 0.9884 - loss: 0.0173 - val_AUC: 0.8774 - val_accuracy: 0.8529 - val_loss: 0.9851\n",
            "Epoch 60/100\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - AUC: 0.9999 - accuracy: 0.9939 - loss: 0.0099 - val_AUC: 0.8762 - val_accuracy: 0.8529 - val_loss: 0.9969\n",
            "Epoch 61/100\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - AUC: 0.9998 - accuracy: 0.9933 - loss: 0.0120 - val_AUC: 0.8774 - val_accuracy: 0.8529 - val_loss: 1.0115\n",
            "Epoch 62/100\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - AUC: 0.9999 - accuracy: 0.9930 - loss: 0.0116 - val_AUC: 0.8793 - val_accuracy: 0.8529 - val_loss: 1.0192\n",
            "Epoch 63/100\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - AUC: 0.9999 - accuracy: 0.9854 - loss: 0.0141 - val_AUC: 0.8778 - val_accuracy: 0.8529 - val_loss: 1.0308\n",
            "Epoch 64/100\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - AUC: 0.9999 - accuracy: 0.9884 - loss: 0.0191 - val_AUC: 0.8779 - val_accuracy: 0.8529 - val_loss: 1.0505\n",
            "Epoch 65/100\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - AUC: 0.9999 - accuracy: 0.9945 - loss: 0.0072 - val_AUC: 0.8781 - val_accuracy: 0.8529 - val_loss: 1.0509\n",
            "Epoch 66/100\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - AUC: 0.9999 - accuracy: 0.9956 - loss: 0.0093 - val_AUC: 0.8783 - val_accuracy: 0.8529 - val_loss: 1.0581\n",
            "Epoch 67/100\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - AUC: 0.9999 - accuracy: 0.9912 - loss: 0.0117 - val_AUC: 0.8789 - val_accuracy: 0.8529 - val_loss: 1.0451\n",
            "Epoch 68/100\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - AUC: 0.9995 - accuracy: 0.9907 - loss: 0.0152 - val_AUC: 0.8791 - val_accuracy: 0.8627 - val_loss: 1.0470\n",
            "Epoch 69/100\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - AUC: 0.9999 - accuracy: 0.9962 - loss: 0.0082 - val_AUC: 0.8793 - val_accuracy: 0.8529 - val_loss: 1.0553\n",
            "Epoch 70/100\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - AUC: 0.9999 - accuracy: 0.9911 - loss: 0.0120 - val_AUC: 0.8795 - val_accuracy: 0.8529 - val_loss: 1.0631\n",
            "Epoch 71/100\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - AUC: 0.9999 - accuracy: 0.9865 - loss: 0.0161 - val_AUC: 0.8797 - val_accuracy: 0.8627 - val_loss: 1.0607\n",
            "Epoch 72/100\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - AUC: 0.9997 - accuracy: 0.9793 - loss: 0.0219 - val_AUC: 0.8801 - val_accuracy: 0.8627 - val_loss: 1.0661\n",
            "Epoch 73/100\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - AUC: 1.0000 - accuracy: 0.9902 - loss: 0.0116 - val_AUC: 0.8797 - val_accuracy: 0.8627 - val_loss: 1.0697\n",
            "Epoch 74/100\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - AUC: 1.0000 - accuracy: 0.9976 - loss: 0.0078 - val_AUC: 0.8797 - val_accuracy: 0.8529 - val_loss: 1.0770\n",
            "Epoch 75/100\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - AUC: 1.0000 - accuracy: 0.9985 - loss: 0.0103 - val_AUC: 0.8820 - val_accuracy: 0.8725 - val_loss: 1.0596\n",
            "Epoch 76/100\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - AUC: 0.9999 - accuracy: 0.9875 - loss: 0.0140 - val_AUC: 0.8816 - val_accuracy: 0.8627 - val_loss: 1.0582\n",
            "Epoch 77/100\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - AUC: 0.9999 - accuracy: 0.9943 - loss: 0.0070 - val_AUC: 0.8820 - val_accuracy: 0.8627 - val_loss: 1.0683\n",
            "Epoch 78/100\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - AUC: 0.9999 - accuracy: 0.9970 - loss: 0.0084 - val_AUC: 0.8814 - val_accuracy: 0.8627 - val_loss: 1.0808\n",
            "Epoch 79/100\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - AUC: 0.9999 - accuracy: 0.9913 - loss: 0.0084 - val_AUC: 0.8745 - val_accuracy: 0.8627 - val_loss: 1.0942\n",
            "Epoch 80/100\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - AUC: 0.9999 - accuracy: 0.9950 - loss: 0.0090 - val_AUC: 0.8745 - val_accuracy: 0.8627 - val_loss: 1.1086\n",
            "Epoch 81/100\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - AUC: 1.0000 - accuracy: 0.9978 - loss: 0.0072 - val_AUC: 0.8743 - val_accuracy: 0.8529 - val_loss: 1.1181\n",
            "Epoch 82/100\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - AUC: 1.0000 - accuracy: 0.9956 - loss: 0.0074 - val_AUC: 0.8747 - val_accuracy: 0.8529 - val_loss: 1.1279\n",
            "Epoch 83/100\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - AUC: 0.9999 - accuracy: 0.9973 - loss: 0.0070 - val_AUC: 0.8743 - val_accuracy: 0.8529 - val_loss: 1.1357\n",
            "Epoch 84/100\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - AUC: 1.0000 - accuracy: 0.9985 - loss: 0.0051 - val_AUC: 0.8739 - val_accuracy: 0.8627 - val_loss: 1.1390\n",
            "Epoch 85/100\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - AUC: 0.9999 - accuracy: 0.9923 - loss: 0.0113 - val_AUC: 0.8739 - val_accuracy: 0.8627 - val_loss: 1.1433\n",
            "Epoch 86/100\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - AUC: 0.9999 - accuracy: 0.9963 - loss: 0.0043 - val_AUC: 0.8735 - val_accuracy: 0.8627 - val_loss: 1.1463\n",
            "Epoch 87/100\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - AUC: 1.0000 - accuracy: 0.9949 - loss: 0.0060 - val_AUC: 0.8739 - val_accuracy: 0.8529 - val_loss: 1.1503\n",
            "Epoch 88/100\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - AUC: 1.0000 - accuracy: 0.9977 - loss: 0.0059 - val_AUC: 0.8739 - val_accuracy: 0.8627 - val_loss: 1.1587\n",
            "Epoch 89/100\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - AUC: 1.0000 - accuracy: 0.9929 - loss: 0.0059 - val_AUC: 0.8739 - val_accuracy: 0.8627 - val_loss: 1.1647\n",
            "Epoch 90/100\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - AUC: 0.9999 - accuracy: 0.9815 - loss: 0.0150 - val_AUC: 0.8739 - val_accuracy: 0.8627 - val_loss: 1.1658\n",
            "Epoch 91/100\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - AUC: 1.0000 - accuracy: 0.9928 - loss: 0.0077 - val_AUC: 0.8739 - val_accuracy: 0.8627 - val_loss: 1.1726\n",
            "Epoch 92/100\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - AUC: 1.0000 - accuracy: 0.9993 - loss: 0.0057 - val_AUC: 0.8739 - val_accuracy: 0.8627 - val_loss: 1.1763\n",
            "Epoch 93/100\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - AUC: 1.0000 - accuracy: 0.9945 - loss: 0.0055 - val_AUC: 0.8739 - val_accuracy: 0.8627 - val_loss: 1.1845\n",
            "Epoch 94/100\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - AUC: 1.0000 - accuracy: 0.9968 - loss: 0.0034 - val_AUC: 0.8739 - val_accuracy: 0.8627 - val_loss: 1.1883\n",
            "Epoch 95/100\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - AUC: 1.0000 - accuracy: 0.9958 - loss: 0.0084 - val_AUC: 0.8739 - val_accuracy: 0.8627 - val_loss: 1.1927\n",
            "Epoch 96/100\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - AUC: 1.0000 - accuracy: 0.9900 - loss: 0.0090 - val_AUC: 0.8739 - val_accuracy: 0.8529 - val_loss: 1.2010\n",
            "Epoch 97/100\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - AUC: 0.9999 - accuracy: 0.9906 - loss: 0.0092 - val_AUC: 0.8739 - val_accuracy: 0.8627 - val_loss: 1.2043\n",
            "Epoch 98/100\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - AUC: 0.9999 - accuracy: 0.9870 - loss: 0.0118 - val_AUC: 0.8735 - val_accuracy: 0.8627 - val_loss: 1.2061\n",
            "Epoch 99/100\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - AUC: 1.0000 - accuracy: 0.9910 - loss: 0.0072 - val_AUC: 0.8735 - val_accuracy: 0.8627 - val_loss: 1.2118\n",
            "Epoch 100/100\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - AUC: 1.0000 - accuracy: 0.9983 - loss: 0.0053 - val_AUC: 0.8731 - val_accuracy: 0.8529 - val_loss: 1.2253\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - AUC: 0.8158 - accuracy: 0.8146 - loss: 1.6525\n",
            "Optimized Model Test Accuracy: 0.7812, AUC: 0.7814\n"
          ]
        }
      ],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, LSTM, Dropout, Reshape # Tambah Reshape\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "# Assume nBits is the size of your fingerprint (e.g., 1024)\n",
        "# Ini harus sama dengan ukuran fingerprint yang lu bikin pake RDKit\n",
        "nBits = 1024 # Sesuaikan dengan nBits yang lu pake di RDKit\n",
        "\n",
        "# Hyperparameters (sesuai kode lu, vocab_size dan embedding_dim nggak kepake lagi)\n",
        "# vocab_size = len(tokenizer.word_index) + 1 # Not needed\n",
        "# embedding_dim = 64 # Not needed\n",
        "units = [12] # Ukuran hidden state LSTM\n",
        "dropout_rate = 0.3\n",
        "learning_rate = 0.01\n",
        "\n",
        "# Build the model for Fingerprint input\n",
        "model_optimized_1 = Sequential()\n",
        "\n",
        "# Layer Input: Langsung terima vektor fingerprint\n",
        "# Bentuk inputnya adalah (panjang_fingerprint,)\n",
        "model_optimized_1.add(tf.keras.Input(shape=(nBits,))) # Define input shape\n",
        "\n",
        "# Tambahkan layer Reshape untuk mengubah (nBits,) menjadi (1, nBits)\n",
        "# Agar cocok dengan input shape LSTM yang butuh 3D (samples, timesteps, features)\n",
        "model_optimized_1.add(Reshape((1, nBits))) # Ubah (features,) jadi (1, features)\n",
        "\n",
        "# Layer LSTM: Sekarang inputnya udah 3D (samples, 1, nBits)\n",
        "# Return sequences False karena kita cuma punya 1 timestep dan mau output single vector\n",
        "model_optimized_1.add(LSTM(units[0], activation='tanh', recurrent_activation='sigmoid', return_sequences=True))\n",
        "model_optimized_1.add(LSTM(units[0], activation='tanh', recurrent_activation='sigmoid', return_sequences=True))\n",
        "model_optimized_1.add(LSTM(units[0], activation='tanh', recurrent_activation='sigmoid', return_sequences=False))\n",
        "model_optimized_1.add(Dropout(dropout_rate))\n",
        "\n",
        "# Layer Output: Dense dengan 1 unit dan activation sigmoid (kalau task-nya binary classification)\n",
        "# Kalau task-nya regresi, ganti activation jadi 'linear' atau jangan pakai activation\n",
        "model_optimized_1.add(Dense(1, activation='sigmoid')) # Ganti kalau task-nya regresi\n",
        "\n",
        "# Compile the model\n",
        "model_optimized_1.compile(optimizer=Adam(learning_rate=learning_rate),\n",
        "                        loss='binary_crossentropy',\n",
        "                        metrics=['accuracy', 'AUC'])\n",
        "\n",
        "model_optimized_1.summary() # Penting buat ngecek arsitektur dan shape\n",
        "\n",
        "# Train the model\n",
        "history_optimized_1 = model_optimized_1.fit(\n",
        "    X_train,\n",
        "    y_train,\n",
        "    validation_split=0.2,\n",
        "    epochs=100,\n",
        "    batch_size=32\n",
        ")\n",
        "\n",
        "# Evaluate the model\n",
        "loss, accuracy, auc = model_optimized_1.evaluate(X_test, y_test)\n",
        "print(f\"Optimized Model Test Accuracy: {accuracy:.4f}, AUC: {auc:.4f}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "id": "2687be02",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_3\"</span>\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1mModel: \"sequential_3\"\u001b[0m\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ reshape_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Reshape</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1024</span>)        │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ lstm_6 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)         │       <span style=\"color: #00af00; text-decoration-color: #00af00\">590,336</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ lstm_7 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)         │       <span style=\"color: #00af00; text-decoration-color: #00af00\">131,584</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ lstm_8 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │       <span style=\"color: #00af00; text-decoration-color: #00af00\">131,584</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dropout_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)              │           <span style=\"color: #00af00; text-decoration-color: #00af00\">129</span> │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
              "</pre>\n"
            ],
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ reshape_3 (\u001b[38;5;33mReshape\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m1024\u001b[0m)        │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ lstm_6 (\u001b[38;5;33mLSTM\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m128\u001b[0m)         │       \u001b[38;5;34m590,336\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ lstm_7 (\u001b[38;5;33mLSTM\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m128\u001b[0m)         │       \u001b[38;5;34m131,584\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ lstm_8 (\u001b[38;5;33mLSTM\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │       \u001b[38;5;34m131,584\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dropout_2 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_2 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)              │           \u001b[38;5;34m129\u001b[0m │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">853,633</span> (3.26 MB)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m853,633\u001b[0m (3.26 MB)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">853,633</span> (3.26 MB)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m853,633\u001b[0m (3.26 MB)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 78ms/step - AUC: 0.5288 - accuracy: 0.5415 - loss: 0.6913 - val_AUC: 0.8772 - val_accuracy: 0.8039 - val_loss: 0.5678\n",
            "Epoch 2/100\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - AUC: 0.8509 - accuracy: 0.7857 - loss: 0.6964 - val_AUC: 0.8845 - val_accuracy: 0.7059 - val_loss: 0.5692\n",
            "Epoch 3/100\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - AUC: 0.9217 - accuracy: 0.7892 - loss: 0.4584 - val_AUC: 0.9054 - val_accuracy: 0.8235 - val_loss: 0.4399\n",
            "Epoch 4/100\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - AUC: 0.9422 - accuracy: 0.8727 - loss: 0.3281 - val_AUC: 0.8990 - val_accuracy: 0.7843 - val_loss: 0.4637\n",
            "Epoch 5/100\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - AUC: 0.9669 - accuracy: 0.8935 - loss: 0.2342 - val_AUC: 0.8925 - val_accuracy: 0.8431 - val_loss: 0.9807\n",
            "Epoch 6/100\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - AUC: 0.9690 - accuracy: 0.9023 - loss: 0.2730 - val_AUC: 0.8930 - val_accuracy: 0.8235 - val_loss: 0.5455\n",
            "Epoch 7/100\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - AUC: 0.9694 - accuracy: 0.9092 - loss: 0.2188 - val_AUC: 0.9147 - val_accuracy: 0.8725 - val_loss: 0.7610\n",
            "Epoch 8/100\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - AUC: 0.9688 - accuracy: 0.8867 - loss: 0.2509 - val_AUC: 0.8749 - val_accuracy: 0.8529 - val_loss: 1.3713\n",
            "Epoch 9/100\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - AUC: 0.9797 - accuracy: 0.9217 - loss: 0.2335 - val_AUC: 0.8743 - val_accuracy: 0.7843 - val_loss: 0.9827\n",
            "Epoch 10/100\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - AUC: 0.9788 - accuracy: 0.9021 - loss: 0.1901 - val_AUC: 0.9074 - val_accuracy: 0.8333 - val_loss: 0.5404\n",
            "Epoch 11/100\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - AUC: 0.9829 - accuracy: 0.9221 - loss: 0.1786 - val_AUC: 0.9056 - val_accuracy: 0.8431 - val_loss: 0.7901\n",
            "Epoch 12/100\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - AUC: 0.9909 - accuracy: 0.9372 - loss: 0.1168 - val_AUC: 0.9072 - val_accuracy: 0.8529 - val_loss: 0.9520\n",
            "Epoch 13/100\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - AUC: 0.9933 - accuracy: 0.9419 - loss: 0.1011 - val_AUC: 0.8810 - val_accuracy: 0.8333 - val_loss: 1.2882\n",
            "Epoch 14/100\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - AUC: 0.9949 - accuracy: 0.9446 - loss: 0.0890 - val_AUC: 0.8807 - val_accuracy: 0.8137 - val_loss: 1.5938\n",
            "Epoch 15/100\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - AUC: 0.9949 - accuracy: 0.9592 - loss: 0.0869 - val_AUC: 0.8702 - val_accuracy: 0.8039 - val_loss: 1.8484\n",
            "Epoch 16/100\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - AUC: 0.9935 - accuracy: 0.9525 - loss: 0.0949 - val_AUC: 0.8634 - val_accuracy: 0.8235 - val_loss: 2.0368\n",
            "Epoch 17/100\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - AUC: 0.9977 - accuracy: 0.9579 - loss: 0.0704 - val_AUC: 0.8872 - val_accuracy: 0.8333 - val_loss: 1.6951\n",
            "Epoch 18/100\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - AUC: 0.9935 - accuracy: 0.9684 - loss: 0.1113 - val_AUC: 0.8834 - val_accuracy: 0.8235 - val_loss: 1.8748\n",
            "Epoch 19/100\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - AUC: 0.9983 - accuracy: 0.9778 - loss: 0.0519 - val_AUC: 0.8721 - val_accuracy: 0.8235 - val_loss: 2.0940\n",
            "Epoch 20/100\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - AUC: 0.9921 - accuracy: 0.9692 - loss: 0.1171 - val_AUC: 0.8607 - val_accuracy: 0.8333 - val_loss: 2.5200\n",
            "Epoch 21/100\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - AUC: 0.9887 - accuracy: 0.9634 - loss: 0.1471 - val_AUC: 0.8640 - val_accuracy: 0.8529 - val_loss: 2.4478\n",
            "Epoch 22/100\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - AUC: 0.9989 - accuracy: 0.9792 - loss: 0.0518 - val_AUC: 0.8549 - val_accuracy: 0.8333 - val_loss: 2.5022\n",
            "Epoch 23/100\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - AUC: 0.9992 - accuracy: 0.9782 - loss: 0.0408 - val_AUC: 0.8776 - val_accuracy: 0.8431 - val_loss: 2.5310\n",
            "Epoch 24/100\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - AUC: 0.9884 - accuracy: 0.9686 - loss: 0.2777 - val_AUC: 0.8772 - val_accuracy: 0.8137 - val_loss: 1.5696\n",
            "Epoch 25/100\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - AUC: 0.9992 - accuracy: 0.9768 - loss: 0.0393 - val_AUC: 0.8737 - val_accuracy: 0.8235 - val_loss: 1.6528\n",
            "Epoch 26/100\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - AUC: 0.9985 - accuracy: 0.9735 - loss: 0.0379 - val_AUC: 0.8706 - val_accuracy: 0.8333 - val_loss: 1.9051\n",
            "Epoch 27/100\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - AUC: 0.9995 - accuracy: 0.9851 - loss: 0.0294 - val_AUC: 0.8694 - val_accuracy: 0.8333 - val_loss: 2.1172\n",
            "Epoch 28/100\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - AUC: 0.9995 - accuracy: 0.9812 - loss: 0.0294 - val_AUC: 0.8694 - val_accuracy: 0.8137 - val_loss: 2.2334\n",
            "Epoch 29/100\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - AUC: 0.9997 - accuracy: 0.9846 - loss: 0.0253 - val_AUC: 0.8640 - val_accuracy: 0.8039 - val_loss: 2.5247\n",
            "Epoch 30/100\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - AUC: 0.9995 - accuracy: 0.9807 - loss: 0.0262 - val_AUC: 0.8559 - val_accuracy: 0.8039 - val_loss: 2.5420\n",
            "Epoch 31/100\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - AUC: 0.9997 - accuracy: 0.9834 - loss: 0.0248 - val_AUC: 0.8652 - val_accuracy: 0.8039 - val_loss: 2.4834\n",
            "Epoch 32/100\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - AUC: 0.9996 - accuracy: 0.9846 - loss: 0.0237 - val_AUC: 0.8557 - val_accuracy: 0.8039 - val_loss: 2.4687\n",
            "Epoch 33/100\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - AUC: 0.9996 - accuracy: 0.9846 - loss: 0.0234 - val_AUC: 0.8561 - val_accuracy: 0.7941 - val_loss: 2.5244\n",
            "Epoch 34/100\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - AUC: 0.9996 - accuracy: 0.9820 - loss: 0.0238 - val_AUC: 0.8563 - val_accuracy: 0.7941 - val_loss: 2.6055\n",
            "Epoch 35/100\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - AUC: 0.9997 - accuracy: 0.9820 - loss: 0.0245 - val_AUC: 0.8578 - val_accuracy: 0.7941 - val_loss: 2.6350\n",
            "Epoch 36/100\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - AUC: 0.9996 - accuracy: 0.9846 - loss: 0.0229 - val_AUC: 0.8516 - val_accuracy: 0.7941 - val_loss: 2.7682\n",
            "Epoch 37/100\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - AUC: 0.9996 - accuracy: 0.9820 - loss: 0.0230 - val_AUC: 0.8524 - val_accuracy: 0.7941 - val_loss: 2.8026\n",
            "Epoch 38/100\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - AUC: 0.9998 - accuracy: 0.9851 - loss: 0.0225 - val_AUC: 0.8393 - val_accuracy: 0.8137 - val_loss: 3.0455\n",
            "Epoch 39/100\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - AUC: 0.9995 - accuracy: 0.9813 - loss: 0.0256 - val_AUC: 0.8725 - val_accuracy: 0.8333 - val_loss: 2.6128\n",
            "Epoch 40/100\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - AUC: 0.9998 - accuracy: 0.9839 - loss: 0.0212 - val_AUC: 0.8710 - val_accuracy: 0.8235 - val_loss: 2.5491\n",
            "Epoch 41/100\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - AUC: 0.9998 - accuracy: 0.9839 - loss: 0.0214 - val_AUC: 0.8700 - val_accuracy: 0.8137 - val_loss: 2.5880\n",
            "Epoch 42/100\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - AUC: 0.9998 - accuracy: 0.9851 - loss: 0.0194 - val_AUC: 0.8675 - val_accuracy: 0.8137 - val_loss: 2.6587\n",
            "Epoch 43/100\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - AUC: 0.9998 - accuracy: 0.9851 - loss: 0.0184 - val_AUC: 0.8671 - val_accuracy: 0.8137 - val_loss: 2.7391\n",
            "Epoch 44/100\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - AUC: 0.9999 - accuracy: 0.9851 - loss: 0.0165 - val_AUC: 0.8596 - val_accuracy: 0.8039 - val_loss: 2.8487\n",
            "Epoch 45/100\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - AUC: 1.0000 - accuracy: 0.9920 - loss: 0.0123 - val_AUC: 0.8584 - val_accuracy: 0.8039 - val_loss: 2.9845\n",
            "Epoch 46/100\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - AUC: 0.9949 - accuracy: 0.9814 - loss: 0.0607 - val_AUC: 0.8723 - val_accuracy: 0.8333 - val_loss: 2.9230\n",
            "Epoch 47/100\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - AUC: 0.9964 - accuracy: 0.9809 - loss: 0.0637 - val_AUC: 0.8797 - val_accuracy: 0.8235 - val_loss: 2.2960\n",
            "Epoch 48/100\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - AUC: 0.9992 - accuracy: 0.9757 - loss: 0.0369 - val_AUC: 0.8640 - val_accuracy: 0.8431 - val_loss: 2.4993\n",
            "Epoch 49/100\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - AUC: 0.9996 - accuracy: 0.9848 - loss: 0.0267 - val_AUC: 0.8540 - val_accuracy: 0.8431 - val_loss: 2.9710\n",
            "Epoch 50/100\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - AUC: 0.9995 - accuracy: 0.9839 - loss: 0.0237 - val_AUC: 0.8706 - val_accuracy: 0.8333 - val_loss: 2.2387\n",
            "Epoch 51/100\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - AUC: 0.9948 - accuracy: 0.9839 - loss: 0.0546 - val_AUC: 0.8776 - val_accuracy: 0.8627 - val_loss: 2.8518\n",
            "Epoch 52/100\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - AUC: 0.9881 - accuracy: 0.9684 - loss: 0.1180 - val_AUC: 0.8557 - val_accuracy: 0.7941 - val_loss: 2.4500\n",
            "Epoch 53/100\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - AUC: 0.9941 - accuracy: 0.9600 - loss: 0.1912 - val_AUC: 0.8731 - val_accuracy: 0.8235 - val_loss: 1.3392\n",
            "Epoch 54/100\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - AUC: 0.9951 - accuracy: 0.9570 - loss: 0.0893 - val_AUC: 0.8832 - val_accuracy: 0.8431 - val_loss: 1.4259\n",
            "Epoch 55/100\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - AUC: 0.9868 - accuracy: 0.9325 - loss: 0.2296 - val_AUC: 0.8851 - val_accuracy: 0.8235 - val_loss: 1.8166\n",
            "Epoch 56/100\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - AUC: 0.9821 - accuracy: 0.9305 - loss: 0.2088 - val_AUC: 0.8439 - val_accuracy: 0.7353 - val_loss: 1.8599\n",
            "Epoch 57/100\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - AUC: 0.9748 - accuracy: 0.9290 - loss: 0.3491 - val_AUC: 0.8799 - val_accuracy: 0.8039 - val_loss: 0.8890\n",
            "Epoch 58/100\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - AUC: 0.9861 - accuracy: 0.9464 - loss: 0.1661 - val_AUC: 0.8561 - val_accuracy: 0.8235 - val_loss: 2.2909\n",
            "Epoch 59/100\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - AUC: 0.9847 - accuracy: 0.9482 - loss: 0.2199 - val_AUC: 0.8783 - val_accuracy: 0.8137 - val_loss: 1.8429\n",
            "Epoch 60/100\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - AUC: 0.9880 - accuracy: 0.9299 - loss: 0.1327 - val_AUC: 0.8667 - val_accuracy: 0.7941 - val_loss: 1.8304\n",
            "Epoch 61/100\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - AUC: 0.9889 - accuracy: 0.9491 - loss: 0.1322 - val_AUC: 0.8741 - val_accuracy: 0.8235 - val_loss: 3.5744\n",
            "Epoch 62/100\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - AUC: 0.9360 - accuracy: 0.8961 - loss: 0.8287 - val_AUC: 0.8961 - val_accuracy: 0.8039 - val_loss: 0.6843\n",
            "Epoch 63/100\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - AUC: 0.9853 - accuracy: 0.9411 - loss: 0.1771 - val_AUC: 0.8646 - val_accuracy: 0.8137 - val_loss: 1.4471\n",
            "Epoch 64/100\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - AUC: 0.9810 - accuracy: 0.9497 - loss: 0.3052 - val_AUC: 0.8696 - val_accuracy: 0.8039 - val_loss: 1.2950\n",
            "Epoch 65/100\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - AUC: 0.9922 - accuracy: 0.9485 - loss: 0.1196 - val_AUC: 0.8491 - val_accuracy: 0.7941 - val_loss: 2.0263\n",
            "Epoch 66/100\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - AUC: 0.9944 - accuracy: 0.9662 - loss: 0.1585 - val_AUC: 0.8193 - val_accuracy: 0.8039 - val_loss: 2.3481\n",
            "Epoch 67/100\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - AUC: 0.9870 - accuracy: 0.9648 - loss: 0.1435 - val_AUC: 0.8760 - val_accuracy: 0.8137 - val_loss: 1.3401\n",
            "Epoch 68/100\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - AUC: 0.9951 - accuracy: 0.9603 - loss: 0.0864 - val_AUC: 0.8710 - val_accuracy: 0.8137 - val_loss: 1.1671\n",
            "Epoch 69/100\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - AUC: 0.9959 - accuracy: 0.9323 - loss: 0.1068 - val_AUC: 0.8855 - val_accuracy: 0.8529 - val_loss: 1.3828\n",
            "Epoch 70/100\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - AUC: 0.9981 - accuracy: 0.9486 - loss: 0.0670 - val_AUC: 0.8727 - val_accuracy: 0.8039 - val_loss: 1.8235\n",
            "Epoch 71/100\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - AUC: 0.9992 - accuracy: 0.9617 - loss: 0.0492 - val_AUC: 0.8739 - val_accuracy: 0.8137 - val_loss: 2.0214\n",
            "Epoch 72/100\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - AUC: 0.9991 - accuracy: 0.9681 - loss: 0.0475 - val_AUC: 0.8781 - val_accuracy: 0.8137 - val_loss: 2.2705\n",
            "Epoch 73/100\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - AUC: 0.9984 - accuracy: 0.9732 - loss: 0.0417 - val_AUC: 0.8588 - val_accuracy: 0.7941 - val_loss: 2.4341\n",
            "Epoch 74/100\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - AUC: 0.9989 - accuracy: 0.9677 - loss: 0.0493 - val_AUC: 0.8596 - val_accuracy: 0.8039 - val_loss: 2.4755\n",
            "Epoch 75/100\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - AUC: 0.9894 - accuracy: 0.9513 - loss: 0.2675 - val_AUC: 0.8559 - val_accuracy: 0.7941 - val_loss: 1.9350\n",
            "Epoch 76/100\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - AUC: 0.9960 - accuracy: 0.9350 - loss: 0.0799 - val_AUC: 0.8694 - val_accuracy: 0.8039 - val_loss: 1.9267\n",
            "Epoch 77/100\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - AUC: 0.9968 - accuracy: 0.9699 - loss: 0.0771 - val_AUC: 0.8708 - val_accuracy: 0.7941 - val_loss: 2.0322\n",
            "Epoch 78/100\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - AUC: 0.9980 - accuracy: 0.9747 - loss: 0.0626 - val_AUC: 0.8669 - val_accuracy: 0.8235 - val_loss: 2.3200\n",
            "Epoch 79/100\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - AUC: 0.9976 - accuracy: 0.9666 - loss: 0.0629 - val_AUC: 0.8623 - val_accuracy: 0.7941 - val_loss: 2.4314\n",
            "Epoch 80/100\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - AUC: 0.9961 - accuracy: 0.9509 - loss: 0.0813 - val_AUC: 0.8573 - val_accuracy: 0.8137 - val_loss: 2.7287\n",
            "Epoch 81/100\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - AUC: 0.9984 - accuracy: 0.9755 - loss: 0.0565 - val_AUC: 0.8478 - val_accuracy: 0.8137 - val_loss: 2.9634\n",
            "Epoch 82/100\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - AUC: 0.9986 - accuracy: 0.9831 - loss: 0.0516 - val_AUC: 0.8557 - val_accuracy: 0.8137 - val_loss: 3.1090\n",
            "Epoch 83/100\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - AUC: 0.9986 - accuracy: 0.9787 - loss: 0.0473 - val_AUC: 0.8557 - val_accuracy: 0.8137 - val_loss: 3.1419\n",
            "Epoch 84/100\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - AUC: 0.9992 - accuracy: 0.9817 - loss: 0.0361 - val_AUC: 0.8520 - val_accuracy: 0.8235 - val_loss: 3.2346\n",
            "Epoch 85/100\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - AUC: 0.9994 - accuracy: 0.9824 - loss: 0.0320 - val_AUC: 0.8538 - val_accuracy: 0.8235 - val_loss: 3.3026\n",
            "Epoch 86/100\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - AUC: 0.9933 - accuracy: 0.9670 - loss: 0.0926 - val_AUC: 0.8530 - val_accuracy: 0.8137 - val_loss: 3.4040\n",
            "Epoch 87/100\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - AUC: 0.9968 - accuracy: 0.9555 - loss: 0.0656 - val_AUC: 0.8501 - val_accuracy: 0.8333 - val_loss: 3.3939\n",
            "Epoch 88/100\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - AUC: 0.9963 - accuracy: 0.9517 - loss: 0.0606 - val_AUC: 0.8478 - val_accuracy: 0.8333 - val_loss: 3.4205\n",
            "Epoch 89/100\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - AUC: 0.9964 - accuracy: 0.9682 - loss: 0.0575 - val_AUC: 0.8478 - val_accuracy: 0.8333 - val_loss: 3.4401\n",
            "Epoch 90/100\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - AUC: 0.9977 - accuracy: 0.9670 - loss: 0.0563 - val_AUC: 0.8474 - val_accuracy: 0.8333 - val_loss: 3.4953\n",
            "Epoch 91/100\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - AUC: 0.9972 - accuracy: 0.9567 - loss: 0.0588 - val_AUC: 0.8443 - val_accuracy: 0.8235 - val_loss: 3.5241\n",
            "Epoch 92/100\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - AUC: 0.9977 - accuracy: 0.9504 - loss: 0.0592 - val_AUC: 0.8443 - val_accuracy: 0.8137 - val_loss: 3.5583\n",
            "Epoch 93/100\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - AUC: 0.9981 - accuracy: 0.9513 - loss: 0.0593 - val_AUC: 0.8462 - val_accuracy: 0.8431 - val_loss: 3.5912\n",
            "Epoch 94/100\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - AUC: 0.9977 - accuracy: 0.9614 - loss: 0.0615 - val_AUC: 0.8451 - val_accuracy: 0.8235 - val_loss: 3.6261\n",
            "Epoch 95/100\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - AUC: 0.9984 - accuracy: 0.9535 - loss: 0.0587 - val_AUC: 0.8441 - val_accuracy: 0.8039 - val_loss: 3.6921\n",
            "Epoch 96/100\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - AUC: 0.9969 - accuracy: 0.9556 - loss: 0.0643 - val_AUC: 0.8524 - val_accuracy: 0.8039 - val_loss: 3.3527\n",
            "Epoch 97/100\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - AUC: 0.9969 - accuracy: 0.9650 - loss: 0.0619 - val_AUC: 0.8540 - val_accuracy: 0.8235 - val_loss: 3.4813\n",
            "Epoch 98/100\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - AUC: 0.9924 - accuracy: 0.9533 - loss: 0.0892 - val_AUC: 0.8547 - val_accuracy: 0.8235 - val_loss: 2.8281\n",
            "Epoch 99/100\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - AUC: 0.9942 - accuracy: 0.9626 - loss: 0.0749 - val_AUC: 0.8598 - val_accuracy: 0.8235 - val_loss: 2.4235\n",
            "Epoch 100/100\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - AUC: 0.9971 - accuracy: 0.9607 - loss: 0.0614 - val_AUC: 0.8615 - val_accuracy: 0.8235 - val_loss: 2.4405\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - AUC: 0.8711 - accuracy: 0.7677 - loss: 3.0774\n",
            "Optimized Model Test Accuracy: 0.7500, AUC: 0.8386\n"
          ]
        }
      ],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, LSTM, Dropout, Reshape\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "\n",
        "nBits = 1024\n",
        "units = [128]\n",
        "dropout_rate = 0.5\n",
        "learning_rate = 0.01\n",
        "\n",
        "model_optimized_swish = Sequential()\n",
        "model_optimized_swish.add(tf.keras.Input(shape=(nBits,)))\n",
        "model_optimized_swish.add(Reshape((1, nBits)))\n",
        "\n",
        "# Layer LSTM dengan Swish activation\n",
        "model_optimized_swish.add(LSTM(units[0], activation=tf.keras.activations.swish, recurrent_activation='sigmoid', return_sequences=True))\n",
        "model_optimized_swish.add(LSTM(units[0], activation=tf.keras.activations.swish, recurrent_activation='sigmoid', return_sequences=True))\n",
        "model_optimized_swish.add(LSTM(units[0], activation=tf.keras.activations.swish, recurrent_activation='sigmoid', return_sequences=False))\n",
        "model_optimized_swish.add(Dropout(dropout_rate))\n",
        "\n",
        "model_optimized_swish.add(Dense(1, activation='sigmoid'))\n",
        "\n",
        "model_optimized_swish.compile(optimizer=Adam(learning_rate=learning_rate),\n",
        "                              loss='binary_crossentropy',\n",
        "                              metrics=['accuracy', 'AUC'])\n",
        "\n",
        "model_optimized_swish.summary()\n",
        "\n",
        "history_optimized_swish = model_optimized_swish.fit(\n",
        "    X_train,\n",
        "    y_train,\n",
        "    validation_split=0.2,\n",
        "    epochs=100,\n",
        "    batch_size=32\n",
        ")\n",
        "\n",
        "\n",
        "# Evaluate the model\n",
        "loss, accuracy, auc = model_optimized_swish.evaluate(X_test, y_test)\n",
        "print(f\"Optimized Model Test Accuracy: {accuracy:.4f}, AUC: {auc:.4f}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "id": "1aa14f9a",
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\Dito Adistya\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\layers\\activations\\leaky_relu.py:41: UserWarning: Argument `alpha` is deprecated. Use `negative_slope` instead.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_7\"</span>\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1mModel: \"sequential_7\"\u001b[0m\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ reshape_7 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Reshape</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1024</span>)        │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ lstm_18 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)          │       <span style=\"color: #00af00; text-decoration-color: #00af00\">135,296</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ leaky_re_lu_6 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LeakyReLU</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)          │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ lstm_19 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">8,320</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ leaky_re_lu_7 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LeakyReLU</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)             │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dropout_6 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)             │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_6 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)              │            <span style=\"color: #00af00; text-decoration-color: #00af00\">33</span> │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
              "</pre>\n"
            ],
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ reshape_7 (\u001b[38;5;33mReshape\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m1024\u001b[0m)        │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ lstm_18 (\u001b[38;5;33mLSTM\u001b[0m)                  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m32\u001b[0m)          │       \u001b[38;5;34m135,296\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ leaky_re_lu_6 (\u001b[38;5;33mLeakyReLU\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m32\u001b[0m)          │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ lstm_19 (\u001b[38;5;33mLSTM\u001b[0m)                  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)             │         \u001b[38;5;34m8,320\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ leaky_re_lu_7 (\u001b[38;5;33mLeakyReLU\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)             │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dropout_6 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)             │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_6 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)              │            \u001b[38;5;34m33\u001b[0m │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">143,649</span> (561.13 KB)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m143,649\u001b[0m (561.13 KB)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">143,649</span> (561.13 KB)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m143,649\u001b[0m (561.13 KB)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 53ms/step - AUC: 0.5619 - accuracy: 0.5622 - loss: 0.6916 - val_AUC: 0.8240 - val_accuracy: 0.6667 - val_loss: 0.6864\n",
            "Epoch 2/100\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - AUC: 0.8649 - accuracy: 0.7149 - loss: 0.6790 - val_AUC: 0.8524 - val_accuracy: 0.7059 - val_loss: 0.6693\n",
            "Epoch 3/100\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - AUC: 0.8868 - accuracy: 0.7737 - loss: 0.6502 - val_AUC: 0.8787 - val_accuracy: 0.7647 - val_loss: 0.6305\n",
            "Epoch 4/100\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - AUC: 0.8960 - accuracy: 0.8009 - loss: 0.6020 - val_AUC: 0.8882 - val_accuracy: 0.8333 - val_loss: 0.5722\n",
            "Epoch 5/100\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - AUC: 0.9354 - accuracy: 0.8700 - loss: 0.5195 - val_AUC: 0.8950 - val_accuracy: 0.8333 - val_loss: 0.5076\n",
            "Epoch 6/100\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 52ms/step - AUC: 0.9353 - accuracy: 0.8861 - loss: 0.4378 - val_AUC: 0.8986 - val_accuracy: 0.8333 - val_loss: 0.4527\n",
            "Epoch 7/100\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - AUC: 0.9458 - accuracy: 0.8815 - loss: 0.3766 - val_AUC: 0.9037 - val_accuracy: 0.8627 - val_loss: 0.4111\n",
            "Epoch 8/100\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - AUC: 0.9618 - accuracy: 0.9053 - loss: 0.3198 - val_AUC: 0.9116 - val_accuracy: 0.8529 - val_loss: 0.3891\n",
            "Epoch 9/100\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - AUC: 0.9658 - accuracy: 0.9174 - loss: 0.2776 - val_AUC: 0.9145 - val_accuracy: 0.8627 - val_loss: 0.3647\n",
            "Epoch 10/100\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - AUC: 0.9697 - accuracy: 0.9310 - loss: 0.2459 - val_AUC: 0.9238 - val_accuracy: 0.8627 - val_loss: 0.3676\n",
            "Epoch 11/100\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - AUC: 0.9873 - accuracy: 0.9467 - loss: 0.1945 - val_AUC: 0.9242 - val_accuracy: 0.8725 - val_loss: 0.3536\n",
            "Epoch 12/100\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - AUC: 0.9793 - accuracy: 0.9300 - loss: 0.2049 - val_AUC: 0.9273 - val_accuracy: 0.8529 - val_loss: 0.3509\n",
            "Epoch 13/100\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - AUC: 0.9812 - accuracy: 0.9461 - loss: 0.1827 - val_AUC: 0.9263 - val_accuracy: 0.8431 - val_loss: 0.3594\n",
            "Epoch 14/100\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - AUC: 0.9897 - accuracy: 0.9446 - loss: 0.1657 - val_AUC: 0.9226 - val_accuracy: 0.8431 - val_loss: 0.3795\n",
            "Epoch 15/100\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - AUC: 0.9881 - accuracy: 0.9427 - loss: 0.1564 - val_AUC: 0.9226 - val_accuracy: 0.8431 - val_loss: 0.3763\n",
            "Epoch 16/100\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - AUC: 0.9844 - accuracy: 0.9549 - loss: 0.1491 - val_AUC: 0.9205 - val_accuracy: 0.8333 - val_loss: 0.4025\n",
            "Epoch 17/100\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - AUC: 0.9961 - accuracy: 0.9548 - loss: 0.1206 - val_AUC: 0.9151 - val_accuracy: 0.8333 - val_loss: 0.4165\n",
            "Epoch 18/100\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - AUC: 0.9973 - accuracy: 0.9672 - loss: 0.1089 - val_AUC: 0.9161 - val_accuracy: 0.8333 - val_loss: 0.4238\n",
            "Epoch 19/100\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - AUC: 0.9970 - accuracy: 0.9692 - loss: 0.1041 - val_AUC: 0.9124 - val_accuracy: 0.8333 - val_loss: 0.4543\n",
            "Epoch 20/100\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - AUC: 0.9980 - accuracy: 0.9727 - loss: 0.0831 - val_AUC: 0.9112 - val_accuracy: 0.8137 - val_loss: 0.4765\n",
            "Epoch 21/100\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - AUC: 0.9986 - accuracy: 0.9796 - loss: 0.0852 - val_AUC: 0.9124 - val_accuracy: 0.8137 - val_loss: 0.4958\n",
            "Epoch 22/100\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - AUC: 0.9992 - accuracy: 0.9825 - loss: 0.0747 - val_AUC: 0.9074 - val_accuracy: 0.8039 - val_loss: 0.5214\n",
            "Epoch 23/100\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - AUC: 0.9969 - accuracy: 0.9660 - loss: 0.0858 - val_AUC: 0.9039 - val_accuracy: 0.7843 - val_loss: 0.5402\n",
            "Epoch 24/100\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - AUC: 0.9987 - accuracy: 0.9778 - loss: 0.0749 - val_AUC: 0.9046 - val_accuracy: 0.8039 - val_loss: 0.5605\n",
            "Epoch 25/100\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - AUC: 0.9986 - accuracy: 0.9789 - loss: 0.0692 - val_AUC: 0.9097 - val_accuracy: 0.7941 - val_loss: 0.5656\n",
            "Epoch 26/100\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - AUC: 0.9995 - accuracy: 0.9850 - loss: 0.0581 - val_AUC: 0.9058 - val_accuracy: 0.8137 - val_loss: 0.5799\n",
            "Epoch 27/100\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - AUC: 0.9995 - accuracy: 0.9865 - loss: 0.0545 - val_AUC: 0.9048 - val_accuracy: 0.8039 - val_loss: 0.5928\n",
            "Epoch 28/100\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - AUC: 0.9997 - accuracy: 0.9866 - loss: 0.0532 - val_AUC: 0.9048 - val_accuracy: 0.8137 - val_loss: 0.6128\n",
            "Epoch 29/100\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - AUC: 0.9999 - accuracy: 0.9927 - loss: 0.0440 - val_AUC: 0.9006 - val_accuracy: 0.8137 - val_loss: 0.6278\n",
            "Epoch 30/100\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - AUC: 0.9995 - accuracy: 0.9866 - loss: 0.0487 - val_AUC: 0.8948 - val_accuracy: 0.7941 - val_loss: 0.6381\n",
            "Epoch 31/100\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - AUC: 0.9999 - accuracy: 0.9950 - loss: 0.0410 - val_AUC: 0.8957 - val_accuracy: 0.7941 - val_loss: 0.6473\n",
            "Epoch 32/100\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - AUC: 0.9998 - accuracy: 0.9930 - loss: 0.0403 - val_AUC: 0.8973 - val_accuracy: 0.8039 - val_loss: 0.6676\n",
            "Epoch 33/100\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - AUC: 0.9990 - accuracy: 0.9833 - loss: 0.0490 - val_AUC: 0.9000 - val_accuracy: 0.7843 - val_loss: 0.6734\n",
            "Epoch 34/100\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - AUC: 0.9994 - accuracy: 0.9785 - loss: 0.0475 - val_AUC: 0.9019 - val_accuracy: 0.8039 - val_loss: 0.6800\n",
            "Epoch 35/100\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - AUC: 0.9998 - accuracy: 0.9925 - loss: 0.0343 - val_AUC: 0.9014 - val_accuracy: 0.7941 - val_loss: 0.6971\n",
            "Epoch 36/100\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - AUC: 1.0000 - accuracy: 0.9905 - loss: 0.0317 - val_AUC: 0.9015 - val_accuracy: 0.7941 - val_loss: 0.7041\n",
            "Epoch 37/100\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - AUC: 0.9998 - accuracy: 0.9901 - loss: 0.0319 - val_AUC: 0.8940 - val_accuracy: 0.8039 - val_loss: 0.7229\n",
            "Epoch 38/100\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - AUC: 0.9999 - accuracy: 0.9953 - loss: 0.0298 - val_AUC: 0.8899 - val_accuracy: 0.7941 - val_loss: 0.7334\n",
            "Epoch 39/100\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - AUC: 0.9998 - accuracy: 0.9852 - loss: 0.0313 - val_AUC: 0.8845 - val_accuracy: 0.7941 - val_loss: 0.7421\n",
            "Epoch 40/100\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - AUC: 0.9998 - accuracy: 0.9844 - loss: 0.0329 - val_AUC: 0.8836 - val_accuracy: 0.7941 - val_loss: 0.7689\n",
            "Epoch 41/100\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - AUC: 0.9999 - accuracy: 0.9941 - loss: 0.0285 - val_AUC: 0.8859 - val_accuracy: 0.7941 - val_loss: 0.7664\n",
            "Epoch 42/100\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - AUC: 0.9999 - accuracy: 0.9909 - loss: 0.0260 - val_AUC: 0.8870 - val_accuracy: 0.7843 - val_loss: 0.7702\n",
            "Epoch 43/100\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - AUC: 0.9997 - accuracy: 0.9794 - loss: 0.0344 - val_AUC: 0.8834 - val_accuracy: 0.7843 - val_loss: 0.7882\n",
            "Epoch 44/100\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - AUC: 0.9998 - accuracy: 0.9843 - loss: 0.0273 - val_AUC: 0.8853 - val_accuracy: 0.7843 - val_loss: 0.8009\n",
            "Epoch 45/100\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - AUC: 0.9999 - accuracy: 0.9953 - loss: 0.0254 - val_AUC: 0.8878 - val_accuracy: 0.8039 - val_loss: 0.7902\n",
            "Epoch 46/100\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - AUC: 0.9999 - accuracy: 0.9870 - loss: 0.0275 - val_AUC: 0.8847 - val_accuracy: 0.7843 - val_loss: 0.8204\n",
            "Epoch 47/100\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - AUC: 0.9998 - accuracy: 0.9872 - loss: 0.0271 - val_AUC: 0.8870 - val_accuracy: 0.8039 - val_loss: 0.8237\n",
            "Epoch 48/100\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - AUC: 0.9998 - accuracy: 0.9917 - loss: 0.0251 - val_AUC: 0.8795 - val_accuracy: 0.7843 - val_loss: 0.8141\n",
            "Epoch 49/100\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - AUC: 0.9999 - accuracy: 0.9870 - loss: 0.0261 - val_AUC: 0.8874 - val_accuracy: 0.7941 - val_loss: 0.8268\n",
            "Epoch 50/100\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - AUC: 0.9999 - accuracy: 0.9953 - loss: 0.0196 - val_AUC: 0.8841 - val_accuracy: 0.7941 - val_loss: 0.8477\n",
            "Epoch 51/100\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - AUC: 0.9999 - accuracy: 0.9880 - loss: 0.0274 - val_AUC: 0.8818 - val_accuracy: 0.8039 - val_loss: 0.8460\n",
            "Epoch 52/100\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - AUC: 0.9998 - accuracy: 0.9876 - loss: 0.0221 - val_AUC: 0.8764 - val_accuracy: 0.8137 - val_loss: 0.8398\n",
            "Epoch 53/100\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - AUC: 0.9999 - accuracy: 0.9902 - loss: 0.0203 - val_AUC: 0.8776 - val_accuracy: 0.8137 - val_loss: 0.8471\n",
            "Epoch 54/100\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - AUC: 1.0000 - accuracy: 0.9982 - loss: 0.0176 - val_AUC: 0.8760 - val_accuracy: 0.8137 - val_loss: 0.8597\n",
            "Epoch 55/100\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - AUC: 0.9999 - accuracy: 0.9855 - loss: 0.0201 - val_AUC: 0.8762 - val_accuracy: 0.8137 - val_loss: 0.8665\n",
            "Epoch 56/100\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - AUC: 0.9999 - accuracy: 0.9874 - loss: 0.0204 - val_AUC: 0.8783 - val_accuracy: 0.8137 - val_loss: 0.8694\n",
            "Epoch 57/100\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - AUC: 0.9999 - accuracy: 0.9943 - loss: 0.0207 - val_AUC: 0.8650 - val_accuracy: 0.8039 - val_loss: 0.8744\n",
            "Epoch 58/100\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - AUC: 0.9999 - accuracy: 0.9898 - loss: 0.0210 - val_AUC: 0.8727 - val_accuracy: 0.8039 - val_loss: 0.8843\n",
            "Epoch 59/100\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - AUC: 0.9999 - accuracy: 0.9874 - loss: 0.0177 - val_AUC: 0.8704 - val_accuracy: 0.8137 - val_loss: 0.8983\n",
            "Epoch 60/100\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - AUC: 0.9998 - accuracy: 0.9848 - loss: 0.0232 - val_AUC: 0.8702 - val_accuracy: 0.8137 - val_loss: 0.9037\n",
            "Epoch 61/100\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - AUC: 0.9998 - accuracy: 0.9820 - loss: 0.0243 - val_AUC: 0.8662 - val_accuracy: 0.8137 - val_loss: 0.8993\n",
            "Epoch 62/100\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - AUC: 0.9999 - accuracy: 0.9902 - loss: 0.0204 - val_AUC: 0.8793 - val_accuracy: 0.7941 - val_loss: 0.9078\n",
            "Epoch 63/100\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - AUC: 0.9998 - accuracy: 0.9848 - loss: 0.0204 - val_AUC: 0.8617 - val_accuracy: 0.8039 - val_loss: 0.9091\n",
            "Epoch 64/100\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - AUC: 0.9997 - accuracy: 0.9855 - loss: 0.0234 - val_AUC: 0.8656 - val_accuracy: 0.8039 - val_loss: 0.9279\n",
            "Epoch 65/100\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - AUC: 0.9998 - accuracy: 0.9925 - loss: 0.0196 - val_AUC: 0.8621 - val_accuracy: 0.7941 - val_loss: 0.9218\n",
            "Epoch 66/100\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - AUC: 0.9998 - accuracy: 0.9898 - loss: 0.0186 - val_AUC: 0.8631 - val_accuracy: 0.8039 - val_loss: 0.9199\n",
            "Epoch 67/100\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - AUC: 0.9999 - accuracy: 0.9928 - loss: 0.0157 - val_AUC: 0.8694 - val_accuracy: 0.7941 - val_loss: 0.9366\n",
            "Epoch 68/100\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - AUC: 0.9998 - accuracy: 0.9855 - loss: 0.0193 - val_AUC: 0.8634 - val_accuracy: 0.8137 - val_loss: 0.9354\n",
            "Epoch 69/100\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - AUC: 0.9999 - accuracy: 0.9943 - loss: 0.0160 - val_AUC: 0.8602 - val_accuracy: 0.8137 - val_loss: 0.9564\n",
            "Epoch 70/100\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - AUC: 0.9999 - accuracy: 0.9953 - loss: 0.0164 - val_AUC: 0.8598 - val_accuracy: 0.8039 - val_loss: 0.9757\n",
            "Epoch 71/100\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - AUC: 0.9999 - accuracy: 0.9962 - loss: 0.0169 - val_AUC: 0.8590 - val_accuracy: 0.8039 - val_loss: 0.9766\n",
            "Epoch 72/100\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - AUC: 0.9998 - accuracy: 0.9822 - loss: 0.0208 - val_AUC: 0.8609 - val_accuracy: 0.7941 - val_loss: 0.9879\n",
            "Epoch 73/100\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - AUC: 0.9999 - accuracy: 0.9905 - loss: 0.0203 - val_AUC: 0.8617 - val_accuracy: 0.8039 - val_loss: 0.9782\n",
            "Epoch 74/100\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - AUC: 0.9999 - accuracy: 0.9935 - loss: 0.0173 - val_AUC: 0.8615 - val_accuracy: 0.8039 - val_loss: 0.9769\n",
            "Epoch 75/100\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - AUC: 0.9999 - accuracy: 0.9921 - loss: 0.0166 - val_AUC: 0.8619 - val_accuracy: 0.8039 - val_loss: 0.9914\n",
            "Epoch 76/100\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - AUC: 0.9998 - accuracy: 0.9902 - loss: 0.0178 - val_AUC: 0.8600 - val_accuracy: 0.8137 - val_loss: 0.9897\n",
            "Epoch 77/100\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - AUC: 0.9998 - accuracy: 0.9880 - loss: 0.0170 - val_AUC: 0.8607 - val_accuracy: 0.8039 - val_loss: 0.9882\n",
            "Epoch 78/100\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - AUC: 0.9999 - accuracy: 0.9884 - loss: 0.0138 - val_AUC: 0.8607 - val_accuracy: 0.8137 - val_loss: 0.9989\n",
            "Epoch 79/100\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - AUC: 0.9999 - accuracy: 0.9968 - loss: 0.0137 - val_AUC: 0.8592 - val_accuracy: 0.8137 - val_loss: 1.0020\n",
            "Epoch 80/100\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - AUC: 0.9998 - accuracy: 0.9921 - loss: 0.0172 - val_AUC: 0.8600 - val_accuracy: 0.8039 - val_loss: 1.0067\n",
            "Epoch 81/100\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - AUC: 0.9999 - accuracy: 0.9888 - loss: 0.0165 - val_AUC: 0.8466 - val_accuracy: 0.7941 - val_loss: 1.0258\n",
            "Epoch 82/100\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - AUC: 0.9999 - accuracy: 0.9866 - loss: 0.0151 - val_AUC: 0.8536 - val_accuracy: 0.7843 - val_loss: 1.0279\n",
            "Epoch 83/100\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - AUC: 1.0000 - accuracy: 0.9993 - loss: 0.0132 - val_AUC: 0.8466 - val_accuracy: 0.7941 - val_loss: 1.0282\n",
            "Epoch 84/100\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - AUC: 1.0000 - accuracy: 0.9920 - loss: 0.0136 - val_AUC: 0.8544 - val_accuracy: 0.7941 - val_loss: 1.0247\n",
            "Epoch 85/100\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - AUC: 0.9999 - accuracy: 0.9920 - loss: 0.0144 - val_AUC: 0.8542 - val_accuracy: 0.8137 - val_loss: 1.0280\n",
            "Epoch 86/100\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - AUC: 0.9999 - accuracy: 0.9978 - loss: 0.0142 - val_AUC: 0.8468 - val_accuracy: 0.8137 - val_loss: 1.0304\n",
            "Epoch 87/100\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - AUC: 0.9999 - accuracy: 0.9898 - loss: 0.0141 - val_AUC: 0.8468 - val_accuracy: 0.8039 - val_loss: 1.0333\n",
            "Epoch 88/100\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - AUC: 1.0000 - accuracy: 0.9968 - loss: 0.0130 - val_AUC: 0.8468 - val_accuracy: 0.8039 - val_loss: 1.0396\n",
            "Epoch 89/100\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - AUC: 1.0000 - accuracy: 1.0000 - loss: 0.0122 - val_AUC: 0.8416 - val_accuracy: 0.8039 - val_loss: 1.0374\n",
            "Epoch 90/100\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - AUC: 0.9999 - accuracy: 0.9968 - loss: 0.0142 - val_AUC: 0.8435 - val_accuracy: 0.8039 - val_loss: 1.0415\n",
            "Epoch 91/100\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - AUC: 0.9999 - accuracy: 0.9928 - loss: 0.0152 - val_AUC: 0.8470 - val_accuracy: 0.8039 - val_loss: 1.0528\n",
            "Epoch 92/100\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - AUC: 0.9999 - accuracy: 0.9968 - loss: 0.0142 - val_AUC: 0.8366 - val_accuracy: 0.8039 - val_loss: 1.0542\n",
            "Epoch 93/100\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - AUC: 1.0000 - accuracy: 0.9939 - loss: 0.0130 - val_AUC: 0.8462 - val_accuracy: 0.8039 - val_loss: 1.0701\n",
            "Epoch 94/100\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - AUC: 1.0000 - accuracy: 0.9946 - loss: 0.0122 - val_AUC: 0.8410 - val_accuracy: 0.8039 - val_loss: 1.0784\n",
            "Epoch 95/100\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - AUC: 0.9999 - accuracy: 0.9874 - loss: 0.0147 - val_AUC: 0.8340 - val_accuracy: 0.8039 - val_loss: 1.0810\n",
            "Epoch 96/100\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - AUC: 1.0000 - accuracy: 1.0000 - loss: 0.0114 - val_AUC: 0.8337 - val_accuracy: 0.8039 - val_loss: 1.0793\n",
            "Epoch 97/100\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - AUC: 0.9999 - accuracy: 0.9888 - loss: 0.0148 - val_AUC: 0.8344 - val_accuracy: 0.7843 - val_loss: 1.0917\n",
            "Epoch 98/100\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - AUC: 1.0000 - accuracy: 0.9898 - loss: 0.0136 - val_AUC: 0.8408 - val_accuracy: 0.7843 - val_loss: 1.0949\n",
            "Epoch 99/100\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - AUC: 0.9999 - accuracy: 0.9905 - loss: 0.0130 - val_AUC: 0.8420 - val_accuracy: 0.7745 - val_loss: 1.0861\n",
            "Epoch 100/100\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - AUC: 0.9999 - accuracy: 0.9895 - loss: 0.0140 - val_AUC: 0.8420 - val_accuracy: 0.7843 - val_loss: 1.0862\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - AUC: 0.8645 - accuracy: 0.8104 - loss: 0.9550 \n",
            "Optimized Model Test Accuracy: 0.7734, AUC: 0.8326\n"
          ]
        }
      ],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, LSTM, Dropout, Reshape, LeakyReLU\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "\n",
        "nBits = 1024\n",
        "units = [32]\n",
        "dropout_rate = 0.5\n",
        "learning_rate = 0.001\n",
        "\n",
        "model_optimized_leaky_relu = Sequential()\n",
        "model_optimized_leaky_relu.add(tf.keras.Input(shape=(nBits,)))\n",
        "model_optimized_leaky_relu.add(Reshape((1, nBits)))\n",
        "\n",
        "# Layer LSTM dengan activation tanh dan LeakyReLU\n",
        "model_optimized_leaky_relu.add(LSTM(units[0], activation='tanh', recurrent_activation='sigmoid', return_sequences=True))\n",
        "model_optimized_leaky_relu.add(LeakyReLU(alpha=0.2)) # Tambahin LeakyReLU di sini\n",
        "model_optimized_leaky_relu.add(LSTM(units[0], activation='tanh', recurrent_activation='sigmoid', return_sequences=False))\n",
        "model_optimized_leaky_relu.add(LeakyReLU(alpha=0.2)) # Tambahin LeakyReLU di sini\n",
        "model_optimized_leaky_relu.add(Dropout(dropout_rate))\n",
        "\n",
        "model_optimized_leaky_relu.add(Dense(1, activation='sigmoid'))\n",
        "\n",
        "model_optimized_leaky_relu.compile(optimizer=Adam(learning_rate=learning_rate),\n",
        "                                   loss='binary_crossentropy',\n",
        "                                   metrics=['accuracy', 'AUC'])\n",
        "\n",
        "model_optimized_leaky_relu.summary()\n",
        "\n",
        "history_optimized_leaky_relu = model_optimized_leaky_relu.fit(\n",
        "    X_train,\n",
        "    y_train,\n",
        "    validation_split=0.2,\n",
        "    epochs=100,\n",
        "    batch_size=32\n",
        ")\n",
        "\n",
        "\n",
        "# Evaluate the model\n",
        "loss, accuracy, auc = model_optimized_leaky_relu.evaluate(X_test, y_test)\n",
        "print(f\"Optimized Model Test Accuracy: {accuracy:.4f}, AUC: {auc:.4f}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "id": "89631db7",
      "metadata": {},
      "outputs": [],
      "source": [
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "\n",
        "# Atur disiplin buat model lu\n",
        "early_stopping_callback = EarlyStopping(\n",
        "    monitor='val_loss', \n",
        "    patience=10, \n",
        "    restore_best_weights=True,\n",
        "    verbose=1 \n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "id": "c77832ca",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_3\"</span>\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1mModel: \"sequential_3\"\u001b[0m\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ reshape_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Reshape</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1024</span>)        │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ lstm_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)             │       <span style=\"color: #00af00; text-decoration-color: #00af00\">135,296</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dropout_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)             │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)              │            <span style=\"color: #00af00; text-decoration-color: #00af00\">33</span> │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
              "</pre>\n"
            ],
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ reshape_3 (\u001b[38;5;33mReshape\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m1024\u001b[0m)        │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ lstm_3 (\u001b[38;5;33mLSTM\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)             │       \u001b[38;5;34m135,296\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dropout_3 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)             │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_3 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)              │            \u001b[38;5;34m33\u001b[0m │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">135,329</span> (528.63 KB)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m135,329\u001b[0m (528.63 KB)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">135,329</span> (528.63 KB)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m135,329\u001b[0m (528.63 KB)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 30ms/step - AUC: 0.5788 - accuracy: 0.5542 - loss: 0.6865 - val_AUC: 0.8151 - val_accuracy: 0.7255 - val_loss: 0.6665\n",
            "Epoch 2/100\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - AUC: 0.8339 - accuracy: 0.7488 - loss: 0.6316 - val_AUC: 0.8708 - val_accuracy: 0.8333 - val_loss: 0.6100\n",
            "Epoch 3/100\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - AUC: 0.8725 - accuracy: 0.8251 - loss: 0.5587 - val_AUC: 0.8894 - val_accuracy: 0.8431 - val_loss: 0.5370\n",
            "Epoch 4/100\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - AUC: 0.8928 - accuracy: 0.8128 - loss: 0.4859 - val_AUC: 0.8952 - val_accuracy: 0.8431 - val_loss: 0.4756\n",
            "Epoch 5/100\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - AUC: 0.9113 - accuracy: 0.8325 - loss: 0.4233 - val_AUC: 0.9019 - val_accuracy: 0.8431 - val_loss: 0.4357\n",
            "Epoch 6/100\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - AUC: 0.9313 - accuracy: 0.8547 - loss: 0.3748 - val_AUC: 0.9052 - val_accuracy: 0.8529 - val_loss: 0.4118\n",
            "Epoch 7/100\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - AUC: 0.9519 - accuracy: 0.8842 - loss: 0.3252 - val_AUC: 0.9149 - val_accuracy: 0.8431 - val_loss: 0.3920\n",
            "Epoch 8/100\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - AUC: 0.9474 - accuracy: 0.8842 - loss: 0.3175 - val_AUC: 0.9172 - val_accuracy: 0.8529 - val_loss: 0.3791\n",
            "Epoch 9/100\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - AUC: 0.9533 - accuracy: 0.8842 - loss: 0.2977 - val_AUC: 0.9221 - val_accuracy: 0.8529 - val_loss: 0.3658\n",
            "Epoch 10/100\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - AUC: 0.9684 - accuracy: 0.9015 - loss: 0.2598 - val_AUC: 0.9211 - val_accuracy: 0.8529 - val_loss: 0.3562\n",
            "Epoch 11/100\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - AUC: 0.9608 - accuracy: 0.9163 - loss: 0.2753 - val_AUC: 0.9251 - val_accuracy: 0.8627 - val_loss: 0.3478\n",
            "Epoch 12/100\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - AUC: 0.9667 - accuracy: 0.8990 - loss: 0.2539 - val_AUC: 0.9257 - val_accuracy: 0.8824 - val_loss: 0.3403\n",
            "Epoch 13/100\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - AUC: 0.9763 - accuracy: 0.8941 - loss: 0.2272 - val_AUC: 0.9279 - val_accuracy: 0.8824 - val_loss: 0.3354\n",
            "Epoch 14/100\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - AUC: 0.9763 - accuracy: 0.9163 - loss: 0.2211 - val_AUC: 0.9259 - val_accuracy: 0.8824 - val_loss: 0.3355\n",
            "Epoch 15/100\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - AUC: 0.9732 - accuracy: 0.9163 - loss: 0.2257 - val_AUC: 0.9284 - val_accuracy: 0.8824 - val_loss: 0.3350\n",
            "Epoch 16/100\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - AUC: 0.9802 - accuracy: 0.9064 - loss: 0.2062 - val_AUC: 0.9280 - val_accuracy: 0.8627 - val_loss: 0.3368\n",
            "Epoch 17/100\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - AUC: 0.9818 - accuracy: 0.9286 - loss: 0.1974 - val_AUC: 0.9269 - val_accuracy: 0.8627 - val_loss: 0.3374\n",
            "Epoch 18/100\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - AUC: 0.9835 - accuracy: 0.9187 - loss: 0.1928 - val_AUC: 0.9277 - val_accuracy: 0.8627 - val_loss: 0.3374\n",
            "Epoch 19/100\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - AUC: 0.9839 - accuracy: 0.9360 - loss: 0.1835 - val_AUC: 0.9292 - val_accuracy: 0.8725 - val_loss: 0.3338\n",
            "Epoch 20/100\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - AUC: 0.9881 - accuracy: 0.9409 - loss: 0.1703 - val_AUC: 0.9284 - val_accuracy: 0.8627 - val_loss: 0.3350\n",
            "Epoch 21/100\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - AUC: 0.9878 - accuracy: 0.9261 - loss: 0.1692 - val_AUC: 0.9306 - val_accuracy: 0.8431 - val_loss: 0.3342\n",
            "Epoch 22/100\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - AUC: 0.9900 - accuracy: 0.9507 - loss: 0.1601 - val_AUC: 0.9300 - val_accuracy: 0.8627 - val_loss: 0.3385\n",
            "Epoch 23/100\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - AUC: 0.9896 - accuracy: 0.9384 - loss: 0.1551 - val_AUC: 0.9280 - val_accuracy: 0.8725 - val_loss: 0.3409\n",
            "Epoch 24/100\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - AUC: 0.9908 - accuracy: 0.9384 - loss: 0.1484 - val_AUC: 0.9259 - val_accuracy: 0.8725 - val_loss: 0.3450\n",
            "Epoch 25/100\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - AUC: 0.9929 - accuracy: 0.9532 - loss: 0.1399 - val_AUC: 0.9284 - val_accuracy: 0.8627 - val_loss: 0.3437\n",
            "Epoch 26/100\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - AUC: 0.9887 - accuracy: 0.9384 - loss: 0.1533 - val_AUC: 0.9277 - val_accuracy: 0.8627 - val_loss: 0.3466\n",
            "Epoch 27/100\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - AUC: 0.9908 - accuracy: 0.9483 - loss: 0.1445 - val_AUC: 0.9279 - val_accuracy: 0.8627 - val_loss: 0.3501\n",
            "Epoch 28/100\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - AUC: 0.9929 - accuracy: 0.9507 - loss: 0.1392 - val_AUC: 0.9263 - val_accuracy: 0.8627 - val_loss: 0.3518\n",
            "Epoch 29/100\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - AUC: 0.9946 - accuracy: 0.9581 - loss: 0.1267 - val_AUC: 0.9242 - val_accuracy: 0.8529 - val_loss: 0.3585\n",
            "Epoch 29: early stopping\n",
            "Restoring model weights from the end of the best epoch: 19.\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - AUC: 0.8998 - accuracy: 0.8203 - loss: 0.4278 \n",
            "Baseline 1 Test Accuracy: 0.8203, AUC: 0.8998\n"
          ]
        }
      ],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, LSTM, Dropout, Reshape # Tambah Reshape\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "tf.random.set_seed(42)\n",
        "\n",
        "# Assume nBits is the size of your fingerprint (e.g., 1024)\n",
        "nBits = 1024 # Sesuaikan dengan nBits yang lu pake di RDKit\n",
        "\n",
        "units = [32] # Ukuran hidden state LSTM\n",
        "dropout_rate = 0.4\n",
        "learning_rate = 0.001\n",
        "\n",
        "# Build the model for Fingerprint input\n",
        "model_baseline_1 = Sequential()\n",
        "\n",
        "# Layer Input: Langsung terima vektor fingerprint\n",
        "# Bentuk inputnya adalah (panjang_fingerprint,)\n",
        "model_baseline_1.add(tf.keras.Input(shape=(nBits,))) # Define input shape\n",
        "\n",
        "# Tambahkan layer Reshape untuk mengubah (nBits,) menjadi (1, nBits)\n",
        "# Agar cocok dengan input shape LSTM yang butuh 3D (samples, timesteps, features)\n",
        "model_baseline_1.add(Reshape((1, nBits))) # Ubah (features,) jadi (1, features)\n",
        "\n",
        "# Layer LSTM: Sekarang inputnya udah 3D (samples, 1, nBits)\n",
        "# Return sequences False karena kita cuma punya 1 timestep dan mau output single vector\n",
        "model_baseline_1.add(LSTM(units[0], activation='relu', recurrent_activation='sigmoid', return_sequences=False))\n",
        "\n",
        "# Layer Dropout\n",
        "model_baseline_1.add(Dropout(dropout_rate))\n",
        "\n",
        "\n",
        "model_baseline_1.add(Dense(1, activation='sigmoid')) # Ganti kalau task-nya regresi\n",
        "\n",
        "# Compile the model\n",
        "model_baseline_1.compile(optimizer=Adam(learning_rate=learning_rate),\n",
        "                        loss='binary_crossentropy',\n",
        "                        metrics=['accuracy', 'AUC'])\n",
        "\n",
        "model_baseline_1.summary() # Penting buat ngecek arsitektur dan shape\n",
        "\n",
        "# Train the model\n",
        "history_baseline_1 = model_baseline_1.fit(\n",
        "    X_train,\n",
        "    y_train,\n",
        "    validation_split=0.2,\n",
        "    epochs=100,\n",
        "    batch_size=32,\n",
        "    callbacks=[early_stopping_callback]\n",
        ")\n",
        "\n",
        "# Evaluate the model\n",
        "loss, accuracy, auc = model_baseline_1.evaluate(X_test, y_test)\n",
        "print(f\"Baseline 1 Test Accuracy: {accuracy:.4f}, AUC: {auc:.4f}\")"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "py311",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.13"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
